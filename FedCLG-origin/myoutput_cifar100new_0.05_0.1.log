nohup: 忽略输入

===== Run 1/3 =====
Torch version: 2.3.1
CUDA available: True
Files already downloaded and verified
Files already downloaded and verified
类别 0 的数据样本不足，采样数从 3177 调整为 2500
类别 12 的数据样本不足，采样数从 3177 调整为 2500
类别 14 的数据样本不足，采样数从 3004 调整为 2500
类别 15 的数据样本不足，采样数从 2789 调整为 2500
类别 17 的数据样本不足，采样数从 2629 调整为 2500
Traning Client Total: 37371 2500 2072 1629 1548 1642 1191 2428 1440 2139 1408 1407 1536 2500 2030 2500 2500 1453 2500 1132 1816
Client 0: 396 0 0 0 0 0 2 0 0 60 0 0 0 0 0 0 3 0 28 0 303
Client 1: 397 15 0 0 0 0 0 0 0 257 5 3 0 0 105 0 0 7 0 5
Client 2: 395 3 0 0 286 0 10 0 2 0 17 51 22 0 1 0 0 1 1 1
Client 3: 396 0 0 0 0 0 0 0 135 0 8 36 0 0 0 0 0 12 194 6 5
Client 4: 396 0 0 0 0 0 19 0 0 13 0 0 0 145 3 0 115 101
Client 5: 393 45 30 104 0 0 16 0 27 7 0 0 47 5 0 1 97 0 0 14
Client 6: 395 263 13 0 0 0 0 0 1 5 0 42 2 0 0 1 0 3 37 28
Client 7: 397 0 41 0 0 0 0 0 0 80 5 0 45 142 0 0 3 0 81
Client 8: 397 0 0 0 0 0 0 0 0 7 0 0 0 155 53 0 176 0 6
Client 9: 396 0 22 263 0 0 24 0 0 0 18 0 0 2 0 0 0 1 0 65 1
Server: 2500 110 88 245 171 12 184 102 21 23 6 30 261 41 1 0 76 187 236 71 635
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:08<13:17,  8.05s/it]  2%|▏         | 2/100 [00:15<12:37,  7.73s/it]  3%|▎         | 3/100 [00:22<12:09,  7.52s/it]  4%|▍         | 4/100 [00:30<11:55,  7.45s/it]  5%|▌         | 5/100 [00:37<11:45,  7.43s/it]  6%|▌         | 6/100 [00:44<11:28,  7.32s/it]  7%|▋         | 7/100 [00:52<11:21,  7.33s/it]  8%|▊         | 8/100 [00:59<11:08,  7.26s/it]  9%|▉         | 9/100 [01:06<10:59,  7.25s/it] 10%|█         | 10/100 [01:13<10:56,  7.30s/it] 11%|█         | 11/100 [01:21<11:01,  7.43s/it] 12%|█▏        | 12/100 [01:28<10:55,  7.45s/it] 13%|█▎        | 13/100 [01:36<10:53,  7.52s/it] 14%|█▍        | 14/100 [01:43<10:37,  7.42s/it] 15%|█▌        | 15/100 [01:51<10:35,  7.47s/it] 16%|█▌        | 16/100 [01:58<10:19,  7.38s/it] 17%|█▋        | 17/100 [02:06<10:22,  7.50s/it] 18%|█▊        | 18/100 [02:13<10:01,  7.34s/it] 19%|█▉        | 19/100 [02:20<09:58,  7.39s/it] 20%|██        | 20/100 [02:28<09:46,  7.33s/it] 21%|██        | 21/100 [02:35<09:34,  7.28s/it] 22%|██▏       | 22/100 [02:42<09:27,  7.27s/it] 23%|██▎       | 23/100 [02:49<09:20,  7.28s/it] 24%|██▍       | 24/100 [02:57<09:12,  7.26s/it] 25%|██▌       | 25/100 [03:04<09:04,  7.26s/it] 26%|██▌       | 26/100 [03:11<08:51,  7.18s/it] 27%|██▋       | 27/100 [03:18<08:45,  7.20s/it] 28%|██▊       | 28/100 [03:25<08:37,  7.19s/it] 29%|██▉       | 29/100 [03:33<08:40,  7.34s/it] 30%|███       | 30/100 [03:40<08:37,  7.40s/it] 31%|███       | 31/100 [03:48<08:30,  7.40s/it] 32%|███▏      | 32/100 [03:55<08:28,  7.48s/it] 33%|███▎      | 33/100 [04:03<08:16,  7.41s/it] 34%|███▍      | 34/100 [04:10<08:07,  7.38s/it] 35%|███▌      | 35/100 [04:18<08:04,  7.45s/it] 36%|███▌      | 36/100 [04:25<07:49,  7.34s/it] 37%|███▋      | 37/100 [04:32<07:41,  7.33s/it] 38%|███▊      | 38/100 [04:39<07:34,  7.34s/it] 39%|███▉      | 39/100 [04:47<07:26,  7.31s/it] 40%|████      | 40/100 [04:54<07:17,  7.29s/it] 41%|████      | 41/100 [05:01<07:08,  7.26s/it] 42%|████▏     | 42/100 [05:08<06:59,  7.23s/it] 43%|████▎     | 43/100 [05:15<06:48,  7.17s/it] 44%|████▍     | 44/100 [05:22<06:39,  7.13s/it] 45%|████▌     | 45/100 [05:30<06:36,  7.21s/it] 46%|████▌     | 46/100 [05:37<06:30,  7.24s/it] 47%|████▋     | 47/100 [05:44<06:22,  7.22s/it] 48%|████▊     | 48/100 [05:51<06:16,  7.25s/it] 49%|████▉     | 49/100 [05:59<06:10,  7.27s/it] 50%|█████     | 50/100 [06:06<06:04,  7.30s/it] 51%|█████     | 51/100 [06:13<05:51,  7.18s/it] 52%|█████▏    | 52/100 [06:20<05:47,  7.23s/it] 53%|█████▎    | 53/100 [06:28<05:39,  7.23s/it] 54%|█████▍    | 54/100 [06:35<05:33,  7.24s/it] 55%|█████▌    | 55/100 [06:42<05:26,  7.26s/it] 56%|█████▌    | 56/100 [06:49<05:18,  7.24s/it] 57%|█████▋    | 57/100 [06:57<05:15,  7.34s/it] 58%|█████▊    | 58/100 [07:04<05:08,  7.34s/it] 59%|█████▉    | 59/100 [07:12<05:01,  7.36s/it] 60%|██████    | 60/100 [07:19<04:55,  7.38s/it] 61%|██████    | 61/100 [07:27<04:49,  7.42s/it] 62%|██████▏   | 62/100 [07:34<04:38,  7.33s/it] 63%|██████▎   | 63/100 [07:42<04:36,  7.47s/it] 64%|██████▍   | 64/100 [07:49<04:30,  7.52s/it] 65%|██████▌   | 65/100 [07:56<04:19,  7.42s/it] 66%|██████▌   | 66/100 [08:03<04:08,  7.32s/it] 67%|██████▋   | 67/100 [08:11<04:04,  7.42s/it] 68%|██████▊   | 68/100 [08:18<03:56,  7.39s/it] 69%|██████▉   | 69/100 [08:26<03:46,  7.30s/it] 70%|███████   | 70/100 [08:33<03:39,  7.32s/it] 71%|███████   | 71/100 [08:40<03:32,  7.32s/it] 72%|███████▏  | 72/100 [08:47<03:23,  7.27s/it] 73%|███████▎  | 73/100 [08:55<03:15,  7.24s/it] 74%|███████▍  | 74/100 [09:02<03:07,  7.23s/it] 75%|███████▌  | 75/100 [09:09<03:00,  7.22s/it] 76%|███████▌  | 76/100 [09:16<02:53,  7.25s/it] 77%|███████▋  | 77/100 [09:24<02:49,  7.36s/it] 78%|███████▊  | 78/100 [09:31<02:40,  7.32s/it] 79%|███████▉  | 79/100 [09:38<02:32,  7.26s/it] 80%|████████  | 80/100 [09:45<02:24,  7.23s/it] 81%|████████  | 81/100 [09:53<02:19,  7.33s/it] 82%|████████▏ | 82/100 [10:00<02:11,  7.32s/it] 83%|████████▎ | 83/100 [10:07<02:03,  7.24s/it] 84%|████████▍ | 84/100 [10:15<01:56,  7.29s/it] 85%|████████▌ | 85/100 [10:22<01:49,  7.29s/it] 86%|████████▌ | 86/100 [10:29<01:42,  7.31s/it] 87%|████████▋ | 87/100 [10:37<01:35,  7.37s/it] 88%|████████▊ | 88/100 [10:44<01:28,  7.40s/it] 89%|████████▉ | 89/100 [10:51<01:20,  7.31s/it] 90%|█████████ | 90/100 [10:59<01:13,  7.31s/it] 91%|█████████ | 91/100 [11:06<01:04,  7.20s/it] 92%|█████████▏| 92/100 [11:13<00:57,  7.13s/it] 93%|█████████▎| 93/100 [11:20<00:50,  7.15s/it] 94%|█████████▍| 94/100 [11:27<00:43,  7.21s/it] 95%|█████████▌| 95/100 [11:34<00:35,  7.17s/it] 96%|█████████▌| 96/100 [11:41<00:28,  7.18s/it] 97%|█████████▋| 97/100 [11:49<00:21,  7.18s/it] 98%|█████████▊| 98/100 [11:56<00:14,  7.25s/it] 99%|█████████▉| 99/100 [12:03<00:07,  7.23s/it]100%|██████████| 100/100 [12:10<00:00,  7.20s/it]100%|██████████| 100/100 [12:10<00:00,  7.31s/it]
FedDU-Mut初始设置:
  服务器数据量: 2500
  服务器数据非IID度: 0.221989
  Mutation幅度(radius): 2.0
  0%|          | 0/100 [00:00<?, ?it/s]  0%|          | 0/100 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "multi_run.py", line 27, in <module>
    globs = runpy.run_path(src_script)
  File "/home/anaconda/envs/env8/lib/python3.8/runpy.py", line 265, in run_path
    return _run_module_code(code, init_globals, run_name,
  File "/home/anaconda/envs/env8/lib/python3.8/runpy.py", line 97, in _run_module_code
    _run_code(code, mod_globals, init_globals,
  File "/home/anaconda/envs/env8/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "script_v14.0_cifar100_0.05_0.1.py", line 2447, in <module>
    results_test_acc, results_train_loss = run_once()
  File "script_v14.0_cifar100_0.05_0.1.py", line 2381, in run_once
    test_acc_FedDU_Mut, train_loss_FedDU_Mut = FedDU_Mut(copy.deepcopy(init_model), global_round, eta, gamma, K, E, M)
  File "script_v14.0_cifar100_0.05_0.1.py", line 1910, in FedDU_Mut
    update_client_w, client_round_loss, _ = update_weights(
  File "script_v14.0_cifar100_0.05_0.1.py", line 753, in update_weights
    loss.backward()
  File "/home/anaconda/envs/env8/lib/python3.8/site-packages/torch/_tensor.py", line 525, in backward
    torch.autograd.backward(
  File "/home/anaconda/envs/env8/lib/python3.8/site-packages/torch/autograd/__init__.py", line 267, in backward
    _engine_run_backward(
  File "/home/anaconda/envs/env8/lib/python3.8/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 64.00 MiB. GPU  has a total capacity of 23.65 GiB of which 28.56 MiB is free. Process 3340009 has 14.97 GiB memory in use. Process 3350450 has 5.14 GiB memory in use. Including non-PyTorch memory, this process has 3.49 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 68.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
