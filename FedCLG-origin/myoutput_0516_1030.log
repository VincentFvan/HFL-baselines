nohup: 忽略输入
Torch version: 2.3.1
CUDA available: True
Files already downloaded and verified
Files already downloaded and verified
类别 4 的数据样本不足，采样数从 2742 调整为 2500
Traning Client Total: 38885 1661 1663 1791 2008 2500 1822 1768 1941 1615 1523 2432 1956 2023 1663 1813 1833 2189 2426 2437 1821
Client 0: 389 11 6 1 3 15 0 1 46 44 0 1 1 8 16 9 33 0 124 58 12
Client 1: 390 5 7 3 1 195 24 20 2 6 1 29 24 12 6 3 18 1 12 0 21
Client 2: 389 84 56 3 22 4 10 23 25 22 18 3 0 0 5 0 2 13 72 0 27
Client 3: 393 69 34 46 2 0 6 0 0 25 72 20 20 10 9 12 0 10 41 12 5
Client 4: 391 20 4 5 0 13 1 59 54 7 4 40 32 69 0 1 24 9 31 18
Client 5: 390 7 57 23 4 16 91 5 5 32 2 34 0 11 1 1 23 1 59 18
Client 6: 390 0 10 2 15 39 33 0 3 44 7 6 4 0 0 0 68 17 1 47 94
Client 7: 391 12 5 26 0 119 3 1 1 0 0 2 8 4 3 25 4 7 13 104 54
Client 8: 392 0 4 39 7 0 13 44 132 10 0 45 8 8 0 42 5 6 25 4
Client 9: 390 2 13 4 40 13 0 33 4 6 7 17 11 32 0 15 2 21 150 14 6
Server: 2500 0 106 181 39 203 57 822 72 16 0 22 336 0 15 0 34 70 486 6 35

--- Running experiments with mut_acc_rate = 0.1 ---
FedDU-Mut初始设置:
  服务器数据量: 2500
  服务器数据非IID度: 0.313398
  Mutation幅度(radius): 2.0
  0%|          | 0/100 [00:00<?, ?it/s]  0%|          | 0/100 [00:01<?, ?it/s]
Traceback (most recent call last):
  File "script_v13.0_250512.py", line 2784, in <module>
    test_acc_FedDU_Mut, train_loss_FedDU_Mut = FedDU_Mut(copy.deepcopy(init_model), global_round, eta, gamma, K, E, M)
  File "script_v13.0_250512.py", line 1909, in FedDU_Mut
    update_client_w, client_round_loss, _ = update_weights(
  File "script_v13.0_250512.py", line 753, in update_weights
    loss.backward()
  File "/home/anaconda/envs/env8/lib/python3.8/site-packages/torch/_tensor.py", line 525, in backward
    torch.autograd.backward(
  File "/home/anaconda/envs/env8/lib/python3.8/site-packages/torch/autograd/__init__.py", line 267, in backward
    _engine_run_backward(
  File "/home/anaconda/envs/env8/lib/python3.8/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 64.00 MiB. GPU  has a total capacity of 23.65 GiB of which 16.56 MiB is free. Process 2806461 has 14.97 GiB memory in use. Process 2902560 has 5.12 GiB memory in use. Including non-PyTorch memory, this process has 3.53 GiB memory in use. Of the allocated memory 2.95 GiB is allocated by PyTorch, and 104.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
