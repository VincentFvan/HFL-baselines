[NbConvertApp] Converting notebook FedCLG_draft_v4.0_250211.ipynb to notebook
[NbConvertApp] Executing notebook with kernel: python3
Traceback (most recent call last):
  File "/home/anaconda/bin/jupyter-nbconvert", line 11, in <module>
    sys.exit(main())
  File "/root/.local/lib/python3.8/site-packages/jupyter_core/application.py", line 283, in launch_instance
    super().launch_instance(argv=argv, **kwargs)
  File "/root/.local/lib/python3.8/site-packages/traitlets/config/application.py", line 1075, in launch_instance
    app.start()
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 350, in start
    self.convert_notebooks()
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 524, in convert_notebooks
    self.convert_single_notebook(notebook_filename)
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 489, in convert_single_notebook
    output, resources = self.export_single_notebook(notebook_filename, resources, input_buffer=input_buffer)
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 418, in export_single_notebook
    output, resources = self.exporter.from_filename(notebook_filename, resources=resources)
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 181, in from_filename
    return self.from_file(f, resources=resources, **kw)
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 199, in from_file
    return self.from_notebook_node(nbformat.read(file_stream, as_version=4), resources=resources, **kw)
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/exporters/notebook.py", line 32, in from_notebook_node
    nb_copy, resources = super().from_notebook_node(nb, resources, **kw)
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 143, in from_notebook_node
    nb_copy, resources = self._preprocess(nb_copy, resources)
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 318, in _preprocess
    nbc, resc = preprocessor(nbc, resc)
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/preprocessors/base.py", line 47, in __call__
    return self.preprocess(nb, resources)
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/preprocessors/execute.py", line 79, in preprocess
    self.execute()
  File "/home/anaconda/lib/python3.8/site-packages/nbclient/util.py", line 74, in wrapped
    return just_run(coro(*args, **kwargs))
  File "/home/anaconda/lib/python3.8/site-packages/nbclient/util.py", line 53, in just_run
    return loop.run_until_complete(coro)
  File "/home/anaconda/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/home/anaconda/lib/python3.8/site-packages/nbclient/client.py", line 540, in async_execute
    await self.async_execute_cell(
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/preprocessors/execute.py", line 123, in async_execute_cell
    cell, resources = self.preprocess_cell(cell, self.resources, cell_index)
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/preprocessors/execute.py", line 146, in preprocess_cell
    cell = run_sync(NotebookClient.async_execute_cell)(self, cell, index, store_history=self.store_history)
  File "/home/anaconda/lib/python3.8/site-packages/nbclient/util.py", line 74, in wrapped
    return just_run(coro(*args, **kwargs))
  File "/home/anaconda/lib/python3.8/site-packages/nbclient/util.py", line 53, in just_run
    return loop.run_until_complete(coro)
  File "/root/.local/lib/python3.8/site-packages/nest_asyncio.py", line 98, in run_until_complete
    return f.result()
  File "/home/anaconda/lib/python3.8/asyncio/futures.py", line 178, in result
    raise self._exception
  File "/home/anaconda/lib/python3.8/asyncio/tasks.py", line 280, in __step
    result = coro.send(None)
  File "/home/anaconda/lib/python3.8/site-packages/nbclient/client.py", line 832, in async_execute_cell
    self._check_raise_for_error(cell, exec_reply)
  File "/home/anaconda/lib/python3.8/site-packages/nbclient/client.py", line 740, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply['content'])
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
def set_random_seed(seed):
    """
        set random seed
    """
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)


# 固定随机数
if random_fix:
    set_random_seed(seed)

if origin_model == 'resnet':
# 准备CIFAR100数据集
    cifar, test_dataset = CIFAR100()
    prob = get_prob(non_iid, client_num, class_num=20)
    client_data = create_data_all_train(prob, size_per_client, cifar, N=20)   # 这里改为全部构建训练集

    # 将测试标签转换为粗类别
    test_dataset.targets = sparse2coarse(test_dataset.targets)

    # 如果需要确保测试标签为整数类型
    test_dataset.targets = test_dataset.targets.astype(int)


    #CIFAR1--IID 挑选服务器子集：
    if server_iid:
        server_images, server_labels = select_server_subset(cifar, percentage=server_percentage, mode='iid')
    else:
        server_images, server_labels = select_server_subset(cifar, percentage=server_percentage,
                                                        mode='non-iid', dirichlet_alpha=0.5)

    # CIFAR100——用了FedMut中定义的CNN网络
    init_model = ResNet18_cifar10().to(device)
    initial_w = copy.deepcopy(init_model.state_dict())
elif origin_model =='lstm':
    # 准备shakespeare数据集
    train_dataset = ShakeSpeare(True)
    test_dataset = ShakeSpeare(False)

    total_shake,total_label = [],[]
    for item,labels in train_dataset:
        total_shake.append(item.numpy())
        total_label.append(labels)
    total_shake = np.array(total_shake)
    total_label = np.array(total_label)

    shake = [total_shake, total_label]

    # 构建每个client的数据量
    dict_users = train_dataset.get_client_dic()

    # 统计类别数量
    unique_classes = np.unique(total_label)
    num_classes = len(unique_classes)
    print("shake数据集中类别数量：", num_classes)
    # 对于每个类别计算样本数量
    class_counts = [np.sum(total_label == cls) for cls in unique_classes]
    # 将数量转换成字符串后，用逗号隔开，并打印（只输出数字）
    print(", ".join(map(str, class_counts)))

    # 统计客户端数量
    num_clients = len(dict_users)
    print("shake数据集中客户端数量：", num_clients)


    # 构建client_data
    client_data = []
    for client in sorted(dict_users.keys()):
        indices = np.array(list(dict_users[client]), dtype=np.int64)
        client_images = total_shake[indices]
        client_labels = total_label[indices]
        client_data.append((client_images, client_labels))


    # Shake 挑选服务器子集，通过 Dirichlet 分布参数控制（例如 dirichlet_alpha=0.5）：
    if server_iid:
        server_images, server_labels = select_server_subset(shake, percentage=server_percentage,
                                                      mode='iid')
    else:
        server_images, server_labels = select_server_subset(shake, percentage=server_percentage,
                                                        mode='non-iid', dirichlet_alpha=0.5)


    # Shakespeare —— 用FedMut中提出的LSTM网络
    init_model = CharLSTM().to(device)
    initial_w = copy.deepcopy(init_model.state_dict())


#  打印数据集情况
all_images = []
all_labels = []
for data in client_data:
    all_images.extend(data[0])
    all_labels.extend(data[1])
comb_client_data = [np.array(all_images), np.array(all_labels)]

# 输出comb_client_data情况
imgs, lbls = comb_client_data
lbls = np.array(lbls)
total_count = len(lbls)
unique_classes, counts = np.unique(lbls, return_counts=True)

num_classes = int(unique_classes.max()) + 1  # 列表长度应该为最大类别
class_counts = [0] * num_classes

for cls, cnt in zip(unique_classes, counts):
    class_counts[cls] = cnt

# 打印格式：Total: 总数 类别0计数 类别1计数 ... 类别19计数
print("Traning Client Total: {}".format(" ".join([str(total_count)] + [str(c) for c in class_counts])))


# 打印每个客户端训练数据情况（只输出前10个）
for i, (imgs, lbls) in enumerate(client_data[:10]):
    lbls = np.array(lbls)
    total_count = len(lbls)
    unique_classes, counts = np.unique(lbls, return_counts=True)
    
    num_classes = int(unique_classes.max()) + 1  # 列表长度应该为最大类别
    class_counts = [0] * num_classes
    
    for cls, cnt in zip(unique_classes, counts):
        class_counts[cls] = cnt
    # 打印格式：Client i: 总数 类别0计数 类别1计数 ... 类别19计数
    print("Client {}: {}".format(i, " ".join([str(total_count)] + [str(c) for c in class_counts])))
    

# 为了与后续代码兼容，这里将 server_data 定义为一个列表：[images, labels]
server_data = [server_images, server_labels]

# 打印服务器数据情况
s_imgs, s_lbls = server_data
s_lbls = np.array(s_lbls)
total_count = len(s_lbls)
unique_classes, counts = np.unique(s_lbls, return_counts=True)

num_classes = int(unique_classes.max()) + 1  # 列表长度应该为最大类别+1
class_counts = [0] * num_classes

for cls, cnt in zip(unique_classes, counts):
    class_counts[cls] = cnt
# 输出格式: Server: 总数 类别0计数 类别1计数 ... 类别19计数
print("Server: {}".format(" ".join([str(total_count)] + [str(c) for c in class_counts])))
# print("  前5个标签: ", lbls[:5])
# print("  前5个数据形状: ", [server_data[0][j].shape for j in range(min(5, len(server_data[0])))])




# 初始化结果存储字典
results_test_acc = {}
results_train_loss = {}

# CLG_Mut 训练
test_acc_CLG_Mut, train_loss_CLG_Mut = CLG_Mut(copy.deepcopy(init_model), global_round, eta, gamma, K, E, M)
results_test_acc['CLG_Mut'] = test_acc_CLG_Mut
results_train_loss['CLG_Mut'] = train_loss_CLG_Mut

# CLG_Mut_2 训练
test_acc_CLG_Mut_2, train_loss_CLG_Mut_2 = CLG_Mut_2(copy.deepcopy(init_model), global_round, eta, gamma, K, E, M)
results_test_acc['CLG_Mut_2'] = test_acc_CLG_Mut_2
results_train_loss['CLG_Mut_2'] = train_loss_CLG_Mut_2

# CLG_Mut_3 训练
test_acc_CLG_Mut_3, train_loss_CLG_Mut_3 = CLG_Mut_3(copy.deepcopy(init_model), global_round, eta, gamma, K, E, M)
results_test_acc['CLG_Mut_3'] = test_acc_CLG_Mut_3
results_train_loss['CLG_Mut_3'] = train_loss_CLG_Mut_3


# FedMut 训练
test_acc_FedMut, train_loss_FedMut = FedMut(copy.deepcopy(init_model), global_round, eta, K, M)
results_test_acc['FedMut'] = test_acc_FedMut
results_train_loss['FedMut'] = train_loss_FedMut

# Server-only 训练
test_acc_server_only, train_loss_server_only = server_only(initial_w, global_round, gamma, E)
results_test_acc['Server_only'] = test_acc_server_only
results_train_loss['Server_only'] = train_loss_server_only

# FedAvg 训练
test_acc_fedavg, train_loss_fedavg = fedavg(initial_w, global_round, eta, K, M)
results_test_acc['FedAvg'] = test_acc_fedavg
results_train_loss['FedAvg'] = train_loss_fedavg

# CLG_SGD 训练
test_acc_CLG_SGD, train_loss_CLG_SGD = CLG_SGD(initial_w, global_round, eta, gamma, K, E, M)
results_test_acc['CLG_SGD'] = test_acc_CLG_SGD
results_train_loss['CLG_SGD'] = train_loss_CLG_SGD

# 打印训练结果（可选）
for algo in results_test_acc:
    print(f"{algo} - 最终测试精度: {results_test_acc[algo][-1]:.2f}%, 最终训练损失: {results_train_loss[algo][-1]:.4f}")

------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mRuntimeError[0m                              Traceback (most recent call last)
Cell [0;32mIn[1], line 89[0m
[1;32m     84[0m         server_images, server_labels [38;5;241m=[39m select_server_subset(shake, percentage[38;5;241m=[39mserver_percentage,
[1;32m     85[0m                                                         mode[38;5;241m=[39m[38;5;124m'[39m[38;5;124mnon-iid[39m[38;5;124m'[39m, dirichlet_alpha[38;5;241m=[39m[38;5;241m0.5[39m)
[1;32m     88[0m     [38;5;66;03m# Shakespeare —— 用FedMut中提出的LSTM网络[39;00m
[0;32m---> 89[0m     init_model [38;5;241m=[39m [43mCharLSTM[49m[43m([49m[43m)[49m[38;5;241;43m.[39;49m[43mto[49m[43m([49m[43mdevice[49m[43m)[49m
[1;32m     90[0m     initial_w [38;5;241m=[39m copy[38;5;241m.[39mdeepcopy(init_model[38;5;241m.[39mstate_dict())
[1;32m     93[0m [38;5;66;03m#  打印数据集情况[39;00m

File [0;32m/home/anaconda/lib/python3.8/site-packages/torch/nn/modules/module.py:927[0m, in [0;36mModule.to[0;34m(self, *args, **kwargs)[0m
[1;32m    923[0m         [38;5;28;01mreturn[39;00m t[38;5;241m.[39mto(device, dtype [38;5;28;01mif[39;00m t[38;5;241m.[39mis_floating_point() [38;5;129;01mor[39;00m t[38;5;241m.[39mis_complex() [38;5;28;01melse[39;00m [38;5;28;01mNone[39;00m,
[1;32m    924[0m                     non_blocking, memory_format[38;5;241m=[39mconvert_to_format)
[1;32m    925[0m     [38;5;28;01mreturn[39;00m t[38;5;241m.[39mto(device, dtype [38;5;28;01mif[39;00m t[38;5;241m.[39mis_floating_point() [38;5;129;01mor[39;00m t[38;5;241m.[39mis_complex() [38;5;28;01melse[39;00m [38;5;28;01mNone[39;00m, non_blocking)
[0;32m--> 927[0m [38;5;28;01mreturn[39;00m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43m_apply[49m[43m([49m[43mconvert[49m[43m)[49m

File [0;32m/home/anaconda/lib/python3.8/site-packages/torch/nn/modules/module.py:579[0m, in [0;36mModule._apply[0;34m(self, fn)[0m
[1;32m    577[0m [38;5;28;01mdef[39;00m [38;5;21m_apply[39m([38;5;28mself[39m, fn):
[1;32m    578[0m     [38;5;28;01mfor[39;00m module [38;5;129;01min[39;00m [38;5;28mself[39m[38;5;241m.[39mchildren():
[0;32m--> 579[0m         [43mmodule[49m[38;5;241;43m.[39;49m[43m_apply[49m[43m([49m[43mfn[49m[43m)[49m
[1;32m    581[0m     [38;5;28;01mdef[39;00m [38;5;21mcompute_should_use_set_data[39m(tensor, tensor_applied):
[1;32m    582[0m         [38;5;28;01mif[39;00m torch[38;5;241m.[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):
[1;32m    583[0m             [38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,[39;00m
[1;32m    584[0m             [38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,[39;00m
[0;32m   (...)[0m
[1;32m    589[0m             [38;5;66;03m# global flag to let the user control whether they want the future[39;00m
[1;32m    590[0m             [38;5;66;03m# behavior of overwriting the existing tensor or not.[39;00m

File [0;32m/home/anaconda/lib/python3.8/site-packages/torch/nn/modules/rnn.py:189[0m, in [0;36mRNNBase._apply[0;34m(self, fn)[0m
[1;32m    187[0m [38;5;28mself[39m[38;5;241m.[39m_flat_weights [38;5;241m=[39m [([38;5;28;01mlambda[39;00m wn: [38;5;28mgetattr[39m([38;5;28mself[39m, wn) [38;5;28;01mif[39;00m [38;5;28mhasattr[39m([38;5;28mself[39m, wn) [38;5;28;01melse[39;00m [38;5;28;01mNone[39;00m)(wn) [38;5;28;01mfor[39;00m wn [38;5;129;01min[39;00m [38;5;28mself[39m[38;5;241m.[39m_flat_weights_names]
[1;32m    188[0m [38;5;66;03m# Flattens params (on CUDA)[39;00m
[0;32m--> 189[0m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mflatten_parameters[49m[43m([49m[43m)[49m
[1;32m    191[0m [38;5;28;01mreturn[39;00m ret

File [0;32m/home/anaconda/lib/python3.8/site-packages/torch/nn/modules/rnn.py:175[0m, in [0;36mRNNBase.flatten_parameters[0;34m(self)[0m
[1;32m    173[0m [38;5;28;01mif[39;00m [38;5;28mself[39m[38;5;241m.[39mproj_size [38;5;241m>[39m [38;5;241m0[39m:
[1;32m    174[0m     num_weights [38;5;241m+[39m[38;5;241m=[39m [38;5;241m1[39m
[0;32m--> 175[0m [43mtorch[49m[38;5;241;43m.[39;49m[43m_cudnn_rnn_flatten_weight[49m[43m([49m
[1;32m    176[0m [43m    [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43m_flat_weights[49m[43m,[49m[43m [49m[43mnum_weights[49m[43m,[49m
[1;32m    177[0m [43m    [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43minput_size[49m[43m,[49m[43m [49m[43mrnn[49m[38;5;241;43m.[39;49m[43mget_cudnn_mode[49m[43m([49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mmode[49m[43m)[49m[43m,[49m
[1;32m    178[0m [43m    [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mhidden_size[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mproj_size[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mnum_layers[49m[43m,[49m
[1;32m    179[0m [43m    [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mbatch_first[49m[43m,[49m[43m [49m[38;5;28;43mbool[39;49m[43m([49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mbidirectional[49m[43m)[49m[43m)[49m

[0;31mRuntimeError[0m: CUDA error: no kernel image is available for execution on the device
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
RuntimeError: CUDA error: no kernel image is available for execution on the device
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.

[NbConvertApp] Converting notebook FedCLG_draft_v4.0_250211.ipynb to notebook
[NbConvertApp] Executing notebook with kernel: python3
Traceback (most recent call last):
  File "/home/anaconda/bin/jupyter-nbconvert", line 11, in <module>
    sys.exit(main())
  File "/root/.local/lib/python3.8/site-packages/jupyter_core/application.py", line 283, in launch_instance
    super().launch_instance(argv=argv, **kwargs)
  File "/root/.local/lib/python3.8/site-packages/traitlets/config/application.py", line 1075, in launch_instance
    app.start()
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 350, in start
    self.convert_notebooks()
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 524, in convert_notebooks
    self.convert_single_notebook(notebook_filename)
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 489, in convert_single_notebook
    output, resources = self.export_single_notebook(notebook_filename, resources, input_buffer=input_buffer)
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 418, in export_single_notebook
    output, resources = self.exporter.from_filename(notebook_filename, resources=resources)
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 181, in from_filename
    return self.from_file(f, resources=resources, **kw)
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 199, in from_file
    return self.from_notebook_node(nbformat.read(file_stream, as_version=4), resources=resources, **kw)
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/exporters/notebook.py", line 32, in from_notebook_node
    nb_copy, resources = super().from_notebook_node(nb, resources, **kw)
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 143, in from_notebook_node
    nb_copy, resources = self._preprocess(nb_copy, resources)
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 318, in _preprocess
    nbc, resc = preprocessor(nbc, resc)
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/preprocessors/base.py", line 47, in __call__
    return self.preprocess(nb, resources)
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/preprocessors/execute.py", line 79, in preprocess
    self.execute()
  File "/home/anaconda/lib/python3.8/site-packages/nbclient/util.py", line 74, in wrapped
    return just_run(coro(*args, **kwargs))
  File "/home/anaconda/lib/python3.8/site-packages/nbclient/util.py", line 53, in just_run
    return loop.run_until_complete(coro)
  File "/home/anaconda/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/home/anaconda/lib/python3.8/site-packages/nbclient/client.py", line 540, in async_execute
    await self.async_execute_cell(
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/preprocessors/execute.py", line 123, in async_execute_cell
    cell, resources = self.preprocess_cell(cell, self.resources, cell_index)
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/preprocessors/execute.py", line 146, in preprocess_cell
    cell = run_sync(NotebookClient.async_execute_cell)(self, cell, index, store_history=self.store_history)
  File "/home/anaconda/lib/python3.8/site-packages/nbclient/util.py", line 74, in wrapped
    return just_run(coro(*args, **kwargs))
  File "/home/anaconda/lib/python3.8/site-packages/nbclient/util.py", line 53, in just_run
    return loop.run_until_complete(coro)
  File "/root/.local/lib/python3.8/site-packages/nest_asyncio.py", line 98, in run_until_complete
    return f.result()
  File "/home/anaconda/lib/python3.8/asyncio/futures.py", line 178, in result
    raise self._exception
  File "/home/anaconda/lib/python3.8/asyncio/tasks.py", line 280, in __step
    result = coro.send(None)
  File "/home/anaconda/lib/python3.8/site-packages/nbclient/client.py", line 832, in async_execute_cell
    self._check_raise_for_error(cell, exec_reply)
  File "/home/anaconda/lib/python3.8/site-packages/nbclient/client.py", line 740, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply['content'])
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
def set_random_seed(seed):
    """
        set random seed
    """
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)


# 固定随机数
if random_fix:
    set_random_seed(seed)

if origin_model == 'resnet':
# 准备CIFAR100数据集
    cifar, test_dataset = CIFAR100()
    prob = get_prob(non_iid, client_num, class_num=20)
    client_data = create_data_all_train(prob, size_per_client, cifar, N=20)   # 这里改为全部构建训练集

    # 将测试标签转换为粗类别
    test_dataset.targets = sparse2coarse(test_dataset.targets)

    # 如果需要确保测试标签为整数类型
    test_dataset.targets = test_dataset.targets.astype(int)


    #CIFAR1--IID 挑选服务器子集：
    if server_iid:
        server_images, server_labels = select_server_subset(cifar, percentage=server_percentage, mode='iid')
    else:
        server_images, server_labels = select_server_subset(cifar, percentage=server_percentage,
                                                        mode='non-iid', dirichlet_alpha=0.5)

    # CIFAR100——用了FedMut中定义的CNN网络
    init_model = ResNet18_cifar10().to(device)
    initial_w = copy.deepcopy(init_model.state_dict())
elif origin_model =='lstm':
    # 准备shakespeare数据集
    train_dataset = ShakeSpeare(True)
    test_dataset = ShakeSpeare(False)

    total_shake,total_label = [],[]
    for item,labels in train_dataset:
        total_shake.append(item.numpy())
        total_label.append(labels)
    total_shake = np.array(total_shake)
    total_label = np.array(total_label)

    shake = [total_shake, total_label]

    # 构建每个client的数据量
    dict_users = train_dataset.get_client_dic()

    # 统计类别数量
    unique_classes = np.unique(total_label)
    num_classes = len(unique_classes)
    print("shake数据集中类别数量：", num_classes)
    # 对于每个类别计算样本数量
    class_counts = [np.sum(total_label == cls) for cls in unique_classes]
    # 将数量转换成字符串后，用逗号隔开，并打印（只输出数字）
    print(", ".join(map(str, class_counts)))

    # 统计客户端数量
    num_clients = len(dict_users)
    print("shake数据集中客户端数量：", num_clients)


    # 构建client_data
    client_data = []
    for client in sorted(dict_users.keys()):
        indices = np.array(list(dict_users[client]), dtype=np.int64)
        client_images = total_shake[indices]
        client_labels = total_label[indices]
        client_data.append((client_images, client_labels))


    # Shake 挑选服务器子集，通过 Dirichlet 分布参数控制（例如 dirichlet_alpha=0.5）：
    if server_iid:
        server_images, server_labels = select_server_subset(shake, percentage=server_percentage,
                                                      mode='iid')
    else:
        server_images, server_labels = select_server_subset(shake, percentage=server_percentage,
                                                        mode='non-iid', dirichlet_alpha=0.5)


    # Shakespeare —— 用FedMut中提出的LSTM网络
    init_model = CharLSTM().to(device)
    initial_w = copy.deepcopy(init_model.state_dict())


#  打印数据集情况
all_images = []
all_labels = []
for data in client_data:
    all_images.extend(data[0])
    all_labels.extend(data[1])
comb_client_data = [np.array(all_images), np.array(all_labels)]

# 输出comb_client_data情况
imgs, lbls = comb_client_data
lbls = np.array(lbls)
total_count = len(lbls)
unique_classes, counts = np.unique(lbls, return_counts=True)

num_classes = int(unique_classes.max()) + 1  # 列表长度应该为最大类别
class_counts = [0] * num_classes

for cls, cnt in zip(unique_classes, counts):
    class_counts[cls] = cnt

# 打印格式：Total: 总数 类别0计数 类别1计数 ... 类别19计数
print("Traning Client Total: {}".format(" ".join([str(total_count)] + [str(c) for c in class_counts])))


# 打印每个客户端训练数据情况（只输出前10个）
for i, (imgs, lbls) in enumerate(client_data[:10]):
    lbls = np.array(lbls)
    total_count = len(lbls)
    unique_classes, counts = np.unique(lbls, return_counts=True)
    
    num_classes = int(unique_classes.max()) + 1  # 列表长度应该为最大类别
    class_counts = [0] * num_classes
    
    for cls, cnt in zip(unique_classes, counts):
        class_counts[cls] = cnt
    # 打印格式：Client i: 总数 类别0计数 类别1计数 ... 类别19计数
    print("Client {}: {}".format(i, " ".join([str(total_count)] + [str(c) for c in class_counts])))
    

# 为了与后续代码兼容，这里将 server_data 定义为一个列表：[images, labels]
server_data = [server_images, server_labels]

# 打印服务器数据情况
s_imgs, s_lbls = server_data
s_lbls = np.array(s_lbls)
total_count = len(s_lbls)
unique_classes, counts = np.unique(s_lbls, return_counts=True)

num_classes = int(unique_classes.max()) + 1  # 列表长度应该为最大类别+1
class_counts = [0] * num_classes

for cls, cnt in zip(unique_classes, counts):
    class_counts[cls] = cnt
# 输出格式: Server: 总数 类别0计数 类别1计数 ... 类别19计数
print("Server: {}".format(" ".join([str(total_count)] + [str(c) for c in class_counts])))
# print("  前5个标签: ", lbls[:5])
# print("  前5个数据形状: ", [server_data[0][j].shape for j in range(min(5, len(server_data[0])))])




# 初始化结果存储字典
results_test_acc = {}
results_train_loss = {}

# CLG_Mut 训练
test_acc_CLG_Mut, train_loss_CLG_Mut = CLG_Mut(copy.deepcopy(init_model), global_round, eta, gamma, K, E, M)
results_test_acc['CLG_Mut'] = test_acc_CLG_Mut
results_train_loss['CLG_Mut'] = train_loss_CLG_Mut

# CLG_Mut_2 训练
test_acc_CLG_Mut_2, train_loss_CLG_Mut_2 = CLG_Mut_2(copy.deepcopy(init_model), global_round, eta, gamma, K, E, M)
results_test_acc['CLG_Mut_2'] = test_acc_CLG_Mut_2
results_train_loss['CLG_Mut_2'] = train_loss_CLG_Mut_2

# CLG_Mut_3 训练
test_acc_CLG_Mut_3, train_loss_CLG_Mut_3 = CLG_Mut_3(copy.deepcopy(init_model), global_round, eta, gamma, K, E, M)
results_test_acc['CLG_Mut_3'] = test_acc_CLG_Mut_3
results_train_loss['CLG_Mut_3'] = train_loss_CLG_Mut_3


# FedMut 训练
test_acc_FedMut, train_loss_FedMut = FedMut(copy.deepcopy(init_model), global_round, eta, K, M)
results_test_acc['FedMut'] = test_acc_FedMut
results_train_loss['FedMut'] = train_loss_FedMut

# Server-only 训练
test_acc_server_only, train_loss_server_only = server_only(initial_w, global_round, gamma, E)
results_test_acc['Server_only'] = test_acc_server_only
results_train_loss['Server_only'] = train_loss_server_only

# FedAvg 训练
test_acc_fedavg, train_loss_fedavg = fedavg(initial_w, global_round, eta, K, M)
results_test_acc['FedAvg'] = test_acc_fedavg
results_train_loss['FedAvg'] = train_loss_fedavg

# CLG_SGD 训练
test_acc_CLG_SGD, train_loss_CLG_SGD = CLG_SGD(initial_w, global_round, eta, gamma, K, E, M)
results_test_acc['CLG_SGD'] = test_acc_CLG_SGD
results_train_loss['CLG_SGD'] = train_loss_CLG_SGD

# 打印训练结果（可选）
for algo in results_test_acc:
    print(f"{algo} - 最终测试精度: {results_test_acc[algo][-1]:.2f}%, 最终训练损失: {results_train_loss[algo][-1]:.4f}")

------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mRuntimeError[0m                              Traceback (most recent call last)
Cell [0;32mIn[1], line 89[0m
[1;32m     84[0m         server_images, server_labels [38;5;241m=[39m select_server_subset(shake, percentage[38;5;241m=[39mserver_percentage,
[1;32m     85[0m                                                         mode[38;5;241m=[39m[38;5;124m'[39m[38;5;124mnon-iid[39m[38;5;124m'[39m, dirichlet_alpha[38;5;241m=[39m[38;5;241m0.5[39m)
[1;32m     88[0m     [38;5;66;03m# Shakespeare —— 用FedMut中提出的LSTM网络[39;00m
[0;32m---> 89[0m     init_model [38;5;241m=[39m [43mCharLSTM[49m[43m([49m[43m)[49m[38;5;241;43m.[39;49m[43mto[49m[43m([49m[43mdevice[49m[43m)[49m
[1;32m     90[0m     initial_w [38;5;241m=[39m copy[38;5;241m.[39mdeepcopy(init_model[38;5;241m.[39mstate_dict())
[1;32m     93[0m [38;5;66;03m#  打印数据集情况[39;00m

File [0;32m/home/anaconda/lib/python3.8/site-packages/torch/nn/modules/module.py:927[0m, in [0;36mModule.to[0;34m(self, *args, **kwargs)[0m
[1;32m    923[0m         [38;5;28;01mreturn[39;00m t[38;5;241m.[39mto(device, dtype [38;5;28;01mif[39;00m t[38;5;241m.[39mis_floating_point() [38;5;129;01mor[39;00m t[38;5;241m.[39mis_complex() [38;5;28;01melse[39;00m [38;5;28;01mNone[39;00m,
[1;32m    924[0m                     non_blocking, memory_format[38;5;241m=[39mconvert_to_format)
[1;32m    925[0m     [38;5;28;01mreturn[39;00m t[38;5;241m.[39mto(device, dtype [38;5;28;01mif[39;00m t[38;5;241m.[39mis_floating_point() [38;5;129;01mor[39;00m t[38;5;241m.[39mis_complex() [38;5;28;01melse[39;00m [38;5;28;01mNone[39;00m, non_blocking)
[0;32m--> 927[0m [38;5;28;01mreturn[39;00m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43m_apply[49m[43m([49m[43mconvert[49m[43m)[49m

File [0;32m/home/anaconda/lib/python3.8/site-packages/torch/nn/modules/module.py:579[0m, in [0;36mModule._apply[0;34m(self, fn)[0m
[1;32m    577[0m [38;5;28;01mdef[39;00m [38;5;21m_apply[39m([38;5;28mself[39m, fn):
[1;32m    578[0m     [38;5;28;01mfor[39;00m module [38;5;129;01min[39;00m [38;5;28mself[39m[38;5;241m.[39mchildren():
[0;32m--> 579[0m         [43mmodule[49m[38;5;241;43m.[39;49m[43m_apply[49m[43m([49m[43mfn[49m[43m)[49m
[1;32m    581[0m     [38;5;28;01mdef[39;00m [38;5;21mcompute_should_use_set_data[39m(tensor, tensor_applied):
[1;32m    582[0m         [38;5;28;01mif[39;00m torch[38;5;241m.[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):
[1;32m    583[0m             [38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,[39;00m
[1;32m    584[0m             [38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,[39;00m
[0;32m   (...)[0m
[1;32m    589[0m             [38;5;66;03m# global flag to let the user control whether they want the future[39;00m
[1;32m    590[0m             [38;5;66;03m# behavior of overwriting the existing tensor or not.[39;00m

File [0;32m/home/anaconda/lib/python3.8/site-packages/torch/nn/modules/rnn.py:189[0m, in [0;36mRNNBase._apply[0;34m(self, fn)[0m
[1;32m    187[0m [38;5;28mself[39m[38;5;241m.[39m_flat_weights [38;5;241m=[39m [([38;5;28;01mlambda[39;00m wn: [38;5;28mgetattr[39m([38;5;28mself[39m, wn) [38;5;28;01mif[39;00m [38;5;28mhasattr[39m([38;5;28mself[39m, wn) [38;5;28;01melse[39;00m [38;5;28;01mNone[39;00m)(wn) [38;5;28;01mfor[39;00m wn [38;5;129;01min[39;00m [38;5;28mself[39m[38;5;241m.[39m_flat_weights_names]
[1;32m    188[0m [38;5;66;03m# Flattens params (on CUDA)[39;00m
[0;32m--> 189[0m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mflatten_parameters[49m[43m([49m[43m)[49m
[1;32m    191[0m [38;5;28;01mreturn[39;00m ret

File [0;32m/home/anaconda/lib/python3.8/site-packages/torch/nn/modules/rnn.py:175[0m, in [0;36mRNNBase.flatten_parameters[0;34m(self)[0m
[1;32m    173[0m [38;5;28;01mif[39;00m [38;5;28mself[39m[38;5;241m.[39mproj_size [38;5;241m>[39m [38;5;241m0[39m:
[1;32m    174[0m     num_weights [38;5;241m+[39m[38;5;241m=[39m [38;5;241m1[39m
[0;32m--> 175[0m [43mtorch[49m[38;5;241;43m.[39;49m[43m_cudnn_rnn_flatten_weight[49m[43m([49m
[1;32m    176[0m [43m    [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43m_flat_weights[49m[43m,[49m[43m [49m[43mnum_weights[49m[43m,[49m
[1;32m    177[0m [43m    [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43minput_size[49m[43m,[49m[43m [49m[43mrnn[49m[38;5;241;43m.[39;49m[43mget_cudnn_mode[49m[43m([49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mmode[49m[43m)[49m[43m,[49m
[1;32m    178[0m [43m    [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mhidden_size[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mproj_size[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mnum_layers[49m[43m,[49m
[1;32m    179[0m [43m    [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mbatch_first[49m[43m,[49m[43m [49m[38;5;28;43mbool[39;49m[43m([49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mbidirectional[49m[43m)[49m[43m)[49m

[0;31mRuntimeError[0m: CUDA error: no kernel image is available for execution on the device
RuntimeError: CUDA error: no kernel image is available for execution on the device

