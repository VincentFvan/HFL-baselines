[NbConvertApp] Converting notebook FedCLG_draft_v4.0_250211.ipynb to notebook
[NbConvertApp] Executing notebook with kernel: python3
Traceback (most recent call last):
  File "/home/anaconda/bin/jupyter-nbconvert", line 11, in <module>
    sys.exit(main())
  File "/root/.local/lib/python3.8/site-packages/jupyter_core/application.py", line 283, in launch_instance
    super().launch_instance(argv=argv, **kwargs)
  File "/root/.local/lib/python3.8/site-packages/traitlets/config/application.py", line 1075, in launch_instance
    app.start()
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 350, in start
    self.convert_notebooks()
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 524, in convert_notebooks
    self.convert_single_notebook(notebook_filename)
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 489, in convert_single_notebook
    output, resources = self.export_single_notebook(notebook_filename, resources, input_buffer=input_buffer)
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 418, in export_single_notebook
    output, resources = self.exporter.from_filename(notebook_filename, resources=resources)
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 181, in from_filename
    return self.from_file(f, resources=resources, **kw)
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 199, in from_file
    return self.from_notebook_node(nbformat.read(file_stream, as_version=4), resources=resources, **kw)
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/exporters/notebook.py", line 32, in from_notebook_node
    nb_copy, resources = super().from_notebook_node(nb, resources, **kw)
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 143, in from_notebook_node
    nb_copy, resources = self._preprocess(nb_copy, resources)
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 318, in _preprocess
    nbc, resc = preprocessor(nbc, resc)
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/preprocessors/base.py", line 47, in __call__
    return self.preprocess(nb, resources)
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/preprocessors/execute.py", line 79, in preprocess
    self.execute()
  File "/home/anaconda/lib/python3.8/site-packages/nbclient/util.py", line 74, in wrapped
    return just_run(coro(*args, **kwargs))
  File "/home/anaconda/lib/python3.8/site-packages/nbclient/util.py", line 53, in just_run
    return loop.run_until_complete(coro)
  File "/home/anaconda/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/home/anaconda/lib/python3.8/site-packages/nbclient/client.py", line 540, in async_execute
    await self.async_execute_cell(
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/preprocessors/execute.py", line 123, in async_execute_cell
    cell, resources = self.preprocess_cell(cell, self.resources, cell_index)
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/preprocessors/execute.py", line 146, in preprocess_cell
    cell = run_sync(NotebookClient.async_execute_cell)(self, cell, index, store_history=self.store_history)
  File "/home/anaconda/lib/python3.8/site-packages/nbclient/util.py", line 74, in wrapped
    return just_run(coro(*args, **kwargs))
  File "/home/anaconda/lib/python3.8/site-packages/nbclient/util.py", line 53, in just_run
    return loop.run_until_complete(coro)
  File "/root/.local/lib/python3.8/site-packages/nest_asyncio.py", line 98, in run_until_complete
    return f.result()
  File "/home/anaconda/lib/python3.8/asyncio/futures.py", line 178, in result
    raise self._exception
  File "/home/anaconda/lib/python3.8/asyncio/tasks.py", line 280, in __step
    result = coro.send(None)
  File "/home/anaconda/lib/python3.8/site-packages/nbclient/client.py", line 832, in async_execute_cell
    self._check_raise_for_error(cell, exec_reply)
  File "/home/anaconda/lib/python3.8/site-packages/nbclient/client.py", line 740, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply['content'])
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
def set_random_seed(seed):
    """
        set random seed
    """
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)


# å›ºå®šéšæœºæ•°
if random_fix:
    set_random_seed(seed)

if origin_model == 'resnet':
# å‡†å¤‡CIFAR100æ•°æ®é›†
    cifar, test_dataset = CIFAR100()
    prob = get_prob(non_iid, client_num, class_num=20)
    client_data = create_data_all_train(prob, size_per_client, cifar, N=20)   # è¿™é‡Œæ”¹ä¸ºå…¨éƒ¨æž„å»ºè®­ç»ƒé›†

    # å°†æµ‹è¯•æ ‡ç­¾è½¬æ¢ä¸ºç²—ç±»åˆ«
    test_dataset.targets = sparse2coarse(test_dataset.targets)

    # å¦‚æžœéœ€è¦ç¡®ä¿æµ‹è¯•æ ‡ç­¾ä¸ºæ•´æ•°ç±»åž‹
    test_dataset.targets = test_dataset.targets.astype(int)


    #CIFAR1--IID æŒ‘é€‰æœåŠ¡å™¨å­é›†ï¼š
    if server_iid:
        server_images, server_labels = select_server_subset(cifar, percentage=server_percentage, mode='iid')
    else:
        server_images, server_labels = select_server_subset(cifar, percentage=server_percentage,
                                                        mode='non-iid', dirichlet_alpha=0.5)

    # CIFAR100â€”â€”ç”¨äº†FedMutä¸­å®šä¹‰çš„CNNç½‘ç»œ
    init_model = ResNet18_cifar10().to(device)
    initial_w = copy.deepcopy(init_model.state_dict())
elif origin_model =='lstm':
    # å‡†å¤‡shakespeareæ•°æ®é›†
    train_dataset = ShakeSpeare(True)
    test_dataset = ShakeSpeare(False)

    total_shake,total_label = [],[]
    for item,labels in train_dataset:
        total_shake.append(item.numpy())
        total_label.append(labels)
    total_shake = np.array(total_shake)
    total_label = np.array(total_label)

    shake = [total_shake, total_label]

    # æž„å»ºæ¯ä¸ªclientçš„æ•°æ®é‡
    dict_users = train_dataset.get_client_dic()

    # ç»Ÿè®¡ç±»åˆ«æ•°é‡
    unique_classes = np.unique(total_label)
    num_classes = len(unique_classes)
    print("shakeæ•°æ®é›†ä¸­ç±»åˆ«æ•°é‡ï¼š", num_classes)
    # å¯¹äºŽæ¯ä¸ªç±»åˆ«è®¡ç®—æ ·æœ¬æ•°é‡
    class_counts = [np.sum(total_label == cls) for cls in unique_classes]
    # å°†æ•°é‡è½¬æ¢æˆå­—ç¬¦ä¸²åŽï¼Œç”¨é€—å·éš”å¼€ï¼Œå¹¶æ‰“å°ï¼ˆåªè¾“å‡ºæ•°å­—ï¼‰
    print(", ".join(map(str, class_counts)))

    # ç»Ÿè®¡å®¢æˆ·ç«¯æ•°é‡
    num_clients = len(dict_users)
    print("shakeæ•°æ®é›†ä¸­å®¢æˆ·ç«¯æ•°é‡ï¼š", num_clients)


    # æž„å»ºclient_data
    client_data = []
    for client in sorted(dict_users.keys()):
        indices = np.array(list(dict_users[client]), dtype=np.int64)
        client_images = total_shake[indices]
        client_labels = total_label[indices]
        client_data.append((client_images, client_labels))


    # Shake æŒ‘é€‰æœåŠ¡å™¨å­é›†ï¼Œé€šè¿‡ Dirichlet åˆ†å¸ƒå‚æ•°æŽ§åˆ¶ï¼ˆä¾‹å¦‚ dirichlet_alpha=0.5ï¼‰ï¼š
    if server_iid:
        server_images, server_labels = select_server_subset(shake, percentage=server_percentage,
                                                      mode='iid')
    else:
        server_images, server_labels = select_server_subset(shake, percentage=server_percentage,
                                                        mode='non-iid', dirichlet_alpha=0.5)


    # Shakespeare â€”â€” ç”¨FedMutä¸­æå‡ºçš„LSTMç½‘ç»œ
    init_model = CharLSTM().to(device)
    initial_w = copy.deepcopy(init_model.state_dict())


#  æ‰“å°æ•°æ®é›†æƒ…å†µ
all_images = []
all_labels = []
for data in client_data:
    all_images.extend(data[0])
    all_labels.extend(data[1])
comb_client_data = [np.array(all_images), np.array(all_labels)]

# è¾“å‡ºcomb_client_dataæƒ…å†µ
imgs, lbls = comb_client_data
lbls = np.array(lbls)
total_count = len(lbls)
unique_classes, counts = np.unique(lbls, return_counts=True)

num_classes = int(unique_classes.max()) + 1  # åˆ—è¡¨é•¿åº¦åº”è¯¥ä¸ºæœ€å¤§ç±»åˆ«
class_counts = [0] * num_classes

for cls, cnt in zip(unique_classes, counts):
    class_counts[cls] = cnt

# æ‰“å°æ ¼å¼ï¼šTotal: æ€»æ•° ç±»åˆ«0è®¡æ•° ç±»åˆ«1è®¡æ•° ... ç±»åˆ«19è®¡æ•°
print("Traning Client Total: {}".format(" ".join([str(total_count)] + [str(c) for c in class_counts])))


# æ‰“å°æ¯ä¸ªå®¢æˆ·ç«¯è®­ç»ƒæ•°æ®æƒ…å†µï¼ˆåªè¾“å‡ºå‰10ä¸ªï¼‰
for i, (imgs, lbls) in enumerate(client_data[:10]):
    lbls = np.array(lbls)
    total_count = len(lbls)
    unique_classes, counts = np.unique(lbls, return_counts=True)
    
    num_classes = int(unique_classes.max()) + 1  # åˆ—è¡¨é•¿åº¦åº”è¯¥ä¸ºæœ€å¤§ç±»åˆ«
    class_counts = [0] * num_classes
    
    for cls, cnt in zip(unique_classes, counts):
        class_counts[cls] = cnt
    # æ‰“å°æ ¼å¼ï¼šClient i: æ€»æ•° ç±»åˆ«0è®¡æ•° ç±»åˆ«1è®¡æ•° ... ç±»åˆ«19è®¡æ•°
    print("Client {}: {}".format(i, " ".join([str(total_count)] + [str(c) for c in class_counts])))
    

# ä¸ºäº†ä¸ŽåŽç»­ä»£ç å…¼å®¹ï¼Œè¿™é‡Œå°† server_data å®šä¹‰ä¸ºä¸€ä¸ªåˆ—è¡¨ï¼š[images, labels]
server_data = [server_images, server_labels]

# æ‰“å°æœåŠ¡å™¨æ•°æ®æƒ…å†µ
s_imgs, s_lbls = server_data
s_lbls = np.array(s_lbls)
total_count = len(s_lbls)
unique_classes, counts = np.unique(s_lbls, return_counts=True)

num_classes = int(unique_classes.max()) + 1  # åˆ—è¡¨é•¿åº¦åº”è¯¥ä¸ºæœ€å¤§ç±»åˆ«+1
class_counts = [0] * num_classes

for cls, cnt in zip(unique_classes, counts):
    class_counts[cls] = cnt
# è¾“å‡ºæ ¼å¼: Server: æ€»æ•° ç±»åˆ«0è®¡æ•° ç±»åˆ«1è®¡æ•° ... ç±»åˆ«19è®¡æ•°
print("Server: {}".format(" ".join([str(total_count)] + [str(c) for c in class_counts])))
# print("  å‰5ä¸ªæ ‡ç­¾: ", lbls[:5])
# print("  å‰5ä¸ªæ•°æ®å½¢çŠ¶: ", [server_data[0][j].shape for j in range(min(5, len(server_data[0])))])




# åˆå§‹åŒ–ç»“æžœå­˜å‚¨å­—å…¸
results_test_acc = {}
results_train_loss = {}

# CLG_Mut è®­ç»ƒ
test_acc_CLG_Mut, train_loss_CLG_Mut = CLG_Mut(copy.deepcopy(init_model), global_round, eta, gamma, K, E, M)
results_test_acc['CLG_Mut'] = test_acc_CLG_Mut
results_train_loss['CLG_Mut'] = train_loss_CLG_Mut

# CLG_Mut_2 è®­ç»ƒ
test_acc_CLG_Mut_2, train_loss_CLG_Mut_2 = CLG_Mut_2(copy.deepcopy(init_model), global_round, eta, gamma, K, E, M)
results_test_acc['CLG_Mut_2'] = test_acc_CLG_Mut_2
results_train_loss['CLG_Mut_2'] = train_loss_CLG_Mut_2

# CLG_Mut_3 è®­ç»ƒ
test_acc_CLG_Mut_3, train_loss_CLG_Mut_3 = CLG_Mut_3(copy.deepcopy(init_model), global_round, eta, gamma, K, E, M)
results_test_acc['CLG_Mut_3'] = test_acc_CLG_Mut_3
results_train_loss['CLG_Mut_3'] = train_loss_CLG_Mut_3


# FedMut è®­ç»ƒ
test_acc_FedMut, train_loss_FedMut = FedMut(copy.deepcopy(init_model), global_round, eta, K, M)
results_test_acc['FedMut'] = test_acc_FedMut
results_train_loss['FedMut'] = train_loss_FedMut

# Server-only è®­ç»ƒ
test_acc_server_only, train_loss_server_only = server_only(initial_w, global_round, gamma, E)
results_test_acc['Server_only'] = test_acc_server_only
results_train_loss['Server_only'] = train_loss_server_only

# FedAvg è®­ç»ƒ
test_acc_fedavg, train_loss_fedavg = fedavg(initial_w, global_round, eta, K, M)
results_test_acc['FedAvg'] = test_acc_fedavg
results_train_loss['FedAvg'] = train_loss_fedavg

# CLG_SGD è®­ç»ƒ
test_acc_CLG_SGD, train_loss_CLG_SGD = CLG_SGD(initial_w, global_round, eta, gamma, K, E, M)
results_test_acc['CLG_SGD'] = test_acc_CLG_SGD
results_train_loss['CLG_SGD'] = train_loss_CLG_SGD

# æ‰“å°è®­ç»ƒç»“æžœï¼ˆå¯é€‰ï¼‰
for algo in results_test_acc:
    print(f"{algo} - æœ€ç»ˆæµ‹è¯•ç²¾åº¦: {results_test_acc[algo][-1]:.2f}%, æœ€ç»ˆè®­ç»ƒæŸå¤±: {results_train_loss[algo][-1]:.4f}")

------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mRuntimeError[0m                              Traceback (most recent call last)
Cell [0;32mIn[1], line 89[0m
[1;32m     84[0m         server_images, server_labels [38;5;241m=[39m select_server_subset(shake, percentage[38;5;241m=[39mserver_percentage,
[1;32m     85[0m                                                         mode[38;5;241m=[39m[38;5;124m'[39m[38;5;124mnon-iid[39m[38;5;124m'[39m, dirichlet_alpha[38;5;241m=[39m[38;5;241m0.5[39m)
[1;32m     88[0m     [38;5;66;03m# Shakespeare â€”â€” ç”¨FedMutä¸­æå‡ºçš„LSTMç½‘ç»œ[39;00m
[0;32m---> 89[0m     init_model [38;5;241m=[39m [43mCharLSTM[49m[43m([49m[43m)[49m[38;5;241;43m.[39;49m[43mto[49m[43m([49m[43mdevice[49m[43m)[49m
[1;32m     90[0m     initial_w [38;5;241m=[39m copy[38;5;241m.[39mdeepcopy(init_model[38;5;241m.[39mstate_dict())
[1;32m     93[0m [38;5;66;03m#  æ‰“å°æ•°æ®é›†æƒ…å†µ[39;00m

File [0;32m/home/anaconda/lib/python3.8/site-packages/torch/nn/modules/module.py:927[0m, in [0;36mModule.to[0;34m(self, *args, **kwargs)[0m
[1;32m    923[0m         [38;5;28;01mreturn[39;00m t[38;5;241m.[39mto(device, dtype [38;5;28;01mif[39;00m t[38;5;241m.[39mis_floating_point() [38;5;129;01mor[39;00m t[38;5;241m.[39mis_complex() [38;5;28;01melse[39;00m [38;5;28;01mNone[39;00m,
[1;32m    924[0m                     non_blocking, memory_format[38;5;241m=[39mconvert_to_format)
[1;32m    925[0m     [38;5;28;01mreturn[39;00m t[38;5;241m.[39mto(device, dtype [38;5;28;01mif[39;00m t[38;5;241m.[39mis_floating_point() [38;5;129;01mor[39;00m t[38;5;241m.[39mis_complex() [38;5;28;01melse[39;00m [38;5;28;01mNone[39;00m, non_blocking)
[0;32m--> 927[0m [38;5;28;01mreturn[39;00m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43m_apply[49m[43m([49m[43mconvert[49m[43m)[49m

File [0;32m/home/anaconda/lib/python3.8/site-packages/torch/nn/modules/module.py:579[0m, in [0;36mModule._apply[0;34m(self, fn)[0m
[1;32m    577[0m [38;5;28;01mdef[39;00m [38;5;21m_apply[39m([38;5;28mself[39m, fn):
[1;32m    578[0m     [38;5;28;01mfor[39;00m module [38;5;129;01min[39;00m [38;5;28mself[39m[38;5;241m.[39mchildren():
[0;32m--> 579[0m         [43mmodule[49m[38;5;241;43m.[39;49m[43m_apply[49m[43m([49m[43mfn[49m[43m)[49m
[1;32m    581[0m     [38;5;28;01mdef[39;00m [38;5;21mcompute_should_use_set_data[39m(tensor, tensor_applied):
[1;32m    582[0m         [38;5;28;01mif[39;00m torch[38;5;241m.[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):
[1;32m    583[0m             [38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,[39;00m
[1;32m    584[0m             [38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,[39;00m
[0;32m   (...)[0m
[1;32m    589[0m             [38;5;66;03m# global flag to let the user control whether they want the future[39;00m
[1;32m    590[0m             [38;5;66;03m# behavior of overwriting the existing tensor or not.[39;00m

File [0;32m/home/anaconda/lib/python3.8/site-packages/torch/nn/modules/rnn.py:189[0m, in [0;36mRNNBase._apply[0;34m(self, fn)[0m
[1;32m    187[0m [38;5;28mself[39m[38;5;241m.[39m_flat_weights [38;5;241m=[39m [([38;5;28;01mlambda[39;00m wn: [38;5;28mgetattr[39m([38;5;28mself[39m, wn) [38;5;28;01mif[39;00m [38;5;28mhasattr[39m([38;5;28mself[39m, wn) [38;5;28;01melse[39;00m [38;5;28;01mNone[39;00m)(wn) [38;5;28;01mfor[39;00m wn [38;5;129;01min[39;00m [38;5;28mself[39m[38;5;241m.[39m_flat_weights_names]
[1;32m    188[0m [38;5;66;03m# Flattens params (on CUDA)[39;00m
[0;32m--> 189[0m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mflatten_parameters[49m[43m([49m[43m)[49m
[1;32m    191[0m [38;5;28;01mreturn[39;00m ret

File [0;32m/home/anaconda/lib/python3.8/site-packages/torch/nn/modules/rnn.py:175[0m, in [0;36mRNNBase.flatten_parameters[0;34m(self)[0m
[1;32m    173[0m [38;5;28;01mif[39;00m [38;5;28mself[39m[38;5;241m.[39mproj_size [38;5;241m>[39m [38;5;241m0[39m:
[1;32m    174[0m     num_weights [38;5;241m+[39m[38;5;241m=[39m [38;5;241m1[39m
[0;32m--> 175[0m [43mtorch[49m[38;5;241;43m.[39;49m[43m_cudnn_rnn_flatten_weight[49m[43m([49m
[1;32m    176[0m [43m    [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43m_flat_weights[49m[43m,[49m[43m [49m[43mnum_weights[49m[43m,[49m
[1;32m    177[0m [43m    [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43minput_size[49m[43m,[49m[43m [49m[43mrnn[49m[38;5;241;43m.[39;49m[43mget_cudnn_mode[49m[43m([49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mmode[49m[43m)[49m[43m,[49m
[1;32m    178[0m [43m    [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mhidden_size[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mproj_size[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mnum_layers[49m[43m,[49m
[1;32m    179[0m [43m    [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mbatch_first[49m[43m,[49m[43m [49m[38;5;28;43mbool[39;49m[43m([49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mbidirectional[49m[43m)[49m[43m)[49m

[0;31mRuntimeError[0m: CUDA error: no kernel image is available for execution on the device
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
RuntimeError: CUDA error: no kernel image is available for execution on the device
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.

[NbConvertApp] Converting notebook FedCLG_draft_v4.0_250211.ipynb to notebook
[NbConvertApp] Executing notebook with kernel: python3
Traceback (most recent call last):
  File "/home/anaconda/bin/jupyter-nbconvert", line 11, in <module>
    sys.exit(main())
  File "/root/.local/lib/python3.8/site-packages/jupyter_core/application.py", line 283, in launch_instance
    super().launch_instance(argv=argv, **kwargs)
  File "/root/.local/lib/python3.8/site-packages/traitlets/config/application.py", line 1075, in launch_instance
    app.start()
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 350, in start
    self.convert_notebooks()
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 524, in convert_notebooks
    self.convert_single_notebook(notebook_filename)
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 489, in convert_single_notebook
    output, resources = self.export_single_notebook(notebook_filename, resources, input_buffer=input_buffer)
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/nbconvertapp.py", line 418, in export_single_notebook
    output, resources = self.exporter.from_filename(notebook_filename, resources=resources)
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 181, in from_filename
    return self.from_file(f, resources=resources, **kw)
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 199, in from_file
    return self.from_notebook_node(nbformat.read(file_stream, as_version=4), resources=resources, **kw)
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/exporters/notebook.py", line 32, in from_notebook_node
    nb_copy, resources = super().from_notebook_node(nb, resources, **kw)
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 143, in from_notebook_node
    nb_copy, resources = self._preprocess(nb_copy, resources)
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/exporters/exporter.py", line 318, in _preprocess
    nbc, resc = preprocessor(nbc, resc)
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/preprocessors/base.py", line 47, in __call__
    return self.preprocess(nb, resources)
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/preprocessors/execute.py", line 79, in preprocess
    self.execute()
  File "/home/anaconda/lib/python3.8/site-packages/nbclient/util.py", line 74, in wrapped
    return just_run(coro(*args, **kwargs))
  File "/home/anaconda/lib/python3.8/site-packages/nbclient/util.py", line 53, in just_run
    return loop.run_until_complete(coro)
  File "/home/anaconda/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/home/anaconda/lib/python3.8/site-packages/nbclient/client.py", line 540, in async_execute
    await self.async_execute_cell(
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/preprocessors/execute.py", line 123, in async_execute_cell
    cell, resources = self.preprocess_cell(cell, self.resources, cell_index)
  File "/home/anaconda/lib/python3.8/site-packages/nbconvert/preprocessors/execute.py", line 146, in preprocess_cell
    cell = run_sync(NotebookClient.async_execute_cell)(self, cell, index, store_history=self.store_history)
  File "/home/anaconda/lib/python3.8/site-packages/nbclient/util.py", line 74, in wrapped
    return just_run(coro(*args, **kwargs))
  File "/home/anaconda/lib/python3.8/site-packages/nbclient/util.py", line 53, in just_run
    return loop.run_until_complete(coro)
  File "/root/.local/lib/python3.8/site-packages/nest_asyncio.py", line 98, in run_until_complete
    return f.result()
  File "/home/anaconda/lib/python3.8/asyncio/futures.py", line 178, in result
    raise self._exception
  File "/home/anaconda/lib/python3.8/asyncio/tasks.py", line 280, in __step
    result = coro.send(None)
  File "/home/anaconda/lib/python3.8/site-packages/nbclient/client.py", line 832, in async_execute_cell
    self._check_raise_for_error(cell, exec_reply)
  File "/home/anaconda/lib/python3.8/site-packages/nbclient/client.py", line 740, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply['content'])
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
def set_random_seed(seed):
    """
        set random seed
    """
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)


# å›ºå®šéšæœºæ•°
if random_fix:
    set_random_seed(seed)

if origin_model == 'resnet':
# å‡†å¤‡CIFAR100æ•°æ®é›†
    cifar, test_dataset = CIFAR100()
    prob = get_prob(non_iid, client_num, class_num=20)
    client_data = create_data_all_train(prob, size_per_client, cifar, N=20)   # è¿™é‡Œæ”¹ä¸ºå…¨éƒ¨æž„å»ºè®­ç»ƒé›†

    # å°†æµ‹è¯•æ ‡ç­¾è½¬æ¢ä¸ºç²—ç±»åˆ«
    test_dataset.targets = sparse2coarse(test_dataset.targets)

    # å¦‚æžœéœ€è¦ç¡®ä¿æµ‹è¯•æ ‡ç­¾ä¸ºæ•´æ•°ç±»åž‹
    test_dataset.targets = test_dataset.targets.astype(int)


    #CIFAR1--IID æŒ‘é€‰æœåŠ¡å™¨å­é›†ï¼š
    if server_iid:
        server_images, server_labels = select_server_subset(cifar, percentage=server_percentage, mode='iid')
    else:
        server_images, server_labels = select_server_subset(cifar, percentage=server_percentage,
                                                        mode='non-iid', dirichlet_alpha=0.5)

    # CIFAR100â€”â€”ç”¨äº†FedMutä¸­å®šä¹‰çš„CNNç½‘ç»œ
    init_model = ResNet18_cifar10().to(device)
    initial_w = copy.deepcopy(init_model.state_dict())
elif origin_model =='lstm':
    # å‡†å¤‡shakespeareæ•°æ®é›†
    train_dataset = ShakeSpeare(True)
    test_dataset = ShakeSpeare(False)

    total_shake,total_label = [],[]
    for item,labels in train_dataset:
        total_shake.append(item.numpy())
        total_label.append(labels)
    total_shake = np.array(total_shake)
    total_label = np.array(total_label)

    shake = [total_shake, total_label]

    # æž„å»ºæ¯ä¸ªclientçš„æ•°æ®é‡
    dict_users = train_dataset.get_client_dic()

    # ç»Ÿè®¡ç±»åˆ«æ•°é‡
    unique_classes = np.unique(total_label)
    num_classes = len(unique_classes)
    print("shakeæ•°æ®é›†ä¸­ç±»åˆ«æ•°é‡ï¼š", num_classes)
    # å¯¹äºŽæ¯ä¸ªç±»åˆ«è®¡ç®—æ ·æœ¬æ•°é‡
    class_counts = [np.sum(total_label == cls) for cls in unique_classes]
    # å°†æ•°é‡è½¬æ¢æˆå­—ç¬¦ä¸²åŽï¼Œç”¨é€—å·éš”å¼€ï¼Œå¹¶æ‰“å°ï¼ˆåªè¾“å‡ºæ•°å­—ï¼‰
    print(", ".join(map(str, class_counts)))

    # ç»Ÿè®¡å®¢æˆ·ç«¯æ•°é‡
    num_clients = len(dict_users)
    print("shakeæ•°æ®é›†ä¸­å®¢æˆ·ç«¯æ•°é‡ï¼š", num_clients)


    # æž„å»ºclient_data
    client_data = []
    for client in sorted(dict_users.keys()):
        indices = np.array(list(dict_users[client]), dtype=np.int64)
        client_images = total_shake[indices]
        client_labels = total_label[indices]
        client_data.append((client_images, client_labels))


    # Shake æŒ‘é€‰æœåŠ¡å™¨å­é›†ï¼Œé€šè¿‡ Dirichlet åˆ†å¸ƒå‚æ•°æŽ§åˆ¶ï¼ˆä¾‹å¦‚ dirichlet_alpha=0.5ï¼‰ï¼š
    if server_iid:
        server_images, server_labels = select_server_subset(shake, percentage=server_percentage,
                                                      mode='iid')
    else:
        server_images, server_labels = select_server_subset(shake, percentage=server_percentage,
                                                        mode='non-iid', dirichlet_alpha=0.5)


    # Shakespeare â€”â€” ç”¨FedMutä¸­æå‡ºçš„LSTMç½‘ç»œ
    init_model = CharLSTM().to(device)
    initial_w = copy.deepcopy(init_model.state_dict())


#  æ‰“å°æ•°æ®é›†æƒ…å†µ
all_images = []
all_labels = []
for data in client_data:
    all_images.extend(data[0])
    all_labels.extend(data[1])
comb_client_data = [np.array(all_images), np.array(all_labels)]

# è¾“å‡ºcomb_client_dataæƒ…å†µ
imgs, lbls = comb_client_data
lbls = np.array(lbls)
total_count = len(lbls)
unique_classes, counts = np.unique(lbls, return_counts=True)

num_classes = int(unique_classes.max()) + 1  # åˆ—è¡¨é•¿åº¦åº”è¯¥ä¸ºæœ€å¤§ç±»åˆ«
class_counts = [0] * num_classes

for cls, cnt in zip(unique_classes, counts):
    class_counts[cls] = cnt

# æ‰“å°æ ¼å¼ï¼šTotal: æ€»æ•° ç±»åˆ«0è®¡æ•° ç±»åˆ«1è®¡æ•° ... ç±»åˆ«19è®¡æ•°
print("Traning Client Total: {}".format(" ".join([str(total_count)] + [str(c) for c in class_counts])))


# æ‰“å°æ¯ä¸ªå®¢æˆ·ç«¯è®­ç»ƒæ•°æ®æƒ…å†µï¼ˆåªè¾“å‡ºå‰10ä¸ªï¼‰
for i, (imgs, lbls) in enumerate(client_data[:10]):
    lbls = np.array(lbls)
    total_count = len(lbls)
    unique_classes, counts = np.unique(lbls, return_counts=True)
    
    num_classes = int(unique_classes.max()) + 1  # åˆ—è¡¨é•¿åº¦åº”è¯¥ä¸ºæœ€å¤§ç±»åˆ«
    class_counts = [0] * num_classes
    
    for cls, cnt in zip(unique_classes, counts):
        class_counts[cls] = cnt
    # æ‰“å°æ ¼å¼ï¼šClient i: æ€»æ•° ç±»åˆ«0è®¡æ•° ç±»åˆ«1è®¡æ•° ... ç±»åˆ«19è®¡æ•°
    print("Client {}: {}".format(i, " ".join([str(total_count)] + [str(c) for c in class_counts])))
    

# ä¸ºäº†ä¸ŽåŽç»­ä»£ç å…¼å®¹ï¼Œè¿™é‡Œå°† server_data å®šä¹‰ä¸ºä¸€ä¸ªåˆ—è¡¨ï¼š[images, labels]
server_data = [server_images, server_labels]

# æ‰“å°æœåŠ¡å™¨æ•°æ®æƒ…å†µ
s_imgs, s_lbls = server_data
s_lbls = np.array(s_lbls)
total_count = len(s_lbls)
unique_classes, counts = np.unique(s_lbls, return_counts=True)

num_classes = int(unique_classes.max()) + 1  # åˆ—è¡¨é•¿åº¦åº”è¯¥ä¸ºæœ€å¤§ç±»åˆ«+1
class_counts = [0] * num_classes

for cls, cnt in zip(unique_classes, counts):
    class_counts[cls] = cnt
# è¾“å‡ºæ ¼å¼: Server: æ€»æ•° ç±»åˆ«0è®¡æ•° ç±»åˆ«1è®¡æ•° ... ç±»åˆ«19è®¡æ•°
print("Server: {}".format(" ".join([str(total_count)] + [str(c) for c in class_counts])))
# print("  å‰5ä¸ªæ ‡ç­¾: ", lbls[:5])
# print("  å‰5ä¸ªæ•°æ®å½¢çŠ¶: ", [server_data[0][j].shape for j in range(min(5, len(server_data[0])))])




# åˆå§‹åŒ–ç»“æžœå­˜å‚¨å­—å…¸
results_test_acc = {}
results_train_loss = {}

# CLG_Mut è®­ç»ƒ
test_acc_CLG_Mut, train_loss_CLG_Mut = CLG_Mut(copy.deepcopy(init_model), global_round, eta, gamma, K, E, M)
results_test_acc['CLG_Mut'] = test_acc_CLG_Mut
results_train_loss['CLG_Mut'] = train_loss_CLG_Mut

# CLG_Mut_2 è®­ç»ƒ
test_acc_CLG_Mut_2, train_loss_CLG_Mut_2 = CLG_Mut_2(copy.deepcopy(init_model), global_round, eta, gamma, K, E, M)
results_test_acc['CLG_Mut_2'] = test_acc_CLG_Mut_2
results_train_loss['CLG_Mut_2'] = train_loss_CLG_Mut_2

# CLG_Mut_3 è®­ç»ƒ
test_acc_CLG_Mut_3, train_loss_CLG_Mut_3 = CLG_Mut_3(copy.deepcopy(init_model), global_round, eta, gamma, K, E, M)
results_test_acc['CLG_Mut_3'] = test_acc_CLG_Mut_3
results_train_loss['CLG_Mut_3'] = train_loss_CLG_Mut_3


# FedMut è®­ç»ƒ
test_acc_FedMut, train_loss_FedMut = FedMut(copy.deepcopy(init_model), global_round, eta, K, M)
results_test_acc['FedMut'] = test_acc_FedMut
results_train_loss['FedMut'] = train_loss_FedMut

# Server-only è®­ç»ƒ
test_acc_server_only, train_loss_server_only = server_only(initial_w, global_round, gamma, E)
results_test_acc['Server_only'] = test_acc_server_only
results_train_loss['Server_only'] = train_loss_server_only

# FedAvg è®­ç»ƒ
test_acc_fedavg, train_loss_fedavg = fedavg(initial_w, global_round, eta, K, M)
results_test_acc['FedAvg'] = test_acc_fedavg
results_train_loss['FedAvg'] = train_loss_fedavg

# CLG_SGD è®­ç»ƒ
test_acc_CLG_SGD, train_loss_CLG_SGD = CLG_SGD(initial_w, global_round, eta, gamma, K, E, M)
results_test_acc['CLG_SGD'] = test_acc_CLG_SGD
results_train_loss['CLG_SGD'] = train_loss_CLG_SGD

# æ‰“å°è®­ç»ƒç»“æžœï¼ˆå¯é€‰ï¼‰
for algo in results_test_acc:
    print(f"{algo} - æœ€ç»ˆæµ‹è¯•ç²¾åº¦: {results_test_acc[algo][-1]:.2f}%, æœ€ç»ˆè®­ç»ƒæŸå¤±: {results_train_loss[algo][-1]:.4f}")

------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mRuntimeError[0m                              Traceback (most recent call last)
Cell [0;32mIn[1], line 89[0m
[1;32m     84[0m         server_images, server_labels [38;5;241m=[39m select_server_subset(shake, percentage[38;5;241m=[39mserver_percentage,
[1;32m     85[0m                                                         mode[38;5;241m=[39m[38;5;124m'[39m[38;5;124mnon-iid[39m[38;5;124m'[39m, dirichlet_alpha[38;5;241m=[39m[38;5;241m0.5[39m)
[1;32m     88[0m     [38;5;66;03m# Shakespeare â€”â€” ç”¨FedMutä¸­æå‡ºçš„LSTMç½‘ç»œ[39;00m
[0;32m---> 89[0m     init_model [38;5;241m=[39m [43mCharLSTM[49m[43m([49m[43m)[49m[38;5;241;43m.[39;49m[43mto[49m[43m([49m[43mdevice[49m[43m)[49m
[1;32m     90[0m     initial_w [38;5;241m=[39m copy[38;5;241m.[39mdeepcopy(init_model[38;5;241m.[39mstate_dict())
[1;32m     93[0m [38;5;66;03m#  æ‰“å°æ•°æ®é›†æƒ…å†µ[39;00m

File [0;32m/home/anaconda/lib/python3.8/site-packages/torch/nn/modules/module.py:927[0m, in [0;36mModule.to[0;34m(self, *args, **kwargs)[0m
[1;32m    923[0m         [38;5;28;01mreturn[39;00m t[38;5;241m.[39mto(device, dtype [38;5;28;01mif[39;00m t[38;5;241m.[39mis_floating_point() [38;5;129;01mor[39;00m t[38;5;241m.[39mis_complex() [38;5;28;01melse[39;00m [38;5;28;01mNone[39;00m,
[1;32m    924[0m                     non_blocking, memory_format[38;5;241m=[39mconvert_to_format)
[1;32m    925[0m     [38;5;28;01mreturn[39;00m t[38;5;241m.[39mto(device, dtype [38;5;28;01mif[39;00m t[38;5;241m.[39mis_floating_point() [38;5;129;01mor[39;00m t[38;5;241m.[39mis_complex() [38;5;28;01melse[39;00m [38;5;28;01mNone[39;00m, non_blocking)
[0;32m--> 927[0m [38;5;28;01mreturn[39;00m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43m_apply[49m[43m([49m[43mconvert[49m[43m)[49m

File [0;32m/home/anaconda/lib/python3.8/site-packages/torch/nn/modules/module.py:579[0m, in [0;36mModule._apply[0;34m(self, fn)[0m
[1;32m    577[0m [38;5;28;01mdef[39;00m [38;5;21m_apply[39m([38;5;28mself[39m, fn):
[1;32m    578[0m     [38;5;28;01mfor[39;00m module [38;5;129;01min[39;00m [38;5;28mself[39m[38;5;241m.[39mchildren():
[0;32m--> 579[0m         [43mmodule[49m[38;5;241;43m.[39;49m[43m_apply[49m[43m([49m[43mfn[49m[43m)[49m
[1;32m    581[0m     [38;5;28;01mdef[39;00m [38;5;21mcompute_should_use_set_data[39m(tensor, tensor_applied):
[1;32m    582[0m         [38;5;28;01mif[39;00m torch[38;5;241m.[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):
[1;32m    583[0m             [38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,[39;00m
[1;32m    584[0m             [38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,[39;00m
[0;32m   (...)[0m
[1;32m    589[0m             [38;5;66;03m# global flag to let the user control whether they want the future[39;00m
[1;32m    590[0m             [38;5;66;03m# behavior of overwriting the existing tensor or not.[39;00m

File [0;32m/home/anaconda/lib/python3.8/site-packages/torch/nn/modules/rnn.py:189[0m, in [0;36mRNNBase._apply[0;34m(self, fn)[0m
[1;32m    187[0m [38;5;28mself[39m[38;5;241m.[39m_flat_weights [38;5;241m=[39m [([38;5;28;01mlambda[39;00m wn: [38;5;28mgetattr[39m([38;5;28mself[39m, wn) [38;5;28;01mif[39;00m [38;5;28mhasattr[39m([38;5;28mself[39m, wn) [38;5;28;01melse[39;00m [38;5;28;01mNone[39;00m)(wn) [38;5;28;01mfor[39;00m wn [38;5;129;01min[39;00m [38;5;28mself[39m[38;5;241m.[39m_flat_weights_names]
[1;32m    188[0m [38;5;66;03m# Flattens params (on CUDA)[39;00m
[0;32m--> 189[0m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mflatten_parameters[49m[43m([49m[43m)[49m
[1;32m    191[0m [38;5;28;01mreturn[39;00m ret

File [0;32m/home/anaconda/lib/python3.8/site-packages/torch/nn/modules/rnn.py:175[0m, in [0;36mRNNBase.flatten_parameters[0;34m(self)[0m
[1;32m    173[0m [38;5;28;01mif[39;00m [38;5;28mself[39m[38;5;241m.[39mproj_size [38;5;241m>[39m [38;5;241m0[39m:
[1;32m    174[0m     num_weights [38;5;241m+[39m[38;5;241m=[39m [38;5;241m1[39m
[0;32m--> 175[0m [43mtorch[49m[38;5;241;43m.[39;49m[43m_cudnn_rnn_flatten_weight[49m[43m([49m
[1;32m    176[0m [43m    [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43m_flat_weights[49m[43m,[49m[43m [49m[43mnum_weights[49m[43m,[49m
[1;32m    177[0m [43m    [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43minput_size[49m[43m,[49m[43m [49m[43mrnn[49m[38;5;241;43m.[39;49m[43mget_cudnn_mode[49m[43m([49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mmode[49m[43m)[49m[43m,[49m
[1;32m    178[0m [43m    [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mhidden_size[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mproj_size[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mnum_layers[49m[43m,[49m
[1;32m    179[0m [43m    [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mbatch_first[49m[43m,[49m[43m [49m[38;5;28;43mbool[39;49m[43m([49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mbidirectional[49m[43m)[49m[43m)[49m

[0;31mRuntimeError[0m: CUDA error: no kernel image is available for execution on the device
RuntimeError: CUDA error: no kernel image is available for execution on the device

