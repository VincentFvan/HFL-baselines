{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "gSK1TSekTVeu"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.functional as func\n",
    "import collections\n",
    "import config\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "9-WEXWakTwf8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True' # 解决由于多次加载 OpenMP 相关动态库而引起的冲突"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sns3blEITybc",
    "outputId": "120095fb-5597-4ada-8c12-b4470d8ad28e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec 17 17:06:55 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090        Off | 00000000:21:00.0 Off |                  Off |\n",
      "| 35%   45C    P2              74W / 350W |   2403MiB / 24564MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 4090        Off | 00000000:E1:00.0 Off |                  Off |\n",
      "| 30%   30C    P8              14W / 350W |     14MiB / 24564MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      4557      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "|    0   N/A  N/A   1469342      C   /home/anaconda/envs/env8/bin/python        2386MiB |\n",
      "|    1   N/A  N/A      4557      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "96gqMCQneWho"
   },
   "outputs": [],
   "source": [
    "# MobileNetV2（比lenet更复杂的CNN网络）网络中的线性瓶颈结构，原文中用于CIFAR-100任务\n",
    "class LinearBottleNeck(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride, t=6, class_num=100):\n",
    "        super().__init__()\n",
    "\n",
    "        self.residual = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels * t, 1),\n",
    "            nn.BatchNorm2d(in_channels * t),\n",
    "            nn.ReLU6(inplace=True),\n",
    "\n",
    "            nn.Conv2d(in_channels * t, in_channels * t, 3, stride=stride, padding=1, groups=in_channels * t),\n",
    "            nn.BatchNorm2d(in_channels * t),\n",
    "            nn.ReLU6(inplace=True),\n",
    "\n",
    "            nn.Conv2d(in_channels * t, out_channels, 1),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "\n",
    "        self.stride = stride\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        residual = self.residual(x)\n",
    "\n",
    "        if self.stride == 1 and self.in_channels == self.out_channels:\n",
    "            residual += x\n",
    "\n",
    "        return residual\n",
    "\n",
    "class MobileNetV2(nn.Module):\n",
    "\n",
    "    def __init__(self, class_num=20):\n",
    "        super().__init__()\n",
    "\n",
    "        self.pre = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU6(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.stage1 = LinearBottleNeck(32, 16, 1, 1)\n",
    "        self.stage2 = self._make_stage(2, 16, 24, 2, 6)\n",
    "        self.stage3 = self._make_stage(3, 24, 32, 2, 6)\n",
    "        self.stage4 = self._make_stage(4, 32, 64, 2, 6)\n",
    "        self.stage5 = self._make_stage(3, 64, 96, 1, 6)\n",
    "        self.stage6 = self._make_stage(3, 96, 160, 1, 6)\n",
    "        self.stage7 = LinearBottleNeck(160, 320, 1, 6)\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(320, 1280, 1),\n",
    "            nn.BatchNorm2d(1280),\n",
    "            nn.ReLU6(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Conv2d(1280, class_num, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pre(x)\n",
    "        x = self.stage1(x)\n",
    "        x = self.stage2(x)\n",
    "        x = self.stage3(x)\n",
    "        x = self.stage4(x)\n",
    "        x = self.stage5(x)\n",
    "        x = self.stage6(x)\n",
    "        x = self.stage7(x)\n",
    "        x = self.conv1(x)\n",
    "        x = F.adaptive_avg_pool2d(x, 1)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _make_stage(self, repeat, in_channels, out_channels, stride, t):\n",
    "\n",
    "        layers = []\n",
    "        layers.append(LinearBottleNeck(in_channels, out_channels, stride, t))\n",
    "\n",
    "        while repeat - 1:\n",
    "            layers.append(LinearBottleNeck(out_channels, out_channels, 1, t))\n",
    "            repeat -= 1\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "def mobilenetv2():\n",
    "    return MobileNetV2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "QkvtGtMuUDmr"
   },
   "outputs": [],
   "source": [
    "def test_inference(model, test):\n",
    "    \"\"\" Returns the test accuracy and loss.\n",
    "    \"\"\"\n",
    "    tensor_x = torch.Tensor(test[0]).to(device)\n",
    "    tensor_y = torch.Tensor(test[1]).to(device)\n",
    "    test_dataset = TensorDataset(tensor_x, tensor_y)\n",
    "\n",
    "    model.eval()\n",
    "    loss, total, correct = 0.0, 0.0, 0.0\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    testloader = DataLoader(test_dataset, batch_size=128,\n",
    "                            shuffle=True)\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(testloader):\n",
    "        with torch.no_grad():  # 在测试过程中不需要计算梯度，节省内存和加速计算\n",
    "        # Inference\n",
    "            outputs = model(images)\n",
    "            batch_loss = criterion(outputs, labels.long())\n",
    "            loss += batch_loss.item() * labels.size(0) # 计算损失值，更好反映模型输出概率分布与真实标签的差距\n",
    "\n",
    "        # Prediction\n",
    "            _, pred_labels = torch.max(outputs, 1)\n",
    "            pred_labels = pred_labels.view(-1)\n",
    "            correct += torch.sum(torch.eq(pred_labels, labels)).item()\n",
    "            total += len(labels)\n",
    "    #print(correct,\"/\",total)\n",
    "    accuracy = correct/total\n",
    "    return accuracy, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "jURskA9VUJOF"
   },
   "outputs": [],
   "source": [
    "# 将CIFAR-100的100个类别转为20个类别（粒度更粗，降低任务复杂度）\n",
    "def sparse2coarse(targets):\n",
    "    \"\"\"Convert Pytorch CIFAR100 sparse targets to coarse targets.\n",
    "\n",
    "    Usage:\n",
    "        trainset = torchvision.datasets.CIFAR100(path)\n",
    "        trainset.targets = sparse2coarse(trainset.targets)\n",
    "    \"\"\"\n",
    "    coarse_labels = np.array([ 4,  1, 14,  8,  0,  6,  7,  7, 18,  3,\n",
    "                               3, 14,  9, 18,  7, 11,  3,  9,  7, 11,\n",
    "                               6, 11,  5, 10,  7,  6, 13, 15,  3, 15,\n",
    "                               0, 11,  1, 10, 12, 14, 16,  9, 11,  5,\n",
    "                               5, 19,  8,  8, 15, 13, 14, 17, 18, 10,\n",
    "                               16, 4, 17,  4,  2,  0, 17,  4, 18, 17,\n",
    "                               10, 3,  2, 12, 12, 16, 12,  1,  9, 19,\n",
    "                               2, 10,  0,  1, 16, 12,  9, 13, 15, 13,\n",
    "                              16, 19,  2,  4,  6, 19,  5,  5,  8, 19,\n",
    "                              18,  1,  2, 15,  6,  0, 17,  8, 14, 13])\n",
    "    return coarse_labels[targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "jcZ7eQGET_YJ"
   },
   "outputs": [],
   "source": [
    "# 共有6w个图像，其中5w训练，1w测试\n",
    "def CIFAR100():\n",
    "    '''Return Cifar100\n",
    "    '''\n",
    "    train_dataset = torchvision.datasets.CIFAR100(root='../data/CIFAR-100',\n",
    "                                            train=True,\n",
    "                                            transform=transforms.ToTensor(),\n",
    "                                            download=True)\n",
    "    test_dataset = torchvision.datasets.CIFAR100(root='../data/CIFAR-100',\n",
    "                                            train=False,\n",
    "                                            transform=transforms.ToTensor(),\n",
    "                                            download=True)\n",
    "    total_img,total_label = [],[]\n",
    "    for imgs,labels in train_dataset:\n",
    "        total_img.append(imgs.numpy())\n",
    "        total_label.append(labels)\n",
    "    for imgs,labels in test_dataset:\n",
    "        total_img.append(imgs.numpy())\n",
    "        total_label.append(labels) \n",
    "    total_img = np.array(total_img)\n",
    "    total_label = np.array(sparse2coarse(total_label))\n",
    "\n",
    "    cifar = [total_img, total_label]\n",
    "    return cifar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "f1eQhNtPUMOF"
   },
   "outputs": [],
   "source": [
    "# 基于 Dirichlet 分布 来模拟non-IID。返回一个形状为 (client_num, class_num) 的概率矩阵，每一行代表一个客户端对各类别的概率分布。\n",
    "def get_prob(non_iid, client_num, class_num = 20):\n",
    "    # Modify：我之后加上的\n",
    "    if data_random_fix:\n",
    "        np.random.seed(seed_num)  # 固定种子，确保数据抽样一致\n",
    "    \n",
    "    return np.random.dirichlet(np.repeat(non_iid, class_num), client_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "npT3idE-UaGm"
   },
   "outputs": [],
   "source": [
    "def create_data(prob, size_per_client, dataset, N=20):\n",
    "    total_each_class = size_per_client * np.sum(prob, 0)\n",
    "    data, label = dataset\n",
    "\n",
    "    # Modify：我之后加上的\n",
    "    if data_random_fix:\n",
    "        np.random.seed(seed_num)  # 固定种子，确保数据抽样一致\n",
    "        random.seed(seed_num)\n",
    "\n",
    "    # 为每个类别随机采样数据\n",
    "    all_class_set = []\n",
    "    for i in range(N):\n",
    "        size = total_each_class[i]\n",
    "        sub_data = data[label == i]\n",
    "        sub_label = label[label == i]\n",
    "\n",
    "        rand_indx = np.random.choice(len(sub_data), size=int(size), replace=False).astype(int)\n",
    "        sub2_data, sub2_label = sub_data[rand_indx], sub_label[rand_indx]\n",
    "        all_class_set.append((sub2_data, sub2_label))\n",
    "\n",
    "    index = [0] * N\n",
    "    clients, test = [], []\n",
    "\n",
    "    for m in range(prob.shape[0]):  # 遍历客户端\n",
    "        labels, images = [], []  # 训练数据\n",
    "        tlabels, timages = [], [] # 测试数据\n",
    "\n",
    "        # TODO_241216：这里每个client的测试集和它的训练集分布相同，并且最后测试时，也是计算所有client中的准确率的平均值\n",
    "        # TODO_241216：别的FL方法也是这样做的吗？我也要这样做吗？\n",
    "        for n in range(N):\n",
    "            # 80%用于训练，20%用于测试\n",
    "            # 这里的int向下取整，会导致实际的数据量比计算略小\n",
    "            start, end = index[n], index[n] + int(prob[m][n] * size_per_client * 0.8)\n",
    "            test_start, test_end = end, index[n] + int(prob[m][n] * size_per_client)\n",
    "\n",
    "            image, label = all_class_set[n][0][start:end], all_class_set[n][1][start:end]\n",
    "            test_image, test_label = all_class_set[n][0][test_start:test_end], all_class_set[n][1][test_start:test_end]\n",
    "\n",
    "            # 记录当前类别的数据分配进度\n",
    "            index[n] += int(prob[m][n] * size_per_client)\n",
    "\n",
    "            labels.extend(label)\n",
    "            images.extend(image)\n",
    "\n",
    "            tlabels.extend(test_label)\n",
    "            timages.extend(test_image)\n",
    "\n",
    "        clients.append((np.array(images), np.array(labels)))\n",
    "        test.append((np.array(timages), np.array(tlabels)))\n",
    "\n",
    "    return clients, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "DCsR6_QqUzJ8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# 合并所有客户端的测试数据 （上面讲测试数据分成了不同的客户端）\n",
    "# 但并没有使用，用途不明\n",
    "def comb_client_test_func(client_test_data):\n",
    "    comb_client_test_image = []\n",
    "    comb_client_test_label = []\n",
    "    for i in range(client_num):\n",
    "        comb_client_test_image.extend(list(client_test_data[i][0]))\n",
    "        comb_client_test_label.extend(list(client_test_data[i][1]))\n",
    "    \n",
    "    # 将测试图片和标签合并为 numpy 数组\n",
    "    comb_client_test_image = np.array(comb_client_test_image)\n",
    "    comb_client_test_label = np.array(comb_client_test_label)\n",
    "    \n",
    "    label_count = Counter(comb_client_test_label)\n",
    "    print(\"测试集类别分布：\")\n",
    "    for label, count in sorted(label_count.items()):\n",
    "        print(f\"类别 {label}: {count} 个样本\")\n",
    "    \n",
    "    return [comb_client_test_image, comb_client_test_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "JEKzDM0yW3DW"
   },
   "outputs": [],
   "source": [
    "# 从数据集中按类别均匀抽取子集，并按照指定的比例 percentage 进行缩减，同时对数据进行随机打乱\n",
    "def select_subset(whole_set, percentage):\n",
    "    \n",
    "    # Modify：我之后加上的\n",
    "    if data_random_fix:\n",
    "        np.random.seed(seed_num)  # 固定种子，确保数据抽样一致\n",
    "        random.seed(seed_num)\n",
    "    \n",
    "    a = whole_set[0]\n",
    "    b = whole_set[1]\n",
    "    if len(a) != len(b):\n",
    "        raise ValueError(\"Both arrays should have the same length.\")\n",
    "\n",
    "    if not 0 <= percentage <= 1:\n",
    "        raise ValueError(\"Percentage must be between 0 and 1.\")\n",
    "\n",
    "    unique_classes = np.unique(b)\n",
    "\n",
    "    a_prime = []\n",
    "    b_prime = []\n",
    "\n",
    "    for cls in unique_classes:\n",
    "        indices = np.where(b == cls)[0]\n",
    "        subset_size = int(len(indices) * percentage)\n",
    "\n",
    "        selected_indices = np.random.choice(indices, subset_size, replace=False)\n",
    "\n",
    "        a_prime.extend(a[selected_indices])\n",
    "        b_prime.extend(b[selected_indices])\n",
    "\n",
    "    a_prime, b_prime = np.array(a_prime), np.array(b_prime)\n",
    "\n",
    "    # Shuffle arrays to randomize the order of elements\n",
    "    shuffle_indices = np.random.permutation(len(a_prime))\n",
    "    a_prime, b_prime = a_prime[shuffle_indices], b_prime[shuffle_indices]\n",
    "\n",
    "    return [a_prime, b_prime]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "False\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Traning Client Total: 30228 1777 1490 1282 1448 1526 1590 1675 1443 1436 1555 1438 1543 1522 1447 1545 1304 1528 1563 1581 1535\n",
      "Client 0: 153 0 17 1 6 22 0 5 0 29 0 0 1 1 14 0 10 12 4 21 10\n",
      "Client 1: 152 0 1 0 3 0 1 0 12 10 3 0 40 3 11 39 0 26 0 3 0\n",
      "Client 2: 151 1 2 0 0 1 8 1 18 7 13 0 2 6 2 18 18 10 1 42 1\n",
      "Client 3: 152 0 45 4 3 4 0 3 2 0 9 2 3 0 1 1 0 19 26 26 4\n",
      "Client 4: 150 10 0 2 1 27 1 0 1 9 0 5 12 12 38 2 8 0 0 3 19\n",
      "Client 5: 151 12 1 2 10 20 5 5 3 41 17 0 8 3 2 0 1 3 0 8 10\n",
      "Client 6: 152 0 5 0 9 1 66 1 3 9 0 2 12 0 24 1 1 15 0 1 2\n",
      "Client 7: 155 0 1 23 5 1 5 15 0 32 2 0 35 1 0 20 0 2 0 13 0\n",
      "Client 8: 152 5 1 8 2 1 26 13 21 0 0 5 2 0 0 21 0 0 13 34 0\n",
      "Client 9: 152 4 8 6 3 33 2 35 0 0 8 2 0 0 10 10 0 0 9 12 10\n",
      "Client 0 Test: 38 0 4 0 1 5 0 1 0 7 0 1 1 0 4 0 2 3 1 6 2\n",
      "Client 1 Test: 39 0 0 1 0 0 1 0 4 3 1 0 10 0 2 10 0 6 0 1 0\n",
      "Client 2 Test: 39 0 0 1 0 0 3 0 4 2 4 0 0 2 1 4 5 3 0 10 0\n",
      "Client 3 Test: 40 0 12 1 1 1 0 1 1 0 2 0 1 0 1 0 0 5 6 6 2\n",
      "Client 4 Test: 41 3 1 1 0 7 1 0 0 3 0 1 3 3 9 1 2 0 0 1 5\n",
      "Client 5 Test: 40 3 0 1 3 6 2 2 0 10 4 0 2 0 0 0 1 1 0 3 2\n",
      "Client 6 Test: 41 0 1 0 3 0 17 1 1 2 0 1 3 0 6 1 0 3 1 0 1\n",
      "Client 7 Test: 35 0 0 5 1 0 1 4 0 8 0 0 8 0 0 5 0 0 0 3 0\n",
      "Client 8 Test: 40 1 1 2 0 0 7 3 5 0 1 2 1 0 0 5 0 0 3 9 0\n",
      "Client 9 Test: 40 1 2 2 1 8 1 9 0 0 2 1 0 0 2 2 0 0 3 3 3\n",
      "Server <built-in function round>: 292 17 14 12 14 15 15 16 14 14 15 14 15 15 14 15 13 15 15 15 15\n"
     ]
    }
   ],
   "source": [
    "# 准备数据集\n",
    "# 这部分是我加的\n",
    "\n",
    "cifar = CIFAR100()\n",
    "prob = get_prob(non_iid, client_num, class_num=20)\n",
    "client_data, client_test_data = create_data(prob, size_per_client, cifar, N=20)\n",
    "\n",
    "\n",
    "all_images = []\n",
    "all_labels = []\n",
    "for data in client_data:\n",
    "    all_images.extend(data[0])\n",
    "    all_labels.extend(data[1])\n",
    "comb_client_data = [np.array(all_images), np.array(all_labels)]\n",
    "\n",
    "# 输出cpmb_client_data情况\n",
    "imgs, lbls = comb_client_data\n",
    "lbls = np.array(lbls)\n",
    "total_count = len(lbls)\n",
    "unique_classes, counts = np.unique(lbls, return_counts=True)\n",
    "\n",
    "# 创建一个长度为20的数组记录各类别计数，默认0\n",
    "class_counts = [0]*20\n",
    "for cls, cnt in zip(unique_classes, counts):\n",
    "    class_counts[cls] = cnt\n",
    "\n",
    "# 打印格式：Total: 总数 类别0计数 类别1计数 ... 类别19计数\n",
    "print(\"Traning Client Total: {}\".format(\" \".join([str(total_count)] + [str(c) for c in class_counts])))\n",
    "\n",
    "\n",
    "# 打印每个客户端训练数据情况（只输出前10个）\n",
    "for i, (imgs, lbls) in enumerate(client_data[:10]):\n",
    "    lbls = np.array(lbls)\n",
    "    total_count = len(lbls)\n",
    "    unique_classes, counts = np.unique(lbls, return_counts=True)\n",
    "    # 创建一个长度为20的数组记录各类别计数，默认0\n",
    "    class_counts = [0]*20\n",
    "    for cls, cnt in zip(unique_classes, counts):\n",
    "        class_counts[cls] = cnt\n",
    "    # 打印格式：Client i: 总数 类别0计数 类别1计数 ... 类别19计数\n",
    "    print(\"Client {}: {}\".format(i, \" \".join([str(total_count)] + [str(c) for c in class_counts])))\n",
    "    # 打印前5个数据和标签\n",
    "    # print(\"  前5个标签: \", lbls[:5])\n",
    "    # print(\"  前5个数据形状: \", [imgs[j].shape for j in range(min(5, len(imgs)))])\n",
    "    # print()\n",
    "    \n",
    "\n",
    "# 打印每个客户端测试数据情况（只输出前10个）\n",
    "for i, (imgs, lbls) in enumerate(client_test_data[:10]):\n",
    "    lbls = np.array(lbls)\n",
    "    total_count = len(lbls)\n",
    "    unique_classes, counts = np.unique(lbls, return_counts=True)\n",
    "    class_counts = [0]*20\n",
    "    for cls, cnt in zip(unique_classes, counts):\n",
    "        class_counts[cls] = cnt\n",
    "    # 打印格式：Client i Test: 总数 类别0计数 类别1计数 ... 类别19计数\n",
    "    print(\"Client {} Test: {}\".format(i, \" \".join([str(total_count)] + [str(c) for c in class_counts])))\n",
    "    # 打印前5个数据和标签\n",
    "    # print(\"  前5个标签: \", lbls[:5])\n",
    "    # print(\"  前5个数据形状: \", [imgs[j].shape for j in range(min(5, len(imgs)))])\n",
    "    # print()\n",
    "\n",
    "# 提前生成固定的服务器数据\n",
    "# Modify: 这是我后来修改的\n",
    "server_data = select_subset(comb_client_data, server_percentage)\n",
    "\n",
    "s_imgs, s_lbls = server_data\n",
    "s_lbls = np.array(s_lbls)\n",
    "total_count = len(s_lbls)\n",
    "unique_classes, counts = np.unique(s_lbls, return_counts=True)\n",
    "class_counts = [0]*20\n",
    "for cls, cnt in zip(unique_classes, counts):\n",
    "    class_counts[cls] = cnt\n",
    "\n",
    "# 输出格式: Server round: 总数 类别0计数 类别1计数 ... 类别19计数\n",
    "print(\"Server {}: {}\".format(round, \" \".join([str(total_count)] + [str(c) for c in class_counts])))\n",
    "# print(\"  前5个标签: \", lbls[:5])\n",
    "# print(\"  前5个数据形状: \", [server_data[0][j].shape for j in range(min(5, len(server_data[0])))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "XvuicdZfeDvL"
   },
   "outputs": [],
   "source": [
    "# 本地训练并更新权重，返回更新后的模型权重、平均训练损失以及第一个迭代的梯度信息\n",
    "def update_weights(model_weight, dataset, learning_rate, local_epoch):\n",
    "    model = mobilenetv2().to(device)\n",
    "    model.load_state_dict(model_weight)\n",
    "\n",
    "    model.train()\n",
    "    epoch_loss = []\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    Tensor_set = TensorDataset(torch.Tensor(dataset[0]).to(device), torch.Tensor(dataset[1]).to(device))\n",
    "    data_loader = DataLoader(Tensor_set, batch_size=128, shuffle=True)\n",
    "\n",
    "    first_iter_gradient = None  # 初始化变量来保存第一个iter的梯度\n",
    "\n",
    "    for iter in range(local_epoch):\n",
    "        batch_loss = []\n",
    "        for batch_idx, (images, labels) in enumerate(data_loader):\n",
    "            model.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels.long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            batch_loss.append(loss.item()/images.shape[0])\n",
    "\n",
    "            # 保存第一个iter的梯度\n",
    "            if iter == 0 and batch_idx == 0:\n",
    "                first_iter_gradient = {}\n",
    "                for name, param in model.named_parameters():\n",
    "                    first_iter_gradient[name] = param.grad.clone()\n",
    "                # 保存 BatchNorm 层的 running mean 和 running variance\n",
    "                for name, module in model.named_modules():\n",
    "                    if isinstance(module, nn.BatchNorm2d):\n",
    "                        first_iter_gradient[name + '.running_mean'] = module.running_mean.clone()\n",
    "                        first_iter_gradient[name + '.running_var'] = module.running_var.clone()\n",
    "\n",
    "        epoch_loss.append(sum(batch_loss)/len(batch_loss))\n",
    "\n",
    "    return model.state_dict(), sum(epoch_loss) / len(epoch_loss), first_iter_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "qsPZGD4Iem5w"
   },
   "outputs": [],
   "source": [
    "# 计算模型权重的差异，并根据学习率 lr 对权重差异进行缩放\n",
    "def weight_differences(n_w, p_w, lr):\n",
    "    w_diff = copy.deepcopy(n_w)\n",
    "    for key in w_diff.keys():\n",
    "        if 'num_batches_tracked' in key:\n",
    "            continue\n",
    "        w_diff[key] = (p_w[key] - n_w[key]) * lr\n",
    "    return w_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "040d862vbG9M"
   },
   "outputs": [],
   "source": [
    "# 也是本地训练，不过引入了本文的权重修正机制\n",
    "def update_weights_correction(model_weight, dataset, learning_rate, local_epoch, c_i, c_s):\n",
    "    model = mobilenetv2().to(device)\n",
    "    model.load_state_dict(model_weight)\n",
    "\n",
    "    model.train()\n",
    "    epoch_loss = []\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    Tensor_set = TensorDataset(torch.Tensor(dataset[0]).to(device), torch.Tensor(dataset[1]).to(device))\n",
    "    data_loader = DataLoader(Tensor_set, batch_size=200, shuffle=True)\n",
    "\n",
    "    for iter in range(local_epoch):\n",
    "        batch_loss = []\n",
    "        for batch_idx, (images, labels) in enumerate(data_loader):\n",
    "            model.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels.long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            batch_loss.append(loss.sum().item()/images.shape[0])\n",
    "        epoch_loss.append(sum(batch_loss)/len(batch_loss))\n",
    "        corrected_graident = weight_differences(c_i, c_s, learning_rate)\n",
    "        orginal_model_weight = model.state_dict()\n",
    "        corrected_model_weight = weight_differences(corrected_graident, orginal_model_weight, 1)  # 这里缩放权重为1\n",
    "        model.load_state_dict(corrected_model_weight)\n",
    "\n",
    "    return model.state_dict(),  sum(epoch_loss) / len(epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "qeFHXRuEo5Du"
   },
   "outputs": [],
   "source": [
    "def average_weights(w):\n",
    "    \"\"\"\n",
    "    Returns the average of the weights.\n",
    "    \"\"\"\n",
    "    w_avg = copy.deepcopy(w[0])\n",
    "    for key in w_avg.keys():\n",
    "        if 'num_batches_tracked' in key:\n",
    "            continue\n",
    "        for i in range(1, len(w)):\n",
    "            w_avg[key] += w[i][key]\n",
    "        w_avg[key] = torch.div(w_avg[key], len(w))\n",
    "    return w_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "pLG9RrFffbl8"
   },
   "outputs": [],
   "source": [
    "# baseline: server-only\n",
    "def server_only(initial_w, global_round, gamma, E):\n",
    "    test_model = mobilenetv2().to(device)\n",
    "    train_w = copy.deepcopy(initial_w)\n",
    "    test_acc = []\n",
    "    train_loss = []\n",
    "    \n",
    "    \n",
    "    for round in tqdm(range(global_round)):\n",
    "        # if gamma > 0.001:\n",
    "        #     gamma = gamma * 0.99\n",
    "        # Server side local training\n",
    "        \n",
    "        \n",
    "        # 从comb中（论文中说明为全部训练数据）选择固定比率的server数据（并且是保证类别均衡的）\n",
    "        # server_data = select_subset(comb_client_data, server_percentage)\n",
    "                \n",
    "        update_server_w, round_loss, _ = update_weights(train_w, server_data, gamma, E)\n",
    "        train_w = update_server_w\n",
    "        test_model.load_state_dict(train_w)\n",
    "        train_loss.append(round_loss)\n",
    "        # Test Accuracy\n",
    "        test_a = 0\n",
    "        for i in client_test_data:\n",
    "            ac = test_inference(test_model,i)[0]\n",
    "            test_a = test_a + ac\n",
    "        test_a = test_a/len(client_test_data)\n",
    "        test_acc.append(test_a)\n",
    "        # print(test_a)\n",
    "    return test_acc, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "nGtAn28aok2c"
   },
   "outputs": [],
   "source": [
    "def fedavg(initial_w, global_round, eta, K, M):\n",
    "    test_model = mobilenetv2().to(device)\n",
    "    train_w = copy.deepcopy(initial_w)\n",
    "    test_acc = []\n",
    "    train_loss = []\n",
    "    for round in tqdm(range(global_round)):\n",
    "        local_weights, local_loss = [], []\n",
    "        # Client side local training\n",
    "        # if eta > 0.001:\n",
    "        #     eta = eta * 0.99\n",
    "        sampled_client = random.sample(range(client_num), M)\n",
    "        for i in sampled_client:\n",
    "            update_client_w, client_round_loss, _ = update_weights(train_w, client_data[i], eta, K)\n",
    "            local_weights.append(update_client_w)\n",
    "            local_loss.append(client_round_loss)\n",
    "\n",
    "        train_w = average_weights(local_weights)\n",
    "\n",
    "        # Test Accuracy\n",
    "        test_model.load_state_dict(train_w)\n",
    "        loss_avg = sum(local_loss)/ len(local_loss)\n",
    "        train_loss.append(loss_avg)\n",
    "        test_a = 0\n",
    "        for i in client_test_data:\n",
    "            ac = test_inference(test_model,i)[0]\n",
    "            test_a = test_a + ac\n",
    "        test_a = test_a/len(client_test_data)\n",
    "        test_acc.append(test_a)\n",
    "#         print(test_a)\n",
    "    return test_acc, train_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybridFL(initial_w, global_round, eta, K, M):\n",
    "    \"\"\"\n",
    "    HybridFL算法：FedAvg改进，服务器也作为一个普通客户端参与训练。\n",
    "    \n",
    "    参数:\n",
    "    - initial_w: 初始模型权重\n",
    "    - global_round: 全局训练轮数\n",
    "    - eta: 学习率\n",
    "    - K: 本地训练轮数\n",
    "    - M: 每轮采样的客户端数量\n",
    "    \"\"\"\n",
    "    test_model = mobilenetv2().to(device)  # 初始化测试模型\n",
    "    train_w = copy.deepcopy(initial_w)     # 当前全局权重\n",
    "    test_acc = []                          # 保存每轮测试精度\n",
    "    train_loss = []                        # 保存每轮训练损失\n",
    "    \n",
    "    for round in tqdm(range(global_round)):\n",
    "        local_weights, local_loss = [], []  # 存储每个客户端/服务器的权重和损失\n",
    "\n",
    "        # 随机采样 M 个客户端\n",
    "        sampled_client = random.sample(range(client_num), M)\n",
    "\n",
    "        # 客户端本地训练\n",
    "        for i in sampled_client:\n",
    "            update_client_w, client_round_loss, _ = update_weights(train_w, client_data[i], eta, K)\n",
    "            local_weights.append(update_client_w)\n",
    "            local_loss.append(client_round_loss)\n",
    "\n",
    "        # 服务器参与训练\n",
    "        update_server_w, server_round_loss, _ = update_weights(train_w, server_data, eta, K)\n",
    "        local_weights.append(update_server_w)   # 将服务器权重加入列表\n",
    "        local_loss.append(server_round_loss)    # 将服务器损失加入列表\n",
    "\n",
    "        # 权重聚合\n",
    "        train_w = average_weights(local_weights)\n",
    "\n",
    "        # 评估模型性能\n",
    "        test_model.load_state_dict(train_w)\n",
    "        loss_avg = sum(local_loss) / len(local_loss)\n",
    "        train_loss.append(loss_avg)\n",
    "        \n",
    "        test_a = 0\n",
    "        for i in client_test_data:  # 遍历所有客户端测试数据\n",
    "            ac = test_inference(test_model, i)[0]\n",
    "            test_a += ac\n",
    "        test_a = test_a / len(client_test_data)\n",
    "        test_acc.append(test_a)\n",
    "        \n",
    "        # # 打印每轮的结果\n",
    "        # print(f\"Round {round + 1}: Test Accuracy = {test_a:.4f}, Train Loss = {loss_avg:.4f}\")\n",
    "    \n",
    "    return test_acc, train_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "uzxW0sUxRGth"
   },
   "outputs": [],
   "source": [
    "def CLG_SGD(initial_w, global_round, eta, gamma, K, E, M):\n",
    "    test_model = mobilenetv2().to(device)\n",
    "    train_w = copy.deepcopy(initial_w)\n",
    "    test_acc = []\n",
    "    train_loss = []\n",
    "    \n",
    "    for round in tqdm(range(global_round)):\n",
    "        # 学习率衰减，这里默认注释掉了\n",
    "        # if eta > 0.001:\n",
    "        #     eta = eta * 0.99\n",
    "        # if gamma > 0.001:\n",
    "        #     gamma = gamma * 0.99\n",
    "        local_weights, local_loss = [], []\n",
    "        # Client side local training\n",
    "        # 从总共client_num客户端中选择M个训练\n",
    "        sampled_client = random.sample(range(client_num), M)\n",
    "        for i in sampled_client:\n",
    "            update_client_w, client_round_loss, _ = update_weights(train_w, client_data[i], eta, K)\n",
    "            local_weights.append(update_client_w)\n",
    "            local_loss.append(client_round_loss)\n",
    "        train_w = average_weights(local_weights)\n",
    "        # Server side local training\n",
    "        \n",
    "        \n",
    "        # 从comb中（论文中说明为全部训练数据）选择固定比率的server数据（并且是保证类别均衡的）\n",
    "        # TODO_241216:这里是每一轮都重新选择数据（但保证类别比例是一样的，都是按照comb中的比例），我的场景中可以这样吗？\n",
    "        # server_data = select_subset(comb_client_data, server_percentage)\n",
    "        \n",
    "        update_server_w, round_loss, _ = update_weights(train_w, server_data, gamma, E)\n",
    "        train_w = update_server_w\n",
    "        local_loss.append(round_loss)\n",
    "\n",
    "        # Test Accuracy\n",
    "        test_model.load_state_dict(train_w)\n",
    "        loss_avg = sum(local_loss)/ len(local_loss)\n",
    "        train_loss.append(loss_avg)   # 计算所有客户端和服务器一起的平均损失\n",
    "\n",
    "        test_a = 0\n",
    "        # 遍历客户端测试数据，计算平均准确率\n",
    "        for i in client_test_data:\n",
    "            ac = test_inference(test_model,i)[0]\n",
    "            test_a = test_a + ac\n",
    "        test_a = test_a/len(client_test_data)\n",
    "        test_acc.append(test_a)\n",
    "#         print(test_a)\n",
    "    return test_acc, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "iJTODAzxYJgA"
   },
   "outputs": [],
   "source": [
    "def Fed_C(initial_w, global_round, eta, gamma, K, E, M):\n",
    "    test_model = mobilenetv2().to(device)\n",
    "    train_w = copy.deepcopy(initial_w)\n",
    "    test_acc = []\n",
    "    train_loss = []\n",
    "    \n",
    "    \n",
    "    for round in tqdm(range(global_round)):\n",
    "        # if eta > 0.001:\n",
    "        #     eta = eta * 0.99\n",
    "        # if gamma > 0.001:\n",
    "        #     gamma = gamma * 0.99\n",
    "        local_weights, local_loss = [], []\n",
    "        g_i_list = []\n",
    "        # server_data = select_subset(comb_client_data, server_percentage)\n",
    "        \n",
    "        \n",
    "        # 计算Server gradient\n",
    "        _, _, g_s = update_weights(train_w, server_data, gamma, 1)\n",
    "\n",
    "        # 计算Client gradient\n",
    "        sampled_client = random.sample(range(client_num), M)\n",
    "        for i in sampled_client:\n",
    "            _, _, g_i = update_weights(train_w, client_data[i], eta, 1)\n",
    "            g_i_list.append(g_i)\n",
    "\n",
    "\n",
    "        # Client side local training\n",
    "        for i in range(len(sampled_client)):\n",
    "            update_client_w, client_round_loss = update_weights_correction(train_w, client_data[sampled_client[i]], eta, K, g_i_list[i], g_s)\n",
    "            local_weights.append(update_client_w)\n",
    "            local_loss.append(client_round_loss)\n",
    "        train_w = average_weights(local_weights)\n",
    "        # Server side local training\n",
    "        update_server_w, round_loss, _ = update_weights(train_w, server_data, gamma, E)\n",
    "        train_w = update_server_w\n",
    "        local_loss.append(round_loss)\n",
    "\n",
    "        # Test Accuracy\n",
    "        test_model.load_state_dict(train_w)\n",
    "        loss_avg = sum(local_loss)/ len(local_loss)\n",
    "        train_loss.append(loss_avg)\n",
    "\n",
    "        test_a = 0\n",
    "        for i in client_test_data:\n",
    "            ac = test_inference(test_model,i)[0]\n",
    "            test_a = test_a + ac\n",
    "        test_a = test_a/len(client_test_data)\n",
    "        test_acc.append(test_a)\n",
    "    return test_acc, train_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "tXqVbWZK7gLn"
   },
   "outputs": [],
   "source": [
    "def Fed_S(initial_w, global_round, eta, gamma, K, E, M):\n",
    "    test_model = mobilenetv2().to(device)\n",
    "    train_w = copy.deepcopy(initial_w)\n",
    "    test_acc = []\n",
    "    train_loss = []\n",
    "    \n",
    "    \n",
    "    for round in tqdm(range(global_round)):\n",
    "        # if eta > 0.001:\n",
    "        #     eta = eta * 0.99\n",
    "        # if gamma > 0.001:\n",
    "        #     gamma = gamma * 0.99\n",
    "        local_weights, local_loss = [], []\n",
    "        g_i_list = []\n",
    "        # Server gradient\n",
    "        # server_data = select_subset(comb_client_data, server_percentage)\n",
    "        _, _, g_s = update_weights(train_w, server_data, gamma, 1)\n",
    "\n",
    "        # Client gradient\n",
    "        sampled_client = random.sample(range(client_num), M)\n",
    "        for i in sampled_client:\n",
    "            _, _, g_i = update_weights(train_w, client_data[i], eta, 1)\n",
    "            g_i_list.append(g_i)\n",
    "\n",
    "\n",
    "        # Client side local training\n",
    "        for i in range(len(sampled_client)):\n",
    "            update_client_w, client_round_loss, _ = update_weights(train_w, client_data[sampled_client[i]], eta, K)\n",
    "            local_weights.append(update_client_w)\n",
    "            local_loss.append(client_round_loss)\n",
    "        train_w = average_weights(local_weights)\n",
    "\n",
    "        # Server aggregation correction\n",
    "        g_i_average = average_weights(g_i_list)\n",
    "        correction_g = weight_differences(g_i_average, g_s, K*eta)\n",
    "        train_w = weight_differences(correction_g, copy.deepcopy(train_w), 1)\n",
    "\n",
    "\n",
    "        # Server side local training\n",
    "        update_server_w, round_loss, _ = update_weights(train_w, server_data, gamma, E)\n",
    "        train_w = update_server_w\n",
    "        local_loss.append(round_loss)\n",
    "\n",
    "        # Test Accuracy\n",
    "        test_model.load_state_dict(train_w)\n",
    "        loss_avg = sum(local_loss)/ len(local_loss)\n",
    "        train_loss.append(loss_avg)\n",
    "\n",
    "        test_a = 0\n",
    "        for i in client_test_data:\n",
    "            ac = test_inference(test_model,i)[0]\n",
    "            test_a = test_a + ac\n",
    "        test_a = test_a/len(client_test_data)\n",
    "        test_acc.append(test_a)\n",
    "    return test_acc, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:45<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server only 训练完成！\n",
      "各轮平均测试精度: [0.051321207209223285, 0.07065446713833504, 0.08132523626374187, 0.07808900201600659, 0.06066246275048179, 0.09995242988167347, 0.09419918188635905, 0.0889215587149879, 0.10124859812935971, 0.12836012757608717, 0.13476190945474378, 0.13689548453519837, 0.13278557602390317, 0.11921261716998273, 0.1119176960323629, 0.11854880776249095, 0.13355632591087618, 0.126508432379652, 0.10489293154666161, 0.10674947088316929, 0.1020418970236527, 0.11097783710336317, 0.13245024320939316, 0.14275119447809154, 0.13324867607028315, 0.1485055149079688, 0.14441928303323348, 0.1036288656048447, 0.14609107211119687, 0.1335654797295428, 0.12809083789805556, 0.13459022435871845, 0.13467406205877924, 0.1430563821854608, 0.1468702590040395, 0.15036390653557102, 0.1507943689518456, 0.12810086282706573, 0.1292130491815761, 0.13542941963439303, 0.13783568270407748, 0.14296703858779553, 0.13812855042473726, 0.13378420299273644, 0.1219911272055083, 0.13085083771002268, 0.10533971955107418, 0.1380185081051538, 0.13619666978012865, 0.14910930337145353, 0.1318101156328944, 0.1354252207413236, 0.14451362134927817, 0.1482835887425028, 0.1412658230861912, 0.13362109419309307, 0.10544100307436567, 0.11930198424990106, 0.1338348902366201, 0.13716910223252937, 0.1355048754690438, 0.14140944637936514, 0.1404833842472696, 0.131429386532306, 0.125935526354101, 0.13231560791906108, 0.13025347313919408, 0.12920352323190248, 0.14529218735948432, 0.1433497781658809, 0.14041436141346195, 0.13295952954035392, 0.138235385134723, 0.1454822468474548, 0.14246425353668535, 0.14410438340341009, 0.14274608178688009, 0.13757453125805508, 0.14314072708403533, 0.14112239382549022, 0.1426479203343324, 0.14564347327867183, 0.1429407144509839, 0.14491356782728387, 0.14265467321454783, 0.1448556540797934, 0.1451942814286679, 0.14099259010862647, 0.14289019838148845, 0.143620218042349, 0.13988798137693173, 0.14155092781073828, 0.14453727989403187, 0.1463395090016913, 0.1433332088187895, 0.1443844214800568, 0.1419719066115085, 0.13998206517679523, 0.14350214356288768, 0.13260403317828226]\n",
      "各轮平均训练损失: [0.04479993503126833, 0.04175639015932878, 0.033111369506352475, 0.033107494983684135, 0.01492707797119187, 0.011751722375413887, 0.014921877153769686, 0.012616217048424814, 0.005750296690018365, 0.0021604373134862355, 0.0008107630628930766, 0.0018855071449016343, 0.0017271249309285647, 0.005411862772760084, 0.005128530418517551, 0.0021197125259614378, 0.00388027205869245, 0.0016595453446993983, 0.004585119562317333, 0.007144814389714695, 0.003766583170120915, 0.006809889540589345, 0.0014727735935593956, 0.0005303857961364512, 0.0024393471948752888, 0.0012583695050125243, 0.0005461416924744198, 0.0029666093730931473, 0.0017462575539226506, 0.0020173524319371033, 0.0008207941209548153, 0.0001941265640602473, 0.00021470374581608834, 8.733104156177702e-05, 0.0003128407436735061, 9.368697463758979e-05, 2.386411389226042e-05, 0.000920986419229545, 0.0004510611202830558, 0.0006388994610730421, 0.0002677664384935741, 0.000439491616281076, 0.0005348035099881668, 0.0002447856786501587, 0.003126477858370857, 0.002101217091991135, 0.001522470422760644, 0.0016739113023774097, 0.0004371866807627225, 0.00037093039350616483, 0.0003545952581320038, 0.0009399178861847891, 0.0001562848610033311, 7.007324065010902e-05, 0.0013180892184377793, 0.0011203662757772554, 0.002916720259101432, 0.0026285702285046377, 0.0006673447129018045, 0.00011134527209193308, 9.439016208421822e-05, 0.00011187244188948643, 0.00041493005627233763, 0.0010318577437087866, 0.0021171952907496705, 0.0027267906958917997, 0.0006729214887012927, 0.000926408039446903, 0.0002141644838856236, 5.3167797686573636e-05, 3.163479427965083e-05, 0.0001767187820658162, 0.0004907737261756093, 7.133451239816942e-05, 7.764198793733225e-05, 3.419952516920872e-05, 7.612500901864727e-05, 0.0009246657928037571, 0.00011616021086208799, 0.0003809437696384487, 2.595778243074973e-05, 4.93418060900526e-05, 1.3054938695286519e-05, 1.8287437647493925e-05, 0.0002431204492457558, 2.9460129418044673e-05, 1.0095277406839564e-05, 3.857016664933663e-05, 1.806622803870697e-05, 7.282130695995402e-06, 3.132888348107843e-05, 1.4329286129513665e-05, 0.00022864062311740512, 5.320517036327349e-06, 1.0376716188728906e-05, 3.591587950453416e-05, 1.4868786673492582e-05, 1.8926036893339595e-05, 9.990799135182359e-06, 0.00023330543543512183]\n",
      "最终测试精度: 0.13260403317828226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:37<00:00,  2.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fedavg训练完成！\n",
      "各轮平均测试精度: [0.0495069447487313, 0.049310456570278355, 0.057000228374489474, 0.04503536199658987, 0.06786833844015079, 0.05851623730684539, 0.07060765565905569, 0.11663307173764821, 0.09354851331488781, 0.1123673301773242, 0.11383894662944644, 0.127842802055668, 0.13516116022423294, 0.10490938008293281, 0.08846518355548266, 0.12240233075226493, 0.10628212633056709, 0.1119781575612171, 0.15461525131882162, 0.11640766639410166, 0.128201801577003, 0.11233377093823917, 0.12150088930811073, 0.1394102576881481, 0.12139291414860112, 0.12920232993412667, 0.15744837330665898, 0.15832157626880275, 0.12897370574022957, 0.13487779157327545, 0.13299627607898853, 0.13990295077309567, 0.15825538538078823, 0.15724061217609506, 0.1174989885905042, 0.15176421837453785, 0.16027532600051766, 0.15839904113372247, 0.1353648819267269, 0.16421094717648135, 0.1610197186066554, 0.18259923571576472, 0.1915946457102679, 0.13230555026828192, 0.14125469159669962, 0.13264232589824052, 0.15589146048414776, 0.18009757507993146, 0.16892512064161383, 0.16524469564501865, 0.1817340882669978, 0.17335377378595418, 0.16628883642160186, 0.17653589081778162, 0.17893032399942338, 0.17036255837689168, 0.19462249213169808, 0.18649846487586416, 0.19324274173209155, 0.1928401098400948, 0.17724568842991384, 0.17507487576767655, 0.18915996046103953, 0.19125570396833105, 0.20457276413929978, 0.1846335573435648, 0.20467930171777166, 0.23028503502222414, 0.19678984047332324, 0.22837040665788766, 0.21166457197360336, 0.2137780404396966, 0.18875047832792927, 0.1872080043764708, 0.19451163719670228, 0.20518662436978616, 0.22707499796439834, 0.23095628368510632, 0.2277374441762184, 0.2084066368684393, 0.2132428756086024, 0.18322169708383015, 0.18884616555468045, 0.19278582242741724, 0.2223874143916236, 0.215484325042763, 0.1883632164880187, 0.19271897532303672, 0.21771177702702157, 0.20617523217730668, 0.22644359198926378, 0.22947848249928293, 0.215702089920363, 0.22336957433243637, 0.22892604113019355, 0.23100300481776412, 0.2301807518813331, 0.2198331203032966, 0.19863838132967082, 0.1996177394932843]\n",
      "各轮平均训练损失: [0.11227678900025426, 0.096943156513985, 0.08258487595041203, 0.06924435652085005, 0.0627641294517325, 0.06268087435843903, 0.06303746787740583, 0.05991376952321702, 0.05836386835928126, 0.05789035338344058, 0.05291715973267054, 0.051894444975058754, 0.05464963139170133, 0.05168824874671207, 0.05212220269591598, 0.05551561803648166, 0.05304170329041914, 0.05267750427230193, 0.05266223206708751, 0.054910640927640385, 0.04949973416744151, 0.049548691272721046, 0.04953927844059359, 0.04656190636102826, 0.05150961602292925, 0.04755466342599368, 0.0511290067768177, 0.04516026404641769, 0.04894509146452333, 0.046164963506064485, 0.04704092225647619, 0.04837427190601641, 0.04715928304811745, 0.041141955355038014, 0.04220945800702789, 0.043317092038107866, 0.04217994880542465, 0.043249374985077436, 0.043680135937248336, 0.04149595721130821, 0.045428523153604766, 0.037201052244901535, 0.03837501936203194, 0.04290819788949661, 0.04014629715075795, 0.042940292385488826, 0.04258470562204699, 0.039810853190205664, 0.043406987169045064, 0.03764379110806359, 0.03920166228717531, 0.03616425816301837, 0.04163506239841534, 0.03520595807854807, 0.04251032846132649, 0.03658360485453215, 0.04227034373200291, 0.03456106279992299, 0.036385632378696284, 0.038516619536350785, 0.034483340439731294, 0.038402523467579754, 0.03392801315037396, 0.030103529831475538, 0.033001068397184294, 0.033345759019801094, 0.03453681011626232, 0.030370774161619502, 0.03314757559944143, 0.032448137494392355, 0.03250196888129085, 0.030142114612001066, 0.0350891305765466, 0.033700213808012934, 0.03128036577929117, 0.036426904053909845, 0.0316570237091572, 0.030490146479563485, 0.03323115146227668, 0.03210862702644675, 0.03516340142892235, 0.029026788573652283, 0.031369257220180614, 0.033180827100999184, 0.02753676683342714, 0.029196347547055752, 0.029419698567758557, 0.02843084556425598, 0.02741037962689231, 0.02864800342362262, 0.029831330025645596, 0.02591960122634333, 0.03162148474185024, 0.026007242467565955, 0.02578184284667686, 0.028842900830924046, 0.027849591355483566, 0.027071829410723763, 0.025543183748102667, 0.030203456886364728]\n",
      "最终测试精度: 0.1996177394932843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:58<00:00,  2.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hrbridFL训练完成！\n",
      "各轮平均测试精度: [0.04741424121514503, 0.05559922580665109, 0.04881679539094752, 0.04807227784439549, 0.06455100950079228, 0.10187515302090853, 0.08884738914420671, 0.07824645374692757, 0.10894948014535949, 0.13914332097885837, 0.15376996298528808, 0.12250669499553726, 0.1395941687510895, 0.1322224136987995, 0.14327155258486407, 0.1319636890159212, 0.147028086623539, 0.16512483896940697, 0.1524205112909025, 0.11463166161048427, 0.1442770288395381, 0.17843431109132496, 0.14869077674956543, 0.15524257494580204, 0.16274725606701956, 0.19205664113573012, 0.18850089675922949, 0.16427613118658577, 0.17185218178730277, 0.18510141684809922, 0.19419353942160464, 0.16984112312350652, 0.17643714387750775, 0.18460573693904656, 0.1688610682156558, 0.19862759088436355, 0.20765864643339482, 0.20101286380594582, 0.1685401689362267, 0.2107580498138233, 0.2004957575903966, 0.21077734385756364, 0.21701228434575456, 0.19228671652201348, 0.185327252187538, 0.19958097894794832, 0.19152357451326746, 0.20456920983405802, 0.1629553087067005, 0.1918329291314707, 0.23428854191586276, 0.184150742253173, 0.1949261177169086, 0.22175628617147627, 0.23618259025640662, 0.208286274222399, 0.19878118128971192, 0.22092863249245148, 0.19820393932461422, 0.22423738044098804, 0.20061293093870647, 0.24732758245420924, 0.22017605507042995, 0.19901059954409883, 0.20246025225275976, 0.21907697352530456, 0.21988344166054474, 0.19265819118386876, 0.2116829087618337, 0.22233662083084046, 0.22341261046572328, 0.23012547838712874, 0.23058092043306758, 0.19364337739696347, 0.22991806017219094, 0.23466508755645443, 0.2524185905793961, 0.22925501044896052, 0.20675626389309326, 0.22718770656307963, 0.23022897331666015, 0.24973299737743943, 0.21872088286883604, 0.2486962769879523, 0.21597377509286392, 0.24650763392224173, 0.23410636069246146, 0.23859836816588154, 0.26128347474709085, 0.23783237015598124, 0.23285125211922375, 0.23231164770368273, 0.256087360353858, 0.2576693711289346, 0.24836378458173688, 0.24830820700841888, 0.22538663841603274, 0.25110964610886627, 0.23208516210410032, 0.2503778343458314]\n",
      "各轮平均训练损失: [0.10079654925930702, 0.08738205188232014, 0.07025198427888553, 0.06245228803043317, 0.059426067102942556, 0.05674276230798892, 0.05247821065088396, 0.05915316661724954, 0.056438687066573824, 0.05127067592696704, 0.04811286926622864, 0.0517386509109887, 0.05092668664839191, 0.04788320660120886, 0.05138438332574751, 0.045740059415337875, 0.04605285865831175, 0.044286098671339785, 0.046825286695382815, 0.044304080236895936, 0.04691727194258682, 0.04329625229415465, 0.04168210853045609, 0.04192972539489433, 0.04299323946962821, 0.04260865488111714, 0.03863705798399391, 0.04076756792216976, 0.04092165831586407, 0.03743218595308049, 0.039499831755161245, 0.04042503394970324, 0.0368819082319308, 0.03596411287326828, 0.03842418017042703, 0.03360445108224543, 0.03585279468426347, 0.03160231745215261, 0.0344182363892261, 0.03303280913768535, 0.031154343925571957, 0.03377748397728357, 0.030346265676627918, 0.032755529688033656, 0.03185174338796183, 0.029952790014732677, 0.033391461885663366, 0.02926364074318569, 0.028105004929519794, 0.033237402734759516, 0.029787483141151504, 0.0312400428477038, 0.030088181237373033, 0.02965361077866524, 0.030004799017325504, 0.0271925127849848, 0.02724521232422473, 0.02544258452965461, 0.031005688093147795, 0.02700573795943118, 0.02709004051233784, 0.030709772106071266, 0.024510948579024427, 0.02658243115102372, 0.02498861185975212, 0.028434993226010122, 0.02547559614737337, 0.027638653528910016, 0.02452503118446631, 0.030480264389062175, 0.025770277483067552, 0.024208266511872523, 0.027966319165507646, 0.023474535756066842, 0.027789570853384037, 0.026194234703944993, 0.02466026411370522, 0.025961321925910153, 0.026345312549274632, 0.024561799619165436, 0.023706138579907273, 0.023222070492390154, 0.024007516166399644, 0.023699164837403166, 0.02472337705178905, 0.021729649047777844, 0.025881103356137903, 0.02443124588836353, 0.022486325833015658, 0.021988056412542093, 0.02098528681750392, 0.019292955275871725, 0.025701106619444095, 0.0196854780666935, 0.021633374677775267, 0.02015353540176368, 0.022189952765479755, 0.024175564817627518, 0.020169718040183752, 0.020678532502810272]\n",
      "最终测试精度: 0.2503778343458314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:58<00:00,  2.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLG_SGD 训练完成！\n",
      "各轮平均测试精度: [0.05109638361879235, 0.06323004287864196, 0.12176141015060533, 0.12827690110862477, 0.14606381481800906, 0.16879372952144006, 0.13642248544046084, 0.15615884564486285, 0.1510988602518253, 0.1812600124392597, 0.19451626995377544, 0.171365737786712, 0.1792969236768233, 0.19071875988984976, 0.1844938674057251, 0.18273410121081907, 0.1892109254419646, 0.19785577235010013, 0.19819995112553396, 0.1840203878341246, 0.2026926432283851, 0.20555804075035644, 0.2031645278735949, 0.2096209327137581, 0.19881761110440915, 0.21261680104084643, 0.22703357744613295, 0.23017716814129924, 0.21604492002635506, 0.22769735956770984, 0.23904051805906812, 0.2351788824349425, 0.22482808098623677, 0.2548487022212245, 0.24849554584939082, 0.2510210564897962, 0.25372188626743886, 0.2507870138558782, 0.25384685300168025, 0.2616656522140669, 0.24116794527234262, 0.26506905737780523, 0.2691175427880954, 0.23743445603818916, 0.26016644561269436, 0.2679540060369874, 0.26209089526637364, 0.26481506632554486, 0.26874221246852753, 0.27563088930115803, 0.27361321344493716, 0.2655811528924941, 0.254923155849097, 0.2766616872272714, 0.2728307423166663, 0.26330839239114234, 0.26791350445916146, 0.28547226483187915, 0.27205097474916023, 0.2728886561268939, 0.26825244324551717, 0.27552010134735094, 0.25667549003243223, 0.28308339927872284, 0.25379658722403975, 0.28185185194963674, 0.28069205581251433, 0.29136107743718126, 0.2761559283031877, 0.287843900352875, 0.2819993898340874, 0.267373384525387, 0.2742510084318045, 0.287869034598585, 0.2802729279202732, 0.2903316449325495, 0.2780437641338727, 0.28676303784278373, 0.2935137408323439, 0.29788522239594334, 0.29045949626328843, 0.2892773452055924, 0.2978030585350271, 0.28620375687255173, 0.2877285896643975, 0.2891851651276375, 0.2953298968983097, 0.2615471692694913, 0.2933746272379733, 0.2659259328262857, 0.2822541065621939, 0.29385764853714974, 0.2826117333473625, 0.28530162449953783, 0.2891317929511499, 0.2792809609883377, 0.29217105451570474, 0.3057305318604687, 0.3062407900630539, 0.30083815352939086]\n",
      "各轮平均训练损失: [0.1002496169616438, 0.07767114059872926, 0.058918798638072103, 0.05484364191546865, 0.05588248300392662, 0.051635804825748255, 0.050052848431609814, 0.05539022262103022, 0.04825009867426413, 0.051851940020523984, 0.05050166498850188, 0.05186435830471574, 0.04879907987848408, 0.05360537211417462, 0.04183950503119097, 0.049357356761178875, 0.041482983384541997, 0.047697345348690495, 0.03940188803476084, 0.04180841197257795, 0.04033693702749991, 0.04311915210427733, 0.03772193226343041, 0.03737736952125759, 0.037928432395132154, 0.03727299728047984, 0.035356475036933295, 0.03569454798289137, 0.030946925935233526, 0.0332079344459733, 0.034433180851764264, 0.028986743868071485, 0.03221187679610404, 0.03070550039472506, 0.02787113306731135, 0.030618437479279295, 0.026787497888333997, 0.026441137293443082, 0.026962877689362265, 0.027080447135282595, 0.02855025367909865, 0.02915507965829409, 0.027213051305575, 0.024453652499938108, 0.024971245315237676, 0.02574997807404633, 0.027510482170250736, 0.024041059357575653, 0.024945221858305954, 0.026494990183259685, 0.02157631621630093, 0.02622575861497688, 0.02356368403908531, 0.02554074955331009, 0.022418973851590532, 0.024255868621212737, 0.0240402256547945, 0.025428902627163994, 0.022492811001472924, 0.021157546889591698, 0.02183614106938027, 0.020462916193362515, 0.020159550330637526, 0.021989888928282263, 0.0227815673172086, 0.021631540196363177, 0.01946062561927563, 0.024143855811962423, 0.018922321833415186, 0.02062807695084208, 0.02354182473640538, 0.020761547850301706, 0.019787749102945097, 0.024185555212588136, 0.020334349153030274, 0.02519716552723905, 0.01831711550898986, 0.02120774339870067, 0.01868834213714701, 0.02150498606919271, 0.01958546966079875, 0.02145537644732902, 0.018038212596141488, 0.018639121691079587, 0.019144296415966457, 0.02169579676970664, 0.020731770535959648, 0.01931386621142781, 0.019407004915510565, 0.017256657219007106, 0.017672610747052078, 0.02203961804451035, 0.019222289824983536, 0.019949777056404282, 0.01987789932189125, 0.019111769903093802, 0.01541724066945465, 0.019429542394486472, 0.019136355305297188, 0.01874953297313552]\n",
      "最终测试精度: 0.30083815352939086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [07:25<00:00,  4.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fed_C 训练完成！\n",
      "各轮平均测试精度: [0.05109638361879235, 0.09275787258845809, 0.09555794114292629, 0.07419276604152852, 0.11729794801989693, 0.08479980684008652, 0.11470389343408188, 0.11170224560214331, 0.1445872109165276, 0.12941011716698703, 0.15438648844335534, 0.14315900045495222, 0.15177498624366245, 0.17242636646326517, 0.17447906640223848, 0.16863243262568564, 0.1897973457444528, 0.18370671368884628, 0.1859520535270899, 0.17397713939474005, 0.20324265502186642, 0.2051722024485442, 0.21401632610522575, 0.2140653629779894, 0.13130312781316966, 0.2024689148327347, 0.15869206809576084, 0.2092460664734487, 0.22085133824254866, 0.20735704821413228, 0.21074072047639825, 0.22183291404229838, 0.18321236069428806, 0.2065631734150482, 0.22850771635381073, 0.22204475374386476, 0.22716622161384378, 0.21361360500839038, 0.22521419631196604, 0.23269691009691962, 0.22458463893593517, 0.2322894425402263, 0.23109153236505298, 0.21753445567491217, 0.2283690893999242, 0.22803295308685342, 0.23789115403976802, 0.23100840906770903, 0.236124476460943, 0.23393394532382705, 0.22477303050549532, 0.23207246606070747, 0.23280505176349195, 0.2367122849883097, 0.24305565606246257, 0.2370480423230818, 0.21183729361579234, 0.23476173281744286, 0.2249984092399345, 0.2431540317433195, 0.22860402424917145, 0.2179912048239919, 0.20146635964348736, 0.21865178509926916, 0.22316721027345474, 0.22522634551676338, 0.2190262720675667, 0.22326093386827928, 0.21557691213221175, 0.2219628994455507, 0.24071279383577487, 0.2511036443833522, 0.23823138419759748, 0.2439358663497019, 0.23116761538398528, 0.24403791615844572, 0.25515019865115385, 0.23995740327198348, 0.23278668749999384, 0.2553856789078449, 0.2509834098278323, 0.24911804371492163, 0.24692944446355558, 0.2326519959405067, 0.21134131046051505, 0.2579743185956504, 0.22418211138328978, 0.25048846209627035, 0.23460970039447204, 0.23268567970695397, 0.2551525440562221, 0.2449202323656081, 0.25238456395170794, 0.24761456791999437, 0.2631990896906745, 0.25791560035688976, 0.24277549954805372, 0.24861015006519444, 0.24719880373603456, 0.24771137826655465]\n",
      "各轮平均训练损失: [0.02308157040585261, 0.01983408784441949, 0.019526071747779962, 0.019684156489566455, 0.019425251715536555, 0.018954839901408865, 0.020678755297561448, 0.021830580393521596, 0.02233120584260944, 0.02064658636012058, 0.019752792462488337, 0.01709037996195527, 0.015283789700196821, 0.013839976948480732, 0.01338619354727606, 0.012225418172963153, 0.011841987456199604, 0.01239149582999894, 0.01150109269568201, 0.012636348865123142, 0.012150483877804428, 0.011235158102308655, 0.009785170371822464, 0.009965308175665344, 0.009846202576228986, 0.011216733975522827, 0.01129831593789022, 0.010293622927484161, 0.010312696232494216, 0.009227042003358839, 0.010171616545191206, 0.009297529087493773, 0.009785323411802329, 0.010142820526044304, 0.009145964112624281, 0.00934077687453929, 0.008256509981748024, 0.008073322876833698, 0.008557583368115164, 0.008480510276393781, 0.008485519920177457, 0.008502524461250159, 0.0077025506781032045, 0.007331783500529498, 0.008196054622661124, 0.007768335503785725, 0.009170772434004146, 0.007236602690322946, 0.00812604812898158, 0.0075985471870527975, 0.009124250796463325, 0.007557793321707958, 0.007790435787757064, 0.006007190176499899, 0.007389689571422617, 0.007168670836895802, 0.0064921734473507185, 0.0071925636303721225, 0.008134183582540557, 0.00853075247142689, 0.007207158221260998, 0.007750339648394517, 0.0073586680955839145, 0.009179020633715422, 0.00968662081816612, 0.00851133713599571, 0.00801101904575035, 0.00924516445788051, 0.008216499581604114, 0.008473812378610682, 0.00810964208234749, 0.00767602073524355, 0.007156828330390024, 0.007088480906484496, 0.00723652652219173, 0.007163809477011946, 0.0068755106747968526, 0.006559399275874717, 0.006406722982799221, 0.007986755615525006, 0.006570830064660609, 0.0065738103831116555, 0.0066255022109478375, 0.006857411739707419, 0.006244162477449336, 0.0073086300669903395, 0.006612659333552156, 0.007129224656059047, 0.007252077522876641, 0.007282294514845486, 0.006043435597831518, 0.006089071269769988, 0.006248431432660359, 0.006660032146814609, 0.005489316197562864, 0.007283954027420699, 0.006006246250711236, 0.007354490635964175, 0.006126135821158864, 0.00699282714709972]\n",
      "最终测试精度: 0.24771137826655465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [06:27<00:00,  3.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fed_S 训练完成！\n",
      "各轮平均测试精度: [0.051321207209223285, 0.06803169238889226, 0.10042575763885499, 0.10132348573782118, 0.09962111318576444, 0.10900401256087207, 0.14390348320345764, 0.12919548045026816, 0.14506491384769643, 0.1361086021725518, 0.12406543859987068, 0.1362936964287569, 0.1455499250695871, 0.14104294305775023, 0.1489386496037165, 0.17437976015089252, 0.1568148575811723, 0.18065803528387483, 0.17993707853628127, 0.17932434553082666, 0.19601073034787236, 0.1711604500016671, 0.1853167596262088, 0.20317377844184337, 0.20700515843174125, 0.1964356718113247, 0.20625164985508448, 0.2113757153703827, 0.20814715842889625, 0.2147264669134762, 0.21707778189630667, 0.21153885874661235, 0.21421303868871913, 0.21284359395234603, 0.20003939284965938, 0.2098357022100865, 0.2162566525592915, 0.22727053111352064, 0.20194919346150791, 0.2178997384647032, 0.22923347294345056, 0.2321312477223902, 0.23235846986461212, 0.22396406081795067, 0.2334544573574001, 0.21925563681758253, 0.2213766134017164, 0.23062721469456032, 0.24088185476025056, 0.2397197881494422, 0.2323563842915799, 0.24257498386980497, 0.25069845485733483, 0.23350259815040608, 0.24925780256740107, 0.23955133144507937, 0.25780606606273065, 0.24141492358446479, 0.26243631932204403, 0.25270288191643087, 0.2464146380844554, 0.23625262438196062, 0.23051335887591734, 0.2314777264246394, 0.23616839538594092, 0.24721821742519112, 0.23847532904573066, 0.23720941759287334, 0.23502704125373308, 0.2516227221643974, 0.25034745155571253, 0.24682636199040647, 0.2526335362956291, 0.25471643173759767, 0.24564682058295662, 0.2436526621028068, 0.23039064500817788, 0.24479980547170524, 0.24866621575783948, 0.2577935640924603, 0.2532103322311699, 0.24724296405458518, 0.23986624661978057, 0.25264996404195417, 0.2506688345837449, 0.25919180911357453, 0.2496889814617633, 0.25802556047946296, 0.26385795177098115, 0.26444682976811584, 0.2596770210510993, 0.27135894874895744, 0.2616749305557965, 0.2721398508941087, 0.26108933756838415, 0.2548286621808317, 0.25814913407823203, 0.25323139194178007, 0.2605837849948703, 0.2717495388349679]\n",
      "各轮平均训练损失: [0.12416868884113734, 0.0676217347265459, 0.058030175706114726, 0.05414006546604863, 0.05449942381139882, 0.0566819734723482, 0.05974269518057604, 0.05492002225677841, 0.052854077264377304, 0.0668942116947178, 0.04979286403814727, 0.059224879614082133, 0.05629101001812305, 0.050761278057464894, 0.05203787518943017, 0.05319673715957216, 0.04934764059017598, 0.05092180553916464, 0.04883201345306596, 0.04202060208879846, 0.04616541172979074, 0.0386087377294137, 0.04525205950449922, 0.03729004644074438, 0.036992915898616606, 0.03716672637782236, 0.0375751319126828, 0.03577630907472556, 0.035932911404642796, 0.03478500943048254, 0.036013114345033945, 0.03337263504479022, 0.03417006041063465, 0.03322170010572319, 0.03514894063418821, 0.032988562964777444, 0.03146792385258058, 0.03197636908596024, 0.032165510818045556, 0.03729887150038533, 0.03161189675584015, 0.03231285226400101, 0.02875870302382153, 0.028936925734944018, 0.028640811613103886, 0.031082686411671293, 0.027643634667134643, 0.02931756527043636, 0.03078907910747275, 0.027696691988520237, 0.026296458084071817, 0.025377505102340377, 0.02631279793866478, 0.02727600310687641, 0.028320099087911502, 0.02654091424011873, 0.027084961537793804, 0.02758174652833447, 0.02632813087624493, 0.026725070787942763, 0.02514232502186929, 0.025152266930762637, 0.027073867218567596, 0.02822494849876005, 0.024900302759456806, 0.02275973600020619, 0.02541220955814899, 0.027234405918405317, 0.023041341803711625, 0.024201178396714665, 0.02421340657445137, 0.02422622543176082, 0.024716987126486435, 0.02416919330467513, 0.022472234967665573, 0.025702705819964314, 0.02484318343918588, 0.020267691723977115, 0.024625002182280812, 0.024913111069360505, 0.0206763748497399, 0.023798762576217422, 0.021265011947878144, 0.021316586973232632, 0.01988340546116618, 0.022525753372823008, 0.02093518854467204, 0.02074507740772695, 0.020449355908636436, 0.021796203180000143, 0.02142160790087186, 0.02265966314624112, 0.02307145315760938, 0.022628506726063036, 0.019763821984165555, 0.019723567732631023, 0.021439618218504628, 0.021727148588546224, 0.02053974307247289, 0.022688723513864934]\n",
      "最终测试精度: 0.2717495388349679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 初始化模型与参数\n",
    "# 这部分是我补充的\n",
    "\n",
    "\n",
    "init_model = mobilenetv2().to(device)\n",
    "initial_w = init_model.state_dict()\n",
    "\n",
    "# Servfer-only训练\n",
    "test_acc, train_loss = server_only(initial_w, global_round, gamma, E)\n",
    "\n",
    "# 打印训练过程中的结果\n",
    "print(\"Server only 训练完成！\")\n",
    "print(\"各轮平均测试精度:\", test_acc)\n",
    "print(\"各轮平均训练损失:\", train_loss)\n",
    "print(\"最终测试精度:\", test_acc[-1] if len(test_acc) > 0 else \"无数据\")\n",
    "\n",
    "\n",
    "init_model = mobilenetv2().to(device)\n",
    "initial_w = init_model.state_dict()\n",
    "\n",
    "# fedavg训练\n",
    "test_acc, train_loss = fedavg(initial_w, global_round, eta, K, M)\n",
    "\n",
    "# 打印训练过程中的结果\n",
    "print(\"fedavg训练完成！\")\n",
    "print(\"各轮平均测试精度:\", test_acc)\n",
    "print(\"各轮平均训练损失:\", train_loss)\n",
    "print(\"最终测试精度:\", test_acc[-1] if len(test_acc) > 0 else \"无数据\")\n",
    "\n",
    "\n",
    "\n",
    "init_model = mobilenetv2().to(device)\n",
    "initial_w = init_model.state_dict()\n",
    "\n",
    "# hybridfl训练\n",
    "test_acc, train_loss = hybridFL(initial_w, global_round, eta, K, M)\n",
    "\n",
    "# 打印训练过程中的结果\n",
    "print(\"hrbridFL训练完成！\")\n",
    "print(\"各轮平均测试精度:\", test_acc)\n",
    "print(\"各轮平均训练损失:\", train_loss)\n",
    "print(\"最终测试精度:\", test_acc[-1] if len(test_acc) > 0 else \"无数据\")\n",
    "\n",
    "\n",
    "init_model = mobilenetv2().to(device)\n",
    "initial_w = init_model.state_dict()\n",
    "\n",
    "# CLG_SGD训练\n",
    "test_acc, train_loss = CLG_SGD(initial_w, global_round, eta, gamma, K, E, M)\n",
    "\n",
    "# 打印训练过程中的结果\n",
    "print(\"CLG_SGD 训练完成！\")\n",
    "print(\"各轮平均测试精度:\", test_acc)\n",
    "print(\"各轮平均训练损失:\", train_loss)\n",
    "print(\"最终测试精度:\", test_acc[-1] if len(test_acc) > 0 else \"无数据\")\n",
    "\n",
    "\n",
    "init_model = mobilenetv2().to(device)\n",
    "initial_w = init_model.state_dict()\n",
    "\n",
    "# Fed_C训练\n",
    "test_acc, train_loss = Fed_C(initial_w, global_round, eta, gamma, K, E, M)\n",
    "\n",
    "# 打印训练过程中的结果\n",
    "print(\"Fed_C 训练完成！\")\n",
    "print(\"各轮平均测试精度:\", test_acc)\n",
    "print(\"各轮平均训练损失:\", train_loss)\n",
    "print(\"最终测试精度:\", test_acc[-1] if len(test_acc) > 0 else \"无数据\")\n",
    "\n",
    "\n",
    "init_model = mobilenetv2().to(device)\n",
    "initial_w = init_model.state_dict()\n",
    "\n",
    "# Fed_S训练\n",
    "test_acc, train_loss = Fed_S(initial_w, global_round, eta, gamma, K, E, M)\n",
    "\n",
    "# 打印训练过程中的结果\n",
    "print(\"Fed_S 训练完成！\")\n",
    "print(\"各轮平均测试精度:\", test_acc)\n",
    "print(\"各轮平均训练损失:\", train_loss)\n",
    "print(\"最终测试精度:\", test_acc[-1] if len(test_acc) > 0 else \"无数据\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "env8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
