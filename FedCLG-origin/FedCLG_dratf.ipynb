{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {
    "id": "gSK1TSekTVeu"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.functional as func\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {
    "id": "9-WEXWakTwf8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True' # 解决由于多次加载 OpenMP 相关动态库而引起的冲突"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sns3blEITybc",
    "outputId": "120095fb-5597-4ada-8c12-b4470d8ad28e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jan  3 17:55:42 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090        Off | 00000000:21:00.0 Off |                  Off |\n",
      "| 30%   34C    P8              11W / 350W |    585MiB / 24564MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 4090        Off | 00000000:E1:00.0 Off |                  Off |\n",
      "| 30%   32C    P8              16W / 350W |     14MiB / 24564MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      4802      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "|    0   N/A  N/A    314011      C   /home/anaconda/envs/env8/bin/python         568MiB |\n",
      "|    1   N/A  N/A      4802      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
    "\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {
    "id": "96gqMCQneWho"
   },
   "outputs": [],
   "source": [
    "\n",
    "class LinearBottleNeck(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride, t=6, class_num=100):\n",
    "        super().__init__()\n",
    "\n",
    "        self.residual = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels * t, 1),\n",
    "            nn.BatchNorm2d(in_channels * t),\n",
    "            nn.ReLU6(inplace=True),\n",
    "\n",
    "            nn.Conv2d(in_channels * t, in_channels * t, 3, stride=stride, padding=1, groups=in_channels * t),\n",
    "            nn.BatchNorm2d(in_channels * t),\n",
    "            nn.ReLU6(inplace=True),\n",
    "\n",
    "            nn.Conv2d(in_channels * t, out_channels, 1),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "\n",
    "        self.stride = stride\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        residual = self.residual(x)\n",
    "\n",
    "        if self.stride == 1 and self.in_channels == self.out_channels:\n",
    "            residual += x\n",
    "\n",
    "        return residual\n",
    "\n",
    "# MobileNetV2（比lenet更复杂的CNN网络）网络中的线性瓶颈结构，原文中用于CIFAR-100任务\n",
    "class MobileNetV2(nn.Module):\n",
    "\n",
    "    def __init__(self, class_num=20):\n",
    "        super().__init__()\n",
    "\n",
    "        self.pre = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU6(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.stage1 = LinearBottleNeck(32, 16, 1, 1)\n",
    "        self.stage2 = self._make_stage(2, 16, 24, 2, 6)\n",
    "        self.stage3 = self._make_stage(3, 24, 32, 2, 6)\n",
    "        self.stage4 = self._make_stage(4, 32, 64, 2, 6)\n",
    "        self.stage5 = self._make_stage(3, 64, 96, 1, 6)\n",
    "        self.stage6 = self._make_stage(3, 96, 160, 1, 6)\n",
    "        self.stage7 = LinearBottleNeck(160, 320, 1, 6)\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(320, 1280, 1),\n",
    "            nn.BatchNorm2d(1280),\n",
    "            nn.ReLU6(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Conv2d(1280, class_num, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pre(x)\n",
    "        x = self.stage1(x)\n",
    "        x = self.stage2(x)\n",
    "        x = self.stage3(x)\n",
    "        x = self.stage4(x)\n",
    "        x = self.stage5(x)\n",
    "        x = self.stage6(x)\n",
    "        x = self.stage7(x)\n",
    "        x = self.conv1(x)\n",
    "        x = F.adaptive_avg_pool2d(x, 1)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _make_stage(self, repeat, in_channels, out_channels, stride, t):\n",
    "\n",
    "        layers = []\n",
    "        layers.append(LinearBottleNeck(in_channels, out_channels, stride, t))\n",
    "\n",
    "        while repeat - 1:\n",
    "            layers.append(LinearBottleNeck(out_channels, out_channels, 1, t))\n",
    "            repeat -= 1\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "def mobilenetv2():\n",
    "    return MobileNetV2()\n",
    "\n",
    "\n",
    "# FedMut中采用的cnn模型\n",
    "class CNNCifar(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNCifar, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x, start_layer_idx=0, logit=False):\n",
    "        if start_layer_idx < 0:  #\n",
    "            return self.mapping(x, start_layer_idx=start_layer_idx, logit=logit)\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        result = {'activation' : x}\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        result['hint'] = x\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        result['representation'] = x\n",
    "        x = self.fc3(x)\n",
    "        result['output'] = x\n",
    "        return result\n",
    "\n",
    "    def mapping(self, z_input, start_layer_idx=-1, logit=True):\n",
    "        z = z_input\n",
    "        z = self.fc3(z)\n",
    "\n",
    "        result = {'output': z}\n",
    "        if logit:\n",
    "            result['logit'] = z\n",
    "        return result\n",
    "    \n",
    "def cnncifar():\n",
    "    return CNNCifar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {
    "id": "QkvtGtMuUDmr"
   },
   "outputs": [],
   "source": [
    "# def test_inference(model, test):\n",
    "#     \"\"\" Returns the test accuracy and loss.\n",
    "#     \"\"\"\n",
    "#     tensor_x = torch.Tensor(test[0]).to(device)\n",
    "#     tensor_y = torch.Tensor(test[1]).to(device)\n",
    "#     test_dataset = TensorDataset(tensor_x, tensor_y)\n",
    "\n",
    "#     model.eval()\n",
    "#     loss, total, correct = 0.0, 0.0, 0.0\n",
    "\n",
    "#     criterion = nn.CrossEntropyLoss()\n",
    "#     testloader = DataLoader(test_dataset, batch_size=bc_size,\n",
    "#                             shuffle=True)\n",
    "\n",
    "#     for batch_idx, (images, labels) in enumerate(testloader):\n",
    "#         with torch.no_grad():  # 在测试过程中不需要计算梯度，节省内存和加速计算\n",
    "#         # Inference\n",
    "#             outputs = model(images)\n",
    "#             batch_loss = criterion(outputs, labels.long())\n",
    "#             loss += batch_loss.item() * labels.size(0) # 计算损失值，更好反映模型输出概率分布与真实标签的差距\n",
    "\n",
    "#         # Prediction\n",
    "#             _, pred_labels = torch.max(outputs, 1)\n",
    "#             pred_labels = pred_labels.view(-1)\n",
    "#             correct += torch.sum(torch.eq(pred_labels, labels)).item()\n",
    "#             total += len(labels)\n",
    "#     #print(correct,\"/\",total)\n",
    "#     accuracy = correct/total\n",
    "    \n",
    "#     print(\"Testing accuracy: {:.2f}\", accuracy)\n",
    "#     return accuracy, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新的测试：针对整个测试数据集的测试\n",
    "def test_inference(net_glob, dataset_test):\n",
    "    # testing\n",
    "    acc_test, loss_test = test_img(net_glob, dataset_test)\n",
    "\n",
    "    # print(\"Testing accuracy: {:.2f}\".format(acc_test))\n",
    "\n",
    "    return acc_test.item()\n",
    "\n",
    "def test_img(net_g, datatest):\n",
    "    net_g.eval()\n",
    "    # testing\n",
    "    # test loss代表在测试集上的平均损失（对测试数据的预测输出与真实标签的差距）\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    data_loader = DataLoader(datatest, batch_size=bc_size)\n",
    "    l = len(data_loader)\n",
    "    with torch.no_grad():\n",
    "        for idx, (data, target) in enumerate(data_loader):\n",
    "            if gpu != -1:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            log_probs = net_g(data)['output']\n",
    "            # sum up batch loss\n",
    "            test_loss += F.cross_entropy(log_probs, target, reduction='sum').item()\n",
    "            # get the index of the max log-probability\n",
    "            y_pred = log_probs.data.max(1, keepdim=True)[1]\n",
    "            correct += y_pred.eq(target.data.view_as(y_pred)).long().cpu().sum()\n",
    "\n",
    "    test_loss /= len(data_loader.dataset)\n",
    "    accuracy = 100.00 * correct / len(data_loader.dataset)\n",
    "    if verbose:\n",
    "        print('\\nTest set: Average loss: {:.4f} \\nAccuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "            test_loss, correct, len(data_loader.dataset), accuracy))\n",
    "    return accuracy, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {
    "id": "jURskA9VUJOF"
   },
   "outputs": [],
   "source": [
    "# 将CIFAR-100的100个类别转为20个类别（粒度更粗，降低任务复杂度）\n",
    "def sparse2coarse(targets):\n",
    "    \"\"\"Convert Pytorch CIFAR100 sparse targets to coarse targets.\n",
    "\n",
    "    Usage:\n",
    "        trainset = torchvision.datasets.CIFAR100(path)\n",
    "        trainset.targets = sparse2coarse(trainset.targets)\n",
    "    \"\"\"\n",
    "    coarse_labels = np.array([ 4,  1, 14,  8,  0,  6,  7,  7, 18,  3,\n",
    "                               3, 14,  9, 18,  7, 11,  3,  9,  7, 11,\n",
    "                               6, 11,  5, 10,  7,  6, 13, 15,  3, 15,\n",
    "                               0, 11,  1, 10, 12, 14, 16,  9, 11,  5,\n",
    "                               5, 19,  8,  8, 15, 13, 14, 17, 18, 10,\n",
    "                               16, 4, 17,  4,  2,  0, 17,  4, 18, 17,\n",
    "                               10, 3,  2, 12, 12, 16, 12,  1,  9, 19,\n",
    "                               2, 10,  0,  1, 16, 12,  9, 13, 15, 13,\n",
    "                              16, 19,  2,  4,  6, 19,  5,  5,  8, 19,\n",
    "                              18,  1,  2, 15,  6,  0, 17,  8, 14, 13])\n",
    "    return coarse_labels[targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {
    "id": "jcZ7eQGET_YJ"
   },
   "outputs": [],
   "source": [
    "# 共有6w个图像，其中5w训练，1w测试\n",
    "def CIFAR100():\n",
    "    '''Return Cifar100\n",
    "    '''\n",
    "    train_dataset = torchvision.datasets.CIFAR100(root='../data/CIFAR-100',\n",
    "                                            train=True,\n",
    "                                            transform=transforms.ToTensor(),\n",
    "                                            download=True)\n",
    "    test_dataset = torchvision.datasets.CIFAR100(root='../data/CIFAR-100',\n",
    "                                            train=False,\n",
    "                                            transform=transforms.ToTensor(),\n",
    "                                            download=True)\n",
    "    total_img,total_label = [],[]\n",
    "    for imgs,labels in train_dataset:\n",
    "        total_img.append(imgs.numpy())\n",
    "        total_label.append(labels)\n",
    "    # for imgs,labels in test_dataset:\n",
    "    #     total_img.append(imgs.numpy())\n",
    "    #     total_label.append(labels) \n",
    "    total_img = np.array(total_img)\n",
    "    total_label = np.array(sparse2coarse(total_label))\n",
    "\n",
    "    cifar = [total_img, total_label]\n",
    "    return cifar, test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {
    "id": "f1eQhNtPUMOF"
   },
   "outputs": [],
   "source": [
    "# 基于 Dirichlet 分布 来模拟non-IID。返回一个形状为 (client_num, class_num) 的概率矩阵，每一行代表一个客户端对各类别的概率分布。\n",
    "def get_prob(non_iid, client_num, class_num = 20):\n",
    "    # Modify：我之后加上的\n",
    "    if data_random_fix:\n",
    "        np.random.seed(seed_num)  # 固定种子，确保数据抽样一致\n",
    "    \n",
    "    return np.random.dirichlet(np.repeat(non_iid, class_num), client_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {
    "id": "npT3idE-UaGm"
   },
   "outputs": [],
   "source": [
    "# 全部用于构建训练集\n",
    "def create_data_all_train(prob, size_per_client, dataset, N=20):\n",
    "    total_each_class = size_per_client * np.sum(prob, 0)\n",
    "    data, label = dataset\n",
    "\n",
    "    if data_random_fix:\n",
    "        np.random.seed(seed_num)  # 固定种子，确保数据抽样一致\n",
    "        random.seed(seed_num)\n",
    "\n",
    "    # 为每个类别随机采样数据\n",
    "    all_class_set = []\n",
    "    for i in range(N):\n",
    "        size = total_each_class[i]\n",
    "        sub_data = data[label == i]\n",
    "        sub_label = label[label == i]\n",
    "\n",
    "        rand_indx = np.random.choice(len(sub_data), size=int(size), replace=False).astype(int)\n",
    "        sub2_data, sub2_label = sub_data[rand_indx], sub_label[rand_indx]\n",
    "        all_class_set.append((sub2_data, sub2_label))\n",
    "\n",
    "    index = [0] * N\n",
    "    clients = []\n",
    "\n",
    "    for m in range(prob.shape[0]):  # 遍历客户端\n",
    "        labels, images = [], []  # 训练数据\n",
    "\n",
    "        for n in range(N):\n",
    "            # 100%用于训练\n",
    "            start, end = index[n], index[n] + int(prob[m][n] * size_per_client)\n",
    "            image, label = all_class_set[n][0][start:end], all_class_set[n][1][start:end]\n",
    "\n",
    "            # 记录当前类别的数据分配进度\n",
    "            index[n] += int(prob[m][n] * size_per_client)\n",
    "\n",
    "            labels.extend(label)\n",
    "            images.extend(image)\n",
    "\n",
    "        clients.append((np.array(images), np.array(labels)))\n",
    "\n",
    "    return clients\n",
    "\n",
    "# 80%构建训练集，20%构建测试集\n",
    "def create_data(prob, size_per_client, dataset, N=20):\n",
    "    total_each_class = size_per_client * np.sum(prob, 0)\n",
    "    data, label = dataset\n",
    "\n",
    "    # Modify：我之后加上的\n",
    "    if data_random_fix:\n",
    "        np.random.seed(seed_num)  # 固定种子，确保数据抽样一致\n",
    "        random.seed(seed_num)\n",
    "\n",
    "    # 为每个类别随机采样数据\n",
    "    all_class_set = []\n",
    "    for i in range(N):\n",
    "        size = total_each_class[i]\n",
    "        sub_data = data[label == i]\n",
    "        sub_label = label[label == i]\n",
    "\n",
    "        rand_indx = np.random.choice(len(sub_data), size=int(size), replace=False).astype(int)\n",
    "        sub2_data, sub2_label = sub_data[rand_indx], sub_label[rand_indx]\n",
    "        all_class_set.append((sub2_data, sub2_label))\n",
    "\n",
    "    index = [0] * N\n",
    "    clients, test = [], []\n",
    "\n",
    "    for m in range(prob.shape[0]):  # 遍历客户端\n",
    "        labels, images = [], []  # 训练数据\n",
    "        tlabels, timages = [], [] # 测试数据\n",
    "\n",
    "        for n in range(N):\n",
    "            # 80%用于训练，20%用于测试\n",
    "            # 这里的int向下取整，会导致实际的数据量比计算略小\n",
    "            start, end = index[n], index[n] + int(prob[m][n] * size_per_client * 0.8)\n",
    "            test_start, test_end = end, index[n] + int(prob[m][n] * size_per_client)\n",
    "\n",
    "            image, label = all_class_set[n][0][start:end], all_class_set[n][1][start:end]\n",
    "            test_image, test_label = all_class_set[n][0][test_start:test_end], all_class_set[n][1][test_start:test_end]\n",
    "\n",
    "            # 记录当前类别的数据分配进度\n",
    "            index[n] += int(prob[m][n] * size_per_client)\n",
    "\n",
    "            labels.extend(label)\n",
    "            images.extend(image)\n",
    "\n",
    "            tlabels.extend(test_label)\n",
    "            timages.extend(test_image)\n",
    "\n",
    "        clients.append((np.array(images), np.array(labels)))\n",
    "        test.append((np.array(timages), np.array(tlabels)))\n",
    "\n",
    "    return clients, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {
    "id": "DCsR6_QqUzJ8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# 合并所有客户端的测试数据 （上面讲测试数据分成了不同的客户端）\n",
    "# 但并没有使用，用途不明\n",
    "def comb_client_test_func(client_test_data):\n",
    "    comb_client_test_image = []\n",
    "    comb_client_test_label = []\n",
    "    for i in range(client_num):\n",
    "        comb_client_test_image.extend(list(client_test_data[i][0]))\n",
    "        comb_client_test_label.extend(list(client_test_data[i][1]))\n",
    "    \n",
    "    # 将测试图片和标签合并为 numpy 数组\n",
    "    comb_client_test_image = np.array(comb_client_test_image)\n",
    "    comb_client_test_label = np.array(comb_client_test_label)\n",
    "    \n",
    "    label_count = Counter(comb_client_test_label)\n",
    "    print(\"测试集类别分布：\")\n",
    "    for label, count in sorted(label_count.items()):\n",
    "        print(f\"类别 {label}: {count} 个样本\")\n",
    "    \n",
    "    return [comb_client_test_image, comb_client_test_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {
    "id": "JEKzDM0yW3DW"
   },
   "outputs": [],
   "source": [
    "# 从数据集中按类别均匀抽取子集，并按照指定的比例 percentage 进行缩减，同时对数据进行随机打乱\n",
    "def select_subset(whole_set, percentage):\n",
    "    \n",
    "    # Modify：我之后加上的\n",
    "    if data_random_fix:\n",
    "        np.random.seed(seed_num)  # 固定种子，确保数据抽样一致\n",
    "        random.seed(seed_num)\n",
    "    \n",
    "    a = whole_set[0]\n",
    "    b = whole_set[1]\n",
    "    if len(a) != len(b):\n",
    "        raise ValueError(\"Both arrays should have the same length.\")\n",
    "\n",
    "    if not 0 <= percentage <= 1:\n",
    "        raise ValueError(\"Percentage must be between 0 and 1.\")\n",
    "\n",
    "    unique_classes = np.unique(b)\n",
    "\n",
    "    a_prime = []\n",
    "    b_prime = []\n",
    "\n",
    "    for cls in unique_classes:\n",
    "        indices = np.where(b == cls)[0]\n",
    "        subset_size = int(len(indices) * percentage)\n",
    "\n",
    "        selected_indices = np.random.choice(indices, subset_size, replace=False)\n",
    "\n",
    "        a_prime.extend(a[selected_indices])\n",
    "        b_prime.extend(b[selected_indices])\n",
    "\n",
    "    a_prime, b_prime = np.array(a_prime), np.array(b_prime)\n",
    "\n",
    "    # Shuffle arrays to randomize the order of elements\n",
    "    shuffle_indices = np.random.permutation(len(a_prime))\n",
    "    a_prime, b_prime = a_prime[shuffle_indices], b_prime[shuffle_indices]\n",
    "\n",
    "    return [a_prime, b_prime]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {
    "id": "XvuicdZfeDvL"
   },
   "outputs": [],
   "source": [
    "# 本地训练并更新权重，返回更新后的模型权重、平均训练损失以及第一个迭代的梯度信息\n",
    "def update_weights(model_weight, dataset, learning_rate, local_epoch):\n",
    "    model = cnncifar().to(device)\n",
    "    model.load_state_dict(model_weight)\n",
    "\n",
    "    model.train()\n",
    "    epoch_loss = []\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    Tensor_set = TensorDataset(torch.Tensor(dataset[0]).to(device), torch.Tensor(dataset[1]).to(device))\n",
    "    data_loader = DataLoader(Tensor_set, batch_size=bc_size, shuffle=True)\n",
    "\n",
    "    first_iter_gradient = None  # 初始化变量来保存第一个iter的梯度\n",
    "\n",
    "    for iter in range(local_epoch):\n",
    "        batch_loss = []\n",
    "        for batch_idx, (images, labels) in enumerate(data_loader):\n",
    "            model.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs['output'], labels.long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            batch_loss.append(loss.item()/images.shape[0])\n",
    "\n",
    "            # 保存第一个iter的梯度\n",
    "            if iter == 0 and batch_idx == 0:\n",
    "                first_iter_gradient = {}\n",
    "                for name, param in model.named_parameters():\n",
    "                    first_iter_gradient[name] = param.grad.clone()\n",
    "                # 保存 BatchNorm 层的 running mean 和 running variance\n",
    "                for name, module in model.named_modules():\n",
    "                    if isinstance(module, nn.BatchNorm2d):\n",
    "                        first_iter_gradient[name + '.running_mean'] = module.running_mean.clone()\n",
    "                        first_iter_gradient[name + '.running_var'] = module.running_var.clone()\n",
    "\n",
    "        epoch_loss.append(sum(batch_loss)/len(batch_loss))\n",
    "\n",
    "    return model.state_dict(), sum(epoch_loss) / len(epoch_loss), first_iter_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {
    "id": "qsPZGD4Iem5w"
   },
   "outputs": [],
   "source": [
    "# 计算模型权重的差异，并根据学习率 lr 对权重差异进行缩放\n",
    "def weight_differences(n_w, p_w, lr):\n",
    "    w_diff = copy.deepcopy(n_w)\n",
    "    for key in w_diff.keys():\n",
    "        if 'num_batches_tracked' in key:\n",
    "            continue\n",
    "        w_diff[key] = (p_w[key] - n_w[key]) * lr\n",
    "    return w_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {
    "id": "040d862vbG9M"
   },
   "outputs": [],
   "source": [
    "# 也是本地训练，不过引入了Fed-C的权重修正机制\n",
    "def update_weights_correction(model_weight, dataset, learning_rate, local_epoch, c_i, c_s):\n",
    "    model = cnncifar().to(device)\n",
    "    model.load_state_dict(model_weight)\n",
    "\n",
    "    model.train()\n",
    "    epoch_loss = []\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    Tensor_set = TensorDataset(torch.Tensor(dataset[0]).to(device), torch.Tensor(dataset[1]).to(device))\n",
    "    data_loader = DataLoader(Tensor_set, batch_size=bc_size, shuffle=True)\n",
    "\n",
    "    for iter in range(local_epoch):\n",
    "        batch_loss = []\n",
    "        for batch_idx, (images, labels) in enumerate(data_loader):\n",
    "            model.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs['output'], labels.long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            batch_loss.append(loss.sum().item()/images.shape[0])\n",
    "        epoch_loss.append(sum(batch_loss)/len(batch_loss))\n",
    "        corrected_graident = weight_differences(c_i, c_s, learning_rate)\n",
    "        orginal_model_weight = model.state_dict()\n",
    "        corrected_model_weight = weight_differences(corrected_graident, orginal_model_weight, 1)  # 这里缩放权重为1\n",
    "        model.load_state_dict(corrected_model_weight)\n",
    "\n",
    "    return model.state_dict(),  sum(epoch_loss) / len(epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {
    "id": "qeFHXRuEo5Du"
   },
   "outputs": [],
   "source": [
    "def average_weights(w):\n",
    "    \"\"\"\n",
    "    Returns the average of the weights.\n",
    "    \"\"\"\n",
    "    w_avg = copy.deepcopy(w[0])\n",
    "    for key in w_avg.keys():\n",
    "        if 'num_batches_tracked' in key:\n",
    "            continue\n",
    "        for i in range(1, len(w)):\n",
    "            w_avg[key] += w[i][key]\n",
    "        w_avg[key] = torch.div(w_avg[key], len(w))\n",
    "    return w_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {
    "id": "pLG9RrFffbl8"
   },
   "outputs": [],
   "source": [
    "# baseline: server-only\n",
    "def server_only(initial_w, global_round, gamma, E):\n",
    "    test_model = cnncifar().to(device)\n",
    "    train_w = copy.deepcopy(initial_w)\n",
    "    test_acc = []\n",
    "    train_loss = []\n",
    "    \n",
    "    \n",
    "    for round in tqdm(range(global_round)):\n",
    "        # if gamma > 0.001:\n",
    "        #     gamma = gamma * 0.99\n",
    "        # Server side local training\n",
    "        \n",
    "        \n",
    "        # 从comb中（论文中说明为全部训练数据）选择固定比率的server数据（并且是保证类别均衡的）\n",
    "        # server_data = select_subset(comb_client_data, server_percentage)\n",
    "                \n",
    "        update_server_w, round_loss, _ = update_weights(train_w, server_data, gamma, E)\n",
    "        train_w = update_server_w\n",
    "        test_model.load_state_dict(train_w)\n",
    "        train_loss.append(round_loss)\n",
    "        \n",
    "        # 新的测试（针对全部测试数据进行）\n",
    "        test_acc.append(test_inference(test_model, test_dataset))\n",
    "    \n",
    "        # Test Accuracy\n",
    "        # test_a = 0\n",
    "        # for i in client_test_data:\n",
    "        #     ac = test_inference(test_model,i)[0]\n",
    "        #     test_a = test_a + ac\n",
    "        # test_a = test_a/len(client_test_data)\n",
    "        # test_acc.append(test_a)\n",
    "        # print(test_a)\n",
    "    return test_acc, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {
    "id": "nGtAn28aok2c"
   },
   "outputs": [],
   "source": [
    "def fedavg(initial_w, global_round, eta, K, M):\n",
    "    test_model = cnncifar().to(device)\n",
    "    train_w = copy.deepcopy(initial_w)\n",
    "    test_acc = []\n",
    "    train_loss = []\n",
    "    for round in tqdm(range(global_round)):\n",
    "        local_weights, local_loss = [], []\n",
    "        # Client side local training\n",
    "        # if eta > 0.001:\n",
    "        #     eta = eta * 0.99\n",
    "        sampled_client = random.sample(range(client_num), M)\n",
    "        for i in sampled_client:\n",
    "            update_client_w, client_round_loss, _ = update_weights(train_w, client_data[i], eta, K)\n",
    "            local_weights.append(update_client_w)\n",
    "            local_loss.append(client_round_loss)\n",
    "\n",
    "        train_w = average_weights(local_weights)\n",
    "\n",
    "        # Test Accuracy\n",
    "        test_model.load_state_dict(train_w)\n",
    "        loss_avg = sum(local_loss)/ len(local_loss)\n",
    "        train_loss.append(loss_avg)\n",
    "        \n",
    "        # 新的测试（针对全部测试数据进行）\n",
    "        test_acc.append(test_inference(test_model, test_dataset))\n",
    "            \n",
    "        # test_a = 0\n",
    "        # for i in client_test_data:\n",
    "        #     ac = test_inference(test_model,i)[0]\n",
    "        #     test_a = test_a + ac\n",
    "        # test_a = test_a/len(client_test_data)\n",
    "        # test_acc.append(test_a)\n",
    "#         print(test_a)\n",
    "    return test_acc, train_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybridFL(initial_w, global_round, eta, K, M):\n",
    "    \"\"\"\n",
    "    HybridFL算法：FedAvg改进，服务器也作为一个普通客户端参与训练。\n",
    "    \n",
    "    参数:\n",
    "    - initial_w: 初始模型权重\n",
    "    - global_round: 全局训练轮数\n",
    "    - eta: 学习率\n",
    "    - K: 本地训练轮数\n",
    "    - M: 每轮采样的客户端数量\n",
    "    \"\"\"\n",
    "    test_model = cnncifar().to(device)  # 初始化测试模型\n",
    "    train_w = copy.deepcopy(initial_w)     # 当前全局权重\n",
    "    test_acc = []                          # 保存每轮测试精度\n",
    "    train_loss = []                        # 保存每轮训练损失\n",
    "    \n",
    "    for round in tqdm(range(global_round)):\n",
    "        local_weights, local_loss = [], []  # 存储每个客户端/服务器的权重和损失\n",
    "\n",
    "        # 随机采样 M 个客户端\n",
    "        sampled_client = random.sample(range(client_num), M)\n",
    "\n",
    "        # 客户端本地训练\n",
    "        for i in sampled_client:\n",
    "            update_client_w, client_round_loss, _ = update_weights(train_w, client_data[i], eta, K)\n",
    "            local_weights.append(update_client_w)\n",
    "            local_loss.append(client_round_loss)\n",
    "\n",
    "        # 服务器参与训练\n",
    "        update_server_w, server_round_loss, _ = update_weights(train_w, server_data, eta, K)\n",
    "        local_weights.append(update_server_w)   # 将服务器权重加入列表\n",
    "        local_loss.append(server_round_loss)    # 将服务器损失加入列表\n",
    "\n",
    "        # 权重聚合\n",
    "        train_w = average_weights(local_weights)\n",
    "\n",
    "        # 评估模型性能\n",
    "        test_model.load_state_dict(train_w)\n",
    "        loss_avg = sum(local_loss) / len(local_loss)\n",
    "        train_loss.append(loss_avg)\n",
    "\n",
    "        # 新的测试（针对全部测试数据进行）\n",
    "        test_acc.append(test_inference(test_model, test_dataset))\n",
    "    \n",
    "        \n",
    "        # test_a = 0\n",
    "        # for i in client_test_data:  # 遍历所有客户端测试数据\n",
    "        #     ac = test_inference(test_model, i)[0]\n",
    "        #     test_a += ac\n",
    "        # test_a = test_a / len(client_test_data)\n",
    "        # test_acc.append(test_a)\n",
    "        \n",
    "        # # 打印每轮的结果\n",
    "        # print(f\"Round {round + 1}: Test Accuracy = {test_a:.4f}, Train Loss = {loss_avg:.4f}\")\n",
    "    \n",
    "    return test_acc, train_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {
    "id": "uzxW0sUxRGth"
   },
   "outputs": [],
   "source": [
    "def CLG_SGD(initial_w, global_round, eta, gamma, K, E, M):\n",
    "    test_model = cnncifar().to(device)\n",
    "    train_w = copy.deepcopy(initial_w)\n",
    "    test_acc = []\n",
    "    train_loss = []\n",
    "    \n",
    "    for round in tqdm(range(global_round)):\n",
    "        # 学习率衰减，这里默认注释掉了\n",
    "        # if eta > 0.001:\n",
    "        #     eta = eta * 0.99\n",
    "        # if gamma > 0.001:\n",
    "        #     gamma = gamma * 0.99\n",
    "        local_weights, local_loss = [], []\n",
    "        # Client side local training\n",
    "        # 从总共client_num客户端中选择M个训练\n",
    "        sampled_client = random.sample(range(client_num), M)\n",
    "        for i in sampled_client:\n",
    "            update_client_w, client_round_loss, _ = update_weights(train_w, client_data[i], eta, K)\n",
    "            local_weights.append(update_client_w)\n",
    "            local_loss.append(client_round_loss)\n",
    "        train_w = average_weights(local_weights)\n",
    "        # Server side local training\n",
    "        \n",
    "        \n",
    "        # 从comb中（论文中说明为全部训练数据）选择固定比率的server数据（并且是保证类别均衡的）\n",
    "        # TODO_241216:这里是每一轮都重新选择数据（但保证类别比例是一样的，都是按照comb中的比例），我的场景中可以这样吗？\n",
    "        # server_data = select_subset(comb_client_data, server_percentage)\n",
    "        \n",
    "        update_server_w, round_loss, _ = update_weights(train_w, server_data, gamma, E)\n",
    "        train_w = update_server_w\n",
    "        local_loss.append(round_loss)\n",
    "\n",
    "        # Test Accuracy\n",
    "        test_model.load_state_dict(train_w)\n",
    "        loss_avg = sum(local_loss)/ len(local_loss)\n",
    "        train_loss.append(loss_avg)   # 计算所有客户端和服务器一起的平均损失\n",
    "\n",
    "        # 新的测试（针对全部测试数据进行）\n",
    "        test_acc.append(test_inference(test_model, test_dataset))\n",
    "    \n",
    "        # test_a = 0\n",
    "        # # 遍历客户端测试数据，计算平均准确率\n",
    "        # for i in client_test_data:\n",
    "        #     ac = test_inference(test_model,i)[0]\n",
    "        #     test_a = test_a + ac\n",
    "        # test_a = test_a/len(client_test_data)\n",
    "        # test_acc.append(test_a)\n",
    "#         print(test_a)\n",
    "    return test_acc, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def CLG_Mut(net_glob, global_round, eta, gamma, K, E, M):\n",
    "    \n",
    "    net_glob.train()\n",
    "    \n",
    "    test_model = cnncifar().to(device)\n",
    "    train_w = copy.deepcopy(net_glob.state_dict())\n",
    "    test_acc = []\n",
    "    train_loss = []\n",
    "    \n",
    "    w_locals = []\n",
    "    for i in range(M):\n",
    "        w_locals.append(copy.deepcopy(net_glob.state_dict()))\n",
    "    \n",
    "    delta_list = []\n",
    "    max_rank = 0\n",
    "    w_old = copy.deepcopy(net_glob.state_dict())\n",
    "    w_old_s1 = copy.deepcopy(net_glob.state_dict())\n",
    "    \n",
    "    for round in tqdm(range(global_round)):\n",
    "        # 学习率衰减，这里默认注释掉了\n",
    "        # if eta > 0.001:\n",
    "        #     eta = eta * 0.99\n",
    "        # if gamma > 0.001:\n",
    "        #     gamma = gamma * 0.99\n",
    "        local_weights, local_loss = [], []\n",
    "        # Client side local training\n",
    "        # 从总共client_num客户端中选择M个训练\n",
    "        idxs_users = np.random.choice(range(client_num), M, replace=False)\n",
    "        for i, idx in enumerate(idxs_users):\n",
    "            net_glob.load_state_dict(w_locals[i])\n",
    "            \n",
    "            update_client_w, client_round_loss, _ = update_weights(copy.deepcopy(net_glob.state_dict()), client_data[idx], eta, K)\n",
    "            w_locals[i] = copy.deepcopy(update_client_w)\n",
    "            local_loss.append(client_round_loss)\n",
    "\n",
    "        # Global Model Generation\n",
    "        w_agg = Aggregation(w_locals, None)  \n",
    "        \n",
    "        # Server side local training\n",
    "        update_server_w, round_loss, _ = update_weights(w_agg, server_data, gamma, E)\n",
    "        local_loss.append(round_loss)\n",
    "\n",
    "        # Test Accuracy\n",
    "        test_model.load_state_dict(update_server_w)\n",
    "        loss_avg = sum(local_loss)/ len(local_loss)\n",
    "        train_loss.append(loss_avg)   # 计算所有客户端和服务器一起的平均损失\n",
    "\n",
    "\n",
    "        # 新的测试（针对全部测试数据进行）\n",
    "        test_acc.append(test_inference(test_model, test_dataset))\n",
    "\n",
    "        # 按照server训练的方向，进行mutation\n",
    "        w_delta = FedSub(update_server_w, w_agg, 1.0)\n",
    "        # 计算模型更新w_delta的L2范数（平方和），衡量模型更新程度的大小\n",
    "        rank = delta_rank(w_delta)\n",
    "        # print(rank)\n",
    "        if rank > max_rank:\n",
    "            max_rank = rank\n",
    "        alpha = radius  # 论文中的alpha，衡量Mutation的幅度\n",
    "        # alpha = min(max(args.radius, max_rank/rank),(10.0-args.radius) * (1 - iter/args.epochs) + args.radius)\n",
    "        w_locals = mutation_spread(\n",
    "            round, update_server_w, M, w_delta, alpha\n",
    "        )\n",
    "\n",
    "    return test_acc, train_loss\n",
    "\n",
    "\n",
    "def mutation_spread(iter, w_glob, m, w_delta, alpha):\n",
    "\n",
    "    w_locals_new = []\n",
    "    ctrl_cmd_list = []\n",
    "    ctrl_rate = mut_acc_rate * (\n",
    "        1.0 - min(iter * 1.0 / mut_bound, 1.0)\n",
    "    )  # 论文中的βt，随着iter逐渐从β0减小到0\n",
    "\n",
    "    # k代表模型中的参数数量，对每个参数按照client数量分配v（论文中是按照每一层分配）\n",
    "    for k in w_glob.keys():\n",
    "        ctrl_list = []\n",
    "        for i in range(0, int(m / 2)):\n",
    "            ctrl = random.random()  # 随机数，范围：[0,1)\n",
    "            # 这里分ctrl感觉没什么必要，shuffle后都会随机掉\n",
    "            if ctrl > 0.5:\n",
    "                ctrl_list.append(1.0)\n",
    "                ctrl_list.append(1.0 * (-1.0 + ctrl_rate))\n",
    "            else:\n",
    "                ctrl_list.append(1.0 * (-1.0 + ctrl_rate))\n",
    "                ctrl_list.append(1.0)\n",
    "        random.shuffle(ctrl_list)  # 打乱列表\n",
    "        ctrl_cmd_list.append(ctrl_list)\n",
    "    cnt = 0\n",
    "    for j in range(m):\n",
    "        w_sub = copy.deepcopy(w_glob)\n",
    "        if not (cnt == m - 1 and m % 2 == 1):\n",
    "            ind = 0\n",
    "            for k in w_sub.keys():\n",
    "                w_sub[k] = w_sub[k] + w_delta[k] * ctrl_cmd_list[ind][j] * alpha\n",
    "                ind += 1\n",
    "        cnt += 1\n",
    "        w_locals_new.append(w_sub)\n",
    "\n",
    "    return w_locals_new\n",
    "\n",
    "\n",
    "\n",
    "# 加权平均聚合，lens代表了权重，如果没有定义就是普通平均（FedMut就每定义）\n",
    "def Aggregation(w, lens):\n",
    "    w_avg = None\n",
    "    if lens == None:\n",
    "        total_count = len(w)\n",
    "        lens = []\n",
    "        for i in range(len(w)):\n",
    "            lens.append(1.0)\n",
    "    else:\n",
    "        total_count = sum(lens)\n",
    "\n",
    "    for i in range(0, len(w)):\n",
    "        if i == 0:\n",
    "            w_avg = copy.deepcopy(w[0])\n",
    "            for k in w_avg.keys():\n",
    "                w_avg[k] = w[i][k] * lens[i]\n",
    "        else:\n",
    "            for k in w_avg.keys():\n",
    "                w_avg[k] += w[i][k] * lens[i]\n",
    "\n",
    "    for k in w_avg.keys():\n",
    "        w_avg[k] = torch.div(w_avg[k], total_count)\n",
    "\n",
    "    return w_avg\n",
    "\n",
    "\n",
    "\n",
    "def FedSub(w, w_old, weight):\n",
    "    w_sub = copy.deepcopy(w)\n",
    "    for k in w_sub.keys():\n",
    "        w_sub[k] = (w[k] - w_old[k]) * weight\n",
    "\n",
    "    return w_sub\n",
    "\n",
    "def delta_rank(delta_dict):\n",
    "    cnt = 0\n",
    "    dict_a = torch.Tensor(0)\n",
    "    s = 0\n",
    "    for p in delta_dict.keys():\n",
    "        a = delta_dict[p]\n",
    "        a = a.view(-1)\n",
    "        if cnt == 0:\n",
    "            dict_a = a\n",
    "        else:\n",
    "            dict_a = torch.cat((dict_a, a), dim=0)\n",
    "\n",
    "        cnt += 1\n",
    "        # print(sim)\n",
    "    s = torch.norm(dict_a, dim=0)\n",
    "    return s\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置训练参数 -- CIFAR100\n",
    "\n",
    "# 随机性\n",
    "data_random_fix = False  # 是否固定数据采样的随机性\n",
    "seed_num = 42\n",
    "\n",
    "gpu = 1  # 默认使用gpu 1 (第二个)\n",
    "verbose = False  # 调试模式，输出一些中间信息\n",
    "\n",
    "client_num = 200\n",
    "non_iid = 0.5  # Dirichlet 分布参数，数值越小数据越不均匀可根据需要调整\n",
    "size_per_client = 200  # 每个客户端的数据量（训练）\n",
    "server_percentage = 0.05  # 服务器端用于微调的数据比例\n",
    "\n",
    "\n",
    "# 模型相关\n",
    "momentum = 0.9\n",
    "weight_decay = 0.0001  # 模型权重衰减参数，强制参数向0靠拢（和学习率衰减不一样！）这个是给我的原始代码中就是这样\n",
    "bc_size = 128\n",
    "num_classes = 20  # 分别数量，CIFAR100中是20（FedMut和CLGG都是这么采用的）\n",
    "\n",
    "# 联邦训练的超参数\n",
    "global_round = 100  # 全局训练轮数，可根据需要调整\n",
    "eta = 0.1  # 客户端端学习率，从{0.01, 0.1, 1}中调优\n",
    "gamma = 0.05  # 服务器端学习率 从{0.005， 0.05， 0.5中调有}\n",
    "K = 5  # 客户端本地训练轮数，从1，3，5中选\n",
    "E = 5  # 服务器本地训练轮数，从1，3，5中选\n",
    "M = 10  # 每一轮抽取客户端\n",
    "\n",
    "# FedMut中参数\n",
    "radius = 1  # alpha，控制mutation的幅度\n",
    "mut_acc_rate = 0.3  # 论文中的β0\n",
    "mut_bound = 50  # Tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Traning Client Total: 38192 1910 1935 1654 1768 1862 1595 1705 2044 1965 1912 2235 2012 1909 1957 1929 2348 1827 1796 2073 1756\n",
      "Client 0: 191 0 33 0 1 29 3 1 5 2 4 0 40 0 18 8 7 1 33 4 2\n",
      "Client 1: 193 0 25 7 0 6 13 14 5 0 0 0 5 9 5 1 28 36 22 0 17\n",
      "Client 2: 191 1 0 21 5 1 5 3 19 0 1 3 29 5 41 6 4 6 29 5 7\n",
      "Client 3: 192 4 8 7 10 0 21 6 2 89 0 2 2 20 0 11 3 2 5 0 0\n",
      "Client 4: 192 5 18 68 14 12 0 2 15 2 3 22 1 2 4 3 10 9 2 0 0\n",
      "Client 5: 191 8 0 0 75 2 14 4 0 4 33 5 2 5 25 2 5 1 2 2 2\n",
      "Client 6: 191 3 15 0 24 0 0 0 0 4 5 0 4 44 3 0 21 0 2 0 66\n",
      "Client 7: 192 3 26 26 4 7 5 0 5 20 16 2 1 28 2 20 0 0 0 23 4\n",
      "Client 8: 190 5 26 5 10 0 0 10 4 10 7 22 0 24 11 3 5 2 0 25 21\n",
      "Client 9: 190 2 29 0 7 0 5 0 0 0 0 5 16 0 14 30 9 69 2 0 2\n",
      "Server: 1899 95 96 82 88 93 79 85 102 98 95 111 100 95 97 96 117 91 89 103 87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:46<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLG-Mut 训练完成！\n",
      "各轮平均测试精度: [5.150000095367432, 12.630000114440918, 6.539999961853027, 10.850000381469727, 7.940000057220459, 9.600000381469727, 5.0, 5.0, 5.0, 9.119999885559082, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0]\n",
      "各轮平均训练损失: [0.03216291566842846, 0.03179636984035633, 0.03293015806489119, 0.03153816249558453, 0.03146963545071025, 0.03158506521606998, 0.0325428275818498, 0.03229223529499131, 0.03217393475164248, 0.03226103835122001, 0.03210867382438795, 0.032081056765502505, 0.03218563590104923, 0.03216717990554222, 0.03187413346387913, 0.03195145314445389, 0.03176204293861729, 0.03161742340662273, 0.031339671666493124, 0.03104762886424062, 0.031359628976207594, 0.03194360054601106, 0.03130743274107384, 0.031216991557366524, 0.031359309297124265, 0.03134887323801393, 0.03016581363812981, 0.03039748598705068, 0.031677823844413464, 0.031437533996317914, 0.03146602865435222, 0.03164546141483777, 0.03063061387957483, 0.030812455007412278, 0.030619312900503414, 0.03118678667319643, 0.030787936511997918, 0.03060064238268304, 0.03133130796282865, 0.03120782505792241, 0.03072667954963303, 0.029966886261623058, 0.030563004113394656, 0.03039122972209725, 0.02985328268381643, 0.031108331588092484, 0.03090661693236617, 0.03103273613598263, 0.031662054280417955, 0.030927565556067793, 0.030522314090148158, 0.031181479992132343, 0.03157494417212833, 0.03123783189719621, 0.03131753880703895, 0.03079412817024898, 0.030931736247394977, 0.030974814336659884, 0.031222634079012455, 0.03161352545265588, 0.031282666084491755, 0.03122667997148305, 0.0303480328300373, 0.03142229306011373, 0.03136239215003582, 0.031156880210221297, 0.03134192155553058, 0.0311972785675087, 0.03130456258191168, 0.031556158866304244, 0.031147770966106124, 0.031237474476288288, 0.030836441288892315, 0.031134168889981242, 0.031408958001835956, 0.03111720249586134, 0.031389841291623685, 0.030954207310731195, 0.03160422190016029, 0.03110602355511696, 0.031054455285727398, 0.030975679845176633, 0.031484692775516084, 0.03123581853154482, 0.03171451846587928, 0.03138673948021677, 0.03111202648308732, 0.03026335227741196, 0.03001072200731714, 0.030639680012099147, 0.03142400988225327, 0.031166453226859712, 0.0318475508634114, 0.031062026278065247, 0.03206403183585078, 0.03160662719104313, 0.02967591203759138, 0.0307817745195191, 0.030411783772437376, 0.03142755470909898]\n",
      "最终测试精度: 5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:20<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server only 训练完成！\n",
      "各轮平均测试精度: [5.0, 9.6899995803833, 11.970000267028809, 17.190000534057617, 18.670000076293945, 20.68000030517578, 21.3700008392334, 19.299999237060547, 20.450000762939453, 18.649999618530273, 19.020000457763672, 17.030000686645508, 15.970000267028809, 16.3799991607666, 16.68000030517578, 17.079999923706055, 16.329999923706055, 15.760000228881836, 15.40999984741211, 15.789999961853027, 16.719999313354492, 17.030000686645508, 16.3799991607666, 15.170000076293945, 15.399999618530273, 16.940000534057617, 15.550000190734863, 15.90999984741211, 14.539999961853027, 14.789999961853027, 13.350000381469727, 15.010000228881836, 15.880000114440918, 15.760000228881836, 15.550000190734863, 13.579999923706055, 14.020000457763672, 13.670000076293945, 15.119999885559082, 13.859999656677246, 14.949999809265137, 12.970000267028809, 13.90999984741211, 13.369999885559082, 11.90999984741211, 13.039999961853027, 12.390000343322754, 14.229999542236328, 14.210000038146973, 12.989999771118164, 13.8100004196167, 11.890000343322754, 12.539999961853027, 12.390000343322754, 12.829999923706055, 13.15999984741211, 5.03000020980835, 6.550000190734863, 8.140000343322754, 10.369999885559082, 11.380000114440918, 12.449999809265137, 13.510000228881836, 12.890000343322754, 10.640000343322754, 12.59000015258789, 12.0, 8.890000343322754, 9.710000038146973, 11.6899995803833, 7.400000095367432, 8.869999885559082, 9.25, 10.1899995803833, 10.390000343322754, 11.3100004196167, 10.100000381469727, 9.529999732971191, 8.359999656677246, 6.179999828338623, 8.229999542236328, 8.930000305175781, 6.449999809265137, 6.289999961853027, 7.309999942779541, 7.329999923706055, 6.53000020980835, 5.050000190734863, 5.010000228881836, 5.010000228881836, 5.010000228881836, 5.010000228881836, 5.010000228881836, 5.010000228881836, 5.010000228881836, 5.010000228881836, 5.010000228881836, 5.010000228881836, 5.0, 5.019999980926514]\n",
      "各轮平均训练损失: [0.0236901152017889, 0.023445009679716324, 0.022537803528975477, 0.021478370988619662, 0.020572113022208214, 0.01886956951491001, 0.016244561814607303, 0.013264115873341248, 0.009576437276297733, 0.007481078262675867, 0.005770542220824697, 0.005682854933310243, 0.003936538153525291, 0.003974286743477451, 0.0039651565888832755, 0.0037064915004032563, 0.0033385276743588023, 0.003206605323673026, 0.0032944385556872595, 0.004144701127019476, 0.0034410010592800183, 0.00301012125128091, 0.002433358803848414, 0.0025487313038982146, 0.006349796614191869, 0.0016161897670291946, 0.003925853957254527, 0.004153382080633228, 0.00424675424055942, 0.002256045403416672, 0.007365150906796919, 0.007950576837073047, 0.0015607500497111762, 0.0010786693947861367, 0.0010650019588769356, 0.0065577798960817476, 0.00732722126255015, 0.005336769355223094, 0.0042104469536516425, 0.004446987832440905, 0.0029707345487535396, 0.007022323913607858, 0.0073692091061759776, 0.006882330569122392, 0.007081195383791078, 0.007451106413496757, 0.009074819849055504, 0.005094124032213494, 0.0029355843483965054, 0.005708774396945865, 0.005325266636488813, 0.008589886747521125, 0.007575502551125936, 0.007278490090899379, 0.00643923662057454, 0.004461911428426725, 0.017078129519473448, 0.023577308816330456, 0.021782752143631103, 0.016525670644766257, 0.009524071463137121, 0.007122856889419095, 0.0047574620484447, 0.004650900027862637, 0.009333843902925559, 0.007441659433523489, 0.00910173499150161, 0.013647623774058815, 0.012230305995014599, 0.009200212489059223, 0.019830071898554437, 0.020021199471900397, 0.01700242362637943, 0.013392785322907557, 0.011903553372800257, 0.009637797887718475, 0.009139013490247951, 0.011317088947083071, 0.015367020364978418, 0.019368130354170114, 0.01850803774917887, 0.01608256767785345, 0.018374917863221187, 0.023345735179858045, 0.021405477899350107, 0.019194133795240775, 0.01793696477092408, 0.021171807124862604, 0.023717067740463022, 0.023680946398004193, 0.023679296173085673, 0.023679738608290472, 0.02367865128889448, 0.023678799572159938, 0.023677989726543797, 0.02367574535287058, 0.023676609989731482, 0.023676014877275515, 0.02367067046950911, 0.02366477992095494]\n",
      "最终测试精度: 5.019999980926514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:24<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fedavg训练完成！\n",
      "各轮平均测试精度: [5.0, 5.0, 5.0, 5.0, 5.0, 5.179999828338623, 5.0, 5.0, 5.0, 5.019999980926514, 5.099999904632568, 5.480000019073486, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 7.0, 5.179999828338623, 5.199999809265137, 4.989999771118164, 7.449999809265137, 7.760000228881836, 7.340000152587891, 5.0, 5.0, 5.630000114440918, 8.520000457763672, 7.809999942779541, 9.479999542236328, 9.479999542236328, 8.529999732971191, 7.28000020980835, 10.600000381469727, 10.460000038146973, 9.359999656677246, 9.279999732971191, 10.640000343322754, 7.699999809265137, 9.630000114440918, 7.699999809265137, 7.050000190734863, 11.069999694824219, 11.260000228881836, 12.270000457763672, 9.430000305175781, 10.239999771118164, 10.859999656677246, 12.699999809265137, 13.75, 13.930000305175781, 11.479999542236328, 8.930000305175781, 12.890000343322754, 14.09000015258789, 13.079999923706055, 13.390000343322754, 15.5600004196167, 11.770000457763672, 13.680000305175781, 15.8100004196167, 14.15999984741211, 13.890000343322754, 14.5, 14.859999656677246, 15.34000015258789, 15.569999694824219, 15.399999618530273, 16.43000030517578, 16.739999771118164, 14.869999885559082, 16.889999389648438, 17.6200008392334, 18.209999084472656, 17.780000686645508, 17.139999389648438, 16.43000030517578, 18.719999313354492, 16.649999618530273, 16.690000534057617, 18.100000381469727, 19.299999237060547, 16.489999771118164, 16.68000030517578, 15.65999984741211, 17.889999389648438]\n",
      "各轮平均训练损失: [0.03272314076938777, 0.032646227142705146, 0.03226452547523791, 0.03318322882495474, 0.03233690854083184, 0.03253591714797788, 0.03161722317897393, 0.03203228776824575, 0.0293672986042672, 0.03126076827203919, 0.030229505394783873, 0.031822546346118634, 0.03183598845715401, 0.03097746063220671, 0.031187255261818213, 0.030425689376778607, 0.031237684317372016, 0.030902883429117355, 0.032255296697027286, 0.030287780169598082, 0.03021269512568066, 0.031039235652375912, 0.03032866159402171, 0.031948862864756726, 0.03061150671090019, 0.030284846068130762, 0.030914655245408172, 0.03179183988876364, 0.030132564626454517, 0.03130843800651391, 0.03181363583461254, 0.030769720496852386, 0.03151129127089476, 0.03060326261282369, 0.031124719926283285, 0.030353498222625397, 0.030336942013679785, 0.030613879972785446, 0.028977953136232675, 0.030548660914846103, 0.03183561930372651, 0.030433757178718622, 0.02901094111715095, 0.02943228945361246, 0.029751723463121105, 0.029064305419430024, 0.029496346770446397, 0.028923278963853726, 0.028589631755257056, 0.02796325914072185, 0.02848878095187323, 0.02871977212604194, 0.026721399043155347, 0.028666717807501352, 0.028584574904458003, 0.02841730170177741, 0.02857435753403862, 0.027423238898247833, 0.028262097980968088, 0.02777418204211521, 0.027723757669984896, 0.028442254012465952, 0.0273185102126282, 0.02683672068551988, 0.026506524328306153, 0.02714929833310214, 0.027755556929131658, 0.026986530910122597, 0.026402405791197608, 0.026312779930164322, 0.02593341729379762, 0.02564825998321919, 0.02574636044654339, 0.026950296766494315, 0.02540690433959854, 0.024289049054876714, 0.02483745043092505, 0.025396341571258862, 0.024673166932826177, 0.024118282609895604, 0.0245156757896742, 0.023436601635711846, 0.02331310255772876, 0.02293208255915943, 0.023332622370112507, 0.023162941351821575, 0.0233050483520496, 0.022815963990339333, 0.021141998906083585, 0.022457133359427405, 0.022913316122274183, 0.021698405418810122, 0.02074225597200658, 0.022579423193123217, 0.021486787788710132, 0.021425767999889964, 0.020769156613115902, 0.020999308470149244, 0.0208903232864378, 0.02119346104022967]\n",
      "最终测试精度: 17.889999389648438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:44<00:00,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLG_SGD 训练完成！\n",
      "各轮平均测试精度: [5.059999942779541, 9.859999656677246, 5.0, 5.0, 6.489999771118164, 9.789999961853027, 11.569999694824219, 12.869999885559082, 16.850000381469727, 17.280000686645508, 17.420000076293945, 16.3700008392334, 15.720000267028809, 14.770000457763672, 14.59000015258789, 14.5, 14.25, 13.600000381469727, 14.100000381469727, 13.930000305175781, 14.510000228881836, 13.390000343322754, 15.180000305175781, 14.520000457763672, 15.149999618530273, 14.539999961853027, 14.9399995803833, 14.449999809265137, 14.369999885559082, 14.550000190734863, 14.859999656677246, 15.25, 14.6899995803833, 14.640000343322754, 14.920000076293945, 14.5600004196167, 14.829999923706055, 15.029999732971191, 14.630000114440918, 15.010000228881836, 14.649999618530273, 15.369999885559082, 15.34000015258789, 15.130000114440918, 15.300000190734863, 15.1899995803833, 15.34000015258789, 15.600000381469727, 15.729999542236328, 15.25, 15.220000267028809, 15.710000038146973, 15.739999771118164, 15.4399995803833, 15.510000228881836, 15.5, 15.649999618530273, 15.789999961853027, 15.880000114440918, 15.970000267028809, 16.09000015258789, 16.149999618530273, 16.040000915527344, 16.280000686645508, 15.800000190734863, 15.800000190734863, 15.8100004196167, 16.31999969482422, 15.869999885559082, 16.059999465942383, 16.31999969482422, 16.530000686645508, 16.440000534057617, 16.479999542236328, 16.1200008392334, 16.399999618530273, 16.149999618530273, 16.649999618530273, 16.350000381469727, 16.75, 16.540000915527344, 16.479999542236328, 16.770000457763672, 16.6200008392334, 16.600000381469727, 16.360000610351562, 16.290000915527344, 16.600000381469727, 16.889999389648438, 16.719999313354492, 16.510000228881836, 16.540000915527344, 16.389999389648438, 16.25, 16.170000076293945, 16.489999771118164, 16.440000534057617, 16.360000610351562, 16.239999771118164, 16.65999984741211]\n",
      "各轮平均训练损失: [0.03231238408754026, 0.03229423649816588, 0.03119980297886331, 0.03289046580689944, 0.03279583614974494, 0.03161776153808849, 0.029286990292261297, 0.028108259979823934, 0.025959112096164517, 0.02501155393686484, 0.023250524278211563, 0.022059152278955937, 0.020750228702850627, 0.023399455651532532, 0.0240951212018604, 0.02330809328881909, 0.025768702309297474, 0.028107145809656838, 0.033238968467873616, 0.02726655309899451, 0.033540702279703453, 0.03698152122965301, 0.02040773960139654, 0.030996540285465116, 0.030031226613331265, 0.03179087890775998, 0.03285126801455038, 0.03312431819643388, 0.033499769354995684, 0.02822912071719682, 0.028785565101303114, 0.029444743681443973, 0.029401345168437718, 0.028062489158405746, 0.02724967126468225, 0.025675919519511828, 0.027904232377560255, 0.02643504273722624, 0.024706331664076712, 0.02168356349119493, 0.024783832803080764, 0.021108410605260038, 0.022076078855076973, 0.022594831501589162, 0.021037020829364924, 0.02116093512757622, 0.021660218762486496, 0.019018684378984144, 0.01896525985618451, 0.020116035223189284, 0.02071965190709014, 0.018989198968968526, 0.01890388767567149, 0.018409037076599858, 0.018432736146492427, 0.01723305412185844, 0.01716517867719283, 0.01834971390687559, 0.02027343853245868, 0.019288977678447002, 0.018206296998223598, 0.017842838782459194, 0.017418666998146398, 0.01595371990401499, 0.014889923124023602, 0.016306385307041715, 0.014752290122203847, 0.014873932884792202, 0.015916092842363547, 0.01715253551103987, 0.013910722199248894, 0.01573914754207313, 0.015665488002755808, 0.016156282171754802, 0.014808211327143215, 0.014886813271335503, 0.01638442867314336, 0.01705101820544116, 0.01569523601238568, 0.01599401347157833, 0.015957929601742124, 0.014305184461261139, 0.016279215083840698, 0.013098311672607315, 0.015895371898520808, 0.014140554681410133, 0.014073070515846792, 0.014349067442906422, 0.014511335000834437, 0.015249510683733382, 0.01518327198669358, 0.014027344583408957, 0.014860836082096594, 0.015180008105228994, 0.014187404798245469, 0.01432924618596267, 0.014053184485636116, 0.014499663803599587, 0.014412599302669611, 0.012678235144735577]\n",
      "最终测试精度: 16.65999984741211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 准备数据集\n",
    "# 这部分是我加的\n",
    "\n",
    "cifar, test_dataset = CIFAR100()\n",
    "prob = get_prob(non_iid, client_num, class_num=20)\n",
    "# client_data, client_test_data = create_data(prob, size_per_client, cifar, N=20)\n",
    "client_data = create_data_all_train(prob, size_per_client, cifar, N=20)   # 这里改为全部构建训练集\n",
    "\n",
    "# 将测试标签转换为粗类别\n",
    "test_dataset.targets = sparse2coarse(test_dataset.targets)\n",
    "\n",
    "# 如果需要确保测试标签为整数类型\n",
    "test_dataset.targets = test_dataset.targets.astype(int)\n",
    "\n",
    "\n",
    "\n",
    "all_images = []\n",
    "all_labels = []\n",
    "for data in client_data:\n",
    "    all_images.extend(data[0])\n",
    "    all_labels.extend(data[1])\n",
    "comb_client_data = [np.array(all_images), np.array(all_labels)]\n",
    "\n",
    "# 输出comb_client_data情况\n",
    "imgs, lbls = comb_client_data\n",
    "lbls = np.array(lbls)\n",
    "total_count = len(lbls)\n",
    "unique_classes, counts = np.unique(lbls, return_counts=True)\n",
    "\n",
    "# 创建一个长度为20的数组记录各类别计数，默认0\n",
    "class_counts = [0]*20\n",
    "for cls, cnt in zip(unique_classes, counts):\n",
    "    class_counts[cls] = cnt\n",
    "\n",
    "# 打印格式：Total: 总数 类别0计数 类别1计数 ... 类别19计数\n",
    "print(\"Traning Client Total: {}\".format(\" \".join([str(total_count)] + [str(c) for c in class_counts])))\n",
    "\n",
    "\n",
    "# 打印每个客户端训练数据情况（只输出前10个）\n",
    "for i, (imgs, lbls) in enumerate(client_data[:10]):\n",
    "    lbls = np.array(lbls)\n",
    "    total_count = len(lbls)\n",
    "    unique_classes, counts = np.unique(lbls, return_counts=True)\n",
    "    # 创建一个长度为20的数组记录各类别计数，默认0\n",
    "    class_counts = [0]*20\n",
    "    for cls, cnt in zip(unique_classes, counts):\n",
    "        class_counts[cls] = cnt\n",
    "    # 打印格式：Client i: 总数 类别0计数 类别1计数 ... 类别19计数\n",
    "    print(\"Client {}: {}\".format(i, \" \".join([str(total_count)] + [str(c) for c in class_counts])))\n",
    "    \n",
    "\n",
    "# 提前生成固定的服务器数据\n",
    "# Modify: 这是我后来修改的\n",
    "server_data = select_subset(comb_client_data, server_percentage)\n",
    "\n",
    "s_imgs, s_lbls = server_data\n",
    "s_lbls = np.array(s_lbls)\n",
    "total_count = len(s_lbls)\n",
    "unique_classes, counts = np.unique(s_lbls, return_counts=True)\n",
    "class_counts = [0]*20\n",
    "for cls, cnt in zip(unique_classes, counts):\n",
    "    class_counts[cls] = cnt\n",
    "\n",
    "# 输出格式: Server: 总数 类别0计数 类别1计数 ... 类别19计数\n",
    "print(\"Server: {}\".format(\" \".join([str(total_count)] + [str(c) for c in class_counts])))\n",
    "# print(\"  前5个标签: \", lbls[:5])\n",
    "# print(\"  前5个数据形状: \", [server_data[0][j].shape for j in range(min(5, len(server_data[0])))])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 用了FedMut中定义的CNN网络\n",
    "\n",
    "init_model = cnncifar().to(device)\n",
    "initial_w = copy.deepcopy(init_model.state_dict())\n",
    "\n",
    "\n",
    "# CLG_Mut训练，这里不同在于直接传初始化后的模型\n",
    "test_acc, train_loss = CLG_Mut(init_model, global_round, eta, gamma, K, E, M)\n",
    "\n",
    "# 打印训练过程中的结果\n",
    "print(\"CLG-Mut 训练完成！\")\n",
    "print(\"各轮平均测试精度:\", test_acc)\n",
    "print(\"各轮平均训练损失:\", train_loss)\n",
    "print(\"最终测试精度:\", test_acc[-1] if len(test_acc) > 0 else \"无数据\")\n",
    "\n",
    "\n",
    "# Server-only训练\n",
    "test_acc, train_loss = server_only(initial_w, global_round, gamma, E)\n",
    "\n",
    "# 打印训练过程中的结果\n",
    "print(\"Server only 训练完成！\")\n",
    "print(\"各轮平均测试精度:\", test_acc)\n",
    "print(\"各轮平均训练损失:\", train_loss)\n",
    "print(\"最终测试精度:\", test_acc[-1] if len(test_acc) > 0 else \"无数据\")\n",
    "\n",
    "\n",
    "# fedavg训练\n",
    "test_acc, train_loss = fedavg(initial_w, global_round, eta, K, M)\n",
    "\n",
    "# 打印训练过程中的结果\n",
    "print(\"fedavg训练完成！\")\n",
    "print(\"各轮平均测试精度:\", test_acc)\n",
    "print(\"各轮平均训练损失:\", train_loss)\n",
    "print(\"最终测试精度:\", test_acc[-1] if len(test_acc) > 0 else \"无数据\")\n",
    "\n",
    "\n",
    "\n",
    "# # hybridfl训练\n",
    "# test_acc, train_loss = hybridFL(initial_w, global_round, eta, K, M)\n",
    "\n",
    "# # 打印训练过程中的结果\n",
    "# print(\"hrbridFL训练完成！\")\n",
    "# print(\"各轮平均测试精度:\", test_acc)\n",
    "# print(\"各轮平均训练损失:\", train_loss)\n",
    "# print(\"最终测试精度:\", test_acc[-1] if len(test_acc) > 0 else \"无数据\")\n",
    "\n",
    "# CLG_SGD训练\n",
    "test_acc, train_loss = CLG_SGD(initial_w, global_round, eta, gamma, K, E, M)\n",
    "\n",
    "# 打印训练过程中的结果\n",
    "print(\"CLG_SGD 训练完成！\")\n",
    "print(\"各轮平均测试精度:\", test_acc)\n",
    "print(\"各轮平均训练损失:\", train_loss)\n",
    "print(\"最终测试精度:\", test_acc[-1] if len(test_acc) > 0 else \"无数据\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "env8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
