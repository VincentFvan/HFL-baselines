{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "gSK1TSekTVeu"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.functional as func\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "9-WEXWakTwf8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True' # 解决由于多次加载 OpenMP 相关动态库而引起的冲突"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sns3blEITybc",
    "outputId": "120095fb-5597-4ada-8c12-b4470d8ad28e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec 17 14:41:17 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090        Off | 00000000:21:00.0 Off |                  Off |\n",
      "| 30%   25C    P8              13W / 350W |   3343MiB / 24564MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 4090        Off | 00000000:E1:00.0 Off |                  Off |\n",
      "| 30%   29C    P8              15W / 350W |     14MiB / 24564MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      4557      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "|    0   N/A  N/A    717162      C   /home/anaconda/envs/env8/bin/python        3326MiB |\n",
      "|    1   N/A  N/A      4557      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "96gqMCQneWho"
   },
   "outputs": [],
   "source": [
    "# MobileNetV2（比lenet更复杂的CNN网络）网络中的线性瓶颈结构，原文中用于CIFAR-100任务\n",
    "class LinearBottleNeck(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride, t=6, class_num=100):\n",
    "        super().__init__()\n",
    "\n",
    "        self.residual = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels * t, 1),\n",
    "            nn.BatchNorm2d(in_channels * t),\n",
    "            nn.ReLU6(inplace=True),\n",
    "\n",
    "            nn.Conv2d(in_channels * t, in_channels * t, 3, stride=stride, padding=1, groups=in_channels * t),\n",
    "            nn.BatchNorm2d(in_channels * t),\n",
    "            nn.ReLU6(inplace=True),\n",
    "\n",
    "            nn.Conv2d(in_channels * t, out_channels, 1),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "\n",
    "        self.stride = stride\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        residual = self.residual(x)\n",
    "\n",
    "        if self.stride == 1 and self.in_channels == self.out_channels:\n",
    "            residual += x\n",
    "\n",
    "        return residual\n",
    "\n",
    "class MobileNetV2(nn.Module):\n",
    "\n",
    "    def __init__(self, class_num=20):\n",
    "        super().__init__()\n",
    "\n",
    "        self.pre = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU6(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.stage1 = LinearBottleNeck(32, 16, 1, 1)\n",
    "        self.stage2 = self._make_stage(2, 16, 24, 2, 6)\n",
    "        self.stage3 = self._make_stage(3, 24, 32, 2, 6)\n",
    "        self.stage4 = self._make_stage(4, 32, 64, 2, 6)\n",
    "        self.stage5 = self._make_stage(3, 64, 96, 1, 6)\n",
    "        self.stage6 = self._make_stage(3, 96, 160, 1, 6)\n",
    "        self.stage7 = LinearBottleNeck(160, 320, 1, 6)\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(320, 1280, 1),\n",
    "            nn.BatchNorm2d(1280),\n",
    "            nn.ReLU6(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Conv2d(1280, class_num, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pre(x)\n",
    "        x = self.stage1(x)\n",
    "        x = self.stage2(x)\n",
    "        x = self.stage3(x)\n",
    "        x = self.stage4(x)\n",
    "        x = self.stage5(x)\n",
    "        x = self.stage6(x)\n",
    "        x = self.stage7(x)\n",
    "        x = self.conv1(x)\n",
    "        x = F.adaptive_avg_pool2d(x, 1)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _make_stage(self, repeat, in_channels, out_channels, stride, t):\n",
    "\n",
    "        layers = []\n",
    "        layers.append(LinearBottleNeck(in_channels, out_channels, stride, t))\n",
    "\n",
    "        while repeat - 1:\n",
    "            layers.append(LinearBottleNeck(out_channels, out_channels, 1, t))\n",
    "            repeat -= 1\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "def mobilenetv2():\n",
    "    return MobileNetV2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "QkvtGtMuUDmr"
   },
   "outputs": [],
   "source": [
    "def test_inference(model, test):\n",
    "    \"\"\" Returns the test accuracy and loss.\n",
    "    \"\"\"\n",
    "    tensor_x = torch.Tensor(test[0]).to(device)\n",
    "    tensor_y = torch.Tensor(test[1]).to(device)\n",
    "    test_dataset = TensorDataset(tensor_x, tensor_y)\n",
    "\n",
    "    model.eval()\n",
    "    loss, total, correct = 0.0, 0.0, 0.0\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    testloader = DataLoader(test_dataset, batch_size=128,\n",
    "                            shuffle=True)\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(testloader):\n",
    "        with torch.no_grad():  # 在测试过程中不需要计算梯度，节省内存和加速计算\n",
    "        # Inference\n",
    "            outputs = model(images)\n",
    "            batch_loss = criterion(outputs, labels.long())\n",
    "            loss += batch_loss.item() * labels.size(0) # 计算损失值，更好反映模型输出概率分布与真实标签的差距\n",
    "\n",
    "        # Prediction\n",
    "            _, pred_labels = torch.max(outputs, 1)\n",
    "            pred_labels = pred_labels.view(-1)\n",
    "            correct += torch.sum(torch.eq(pred_labels, labels)).item()\n",
    "            total += len(labels)\n",
    "    #print(correct,\"/\",total)\n",
    "    accuracy = correct/total\n",
    "    return accuracy, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "jURskA9VUJOF"
   },
   "outputs": [],
   "source": [
    "# 将CIFAR-100的100个类别转为20个类别（粒度更粗，降低任务复杂度）\n",
    "def sparse2coarse(targets):\n",
    "    \"\"\"Convert Pytorch CIFAR100 sparse targets to coarse targets.\n",
    "\n",
    "    Usage:\n",
    "        trainset = torchvision.datasets.CIFAR100(path)\n",
    "        trainset.targets = sparse2coarse(trainset.targets)\n",
    "    \"\"\"\n",
    "    coarse_labels = np.array([ 4,  1, 14,  8,  0,  6,  7,  7, 18,  3,\n",
    "                               3, 14,  9, 18,  7, 11,  3,  9,  7, 11,\n",
    "                               6, 11,  5, 10,  7,  6, 13, 15,  3, 15,\n",
    "                               0, 11,  1, 10, 12, 14, 16,  9, 11,  5,\n",
    "                               5, 19,  8,  8, 15, 13, 14, 17, 18, 10,\n",
    "                               16, 4, 17,  4,  2,  0, 17,  4, 18, 17,\n",
    "                               10, 3,  2, 12, 12, 16, 12,  1,  9, 19,\n",
    "                               2, 10,  0,  1, 16, 12,  9, 13, 15, 13,\n",
    "                              16, 19,  2,  4,  6, 19,  5,  5,  8, 19,\n",
    "                              18,  1,  2, 15,  6,  0, 17,  8, 14, 13])\n",
    "    return coarse_labels[targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "jcZ7eQGET_YJ"
   },
   "outputs": [],
   "source": [
    "# 共有6w个图像，其中5w训练，1w测试\n",
    "def CIFAR100():\n",
    "    '''Return Cifar100\n",
    "    '''\n",
    "    train_dataset = torchvision.datasets.CIFAR100(root='../data/CIFAR-100',\n",
    "                                            train=True,\n",
    "                                            transform=transforms.ToTensor(),\n",
    "                                            download=True)\n",
    "    test_dataset = torchvision.datasets.CIFAR100(root='../data/CIFAR-100',\n",
    "                                            train=False,\n",
    "                                            transform=transforms.ToTensor(),\n",
    "                                            download=True)\n",
    "    total_img,total_label = [],[]\n",
    "    for imgs,labels in train_dataset:\n",
    "        total_img.append(imgs.numpy())\n",
    "        total_label.append(labels)\n",
    "    for imgs,labels in test_dataset:\n",
    "        total_img.append(imgs.numpy())\n",
    "        total_label.append(labels) \n",
    "    total_img = np.array(total_img)\n",
    "    total_label = np.array(sparse2coarse(total_label))\n",
    "\n",
    "    cifar = [total_img, total_label]\n",
    "    return cifar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "f1eQhNtPUMOF"
   },
   "outputs": [],
   "source": [
    "# 基于 Dirichlet 分布 来模拟non-IID。返回一个形状为 (client_num, class_num) 的概率矩阵，每一行代表一个客户端对各类别的概率分布。\n",
    "def get_prob(non_iid, client_num, class_num = 20):\n",
    "    return np.random.dirichlet(np.repeat(non_iid, class_num), client_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "npT3idE-UaGm"
   },
   "outputs": [],
   "source": [
    "def create_data(prob, size_per_client, dataset, N=20):\n",
    "    total_each_class = size_per_client * np.sum(prob, 0)\n",
    "    data, label = dataset\n",
    "\n",
    "\n",
    "    # 为每个类别随机采样数据\n",
    "    all_class_set = []\n",
    "    for i in range(N):\n",
    "        size = total_each_class[i]\n",
    "        sub_data = data[label == i]\n",
    "        sub_label = label[label == i]\n",
    "\n",
    "        rand_indx = np.random.choice(len(sub_data), size=int(size), replace=False).astype(int)\n",
    "        sub2_data, sub2_label = sub_data[rand_indx], sub_label[rand_indx]\n",
    "        all_class_set.append((sub2_data, sub2_label))\n",
    "\n",
    "    index = [0] * N\n",
    "    clients, test = [], []\n",
    "\n",
    "    for m in range(prob.shape[0]):  # 遍历客户端\n",
    "        labels, images = [], []  # 训练数据\n",
    "        tlabels, timages = [], [] # 测试数据\n",
    "\n",
    "        # TODO_241216：这里每个client的测试集和它的训练集分布相同，并且最后测试时，也是计算所有client中的准确率的平均值\n",
    "        # TODO_241216：别的FL方法也是这样做的吗？我也要这样做吗？\n",
    "        for n in range(N):\n",
    "            # 80%用于训练，20%用于测试\n",
    "            # 这里的int向下取整，会导致实际的数据量比计算略小\n",
    "            start, end = index[n], index[n] + int(prob[m][n] * size_per_client * 0.8)\n",
    "            test_start, test_end = end, index[n] + int(prob[m][n] * size_per_client)\n",
    "\n",
    "            image, label = all_class_set[n][0][start:end], all_class_set[n][1][start:end]\n",
    "            test_image, test_label = all_class_set[n][0][test_start:test_end], all_class_set[n][1][test_start:test_end]\n",
    "\n",
    "            # 记录当前类别的数据分配进度\n",
    "            index[n] += int(prob[m][n] * size_per_client)\n",
    "\n",
    "            labels.extend(label)\n",
    "            images.extend(image)\n",
    "\n",
    "            tlabels.extend(test_label)\n",
    "            timages.extend(test_image)\n",
    "\n",
    "        clients.append((np.array(images), np.array(labels)))\n",
    "        test.append((np.array(timages), np.array(tlabels)))\n",
    "\n",
    "    return clients, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "DCsR6_QqUzJ8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# 合并所有客户端的测试数据 （上面讲测试数据分成了不同的客户端）\n",
    "# 但并没有使用，用途不明\n",
    "def comb_client_test_func(client_test_data):\n",
    "    comb_client_test_image = []\n",
    "    comb_client_test_label = []\n",
    "    for i in range(client_num):\n",
    "        comb_client_test_image.extend(list(client_test_data[i][0]))\n",
    "        comb_client_test_label.extend(list(client_test_data[i][1]))\n",
    "    \n",
    "    # 将测试图片和标签合并为 numpy 数组\n",
    "    comb_client_test_image = np.array(comb_client_test_image)\n",
    "    comb_client_test_label = np.array(comb_client_test_label)\n",
    "    \n",
    "    label_count = Counter(comb_client_test_label)\n",
    "    print(\"测试集类别分布：\")\n",
    "    for label, count in sorted(label_count.items()):\n",
    "        print(f\"类别 {label}: {count} 个样本\")\n",
    "    \n",
    "    return [comb_client_test_image, comb_client_test_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "JEKzDM0yW3DW"
   },
   "outputs": [],
   "source": [
    "# 从数据集中按类别均匀抽取子集，并按照指定的比例 percentage 进行缩减，同时对数据进行随机打乱\n",
    "def select_subset(whole_set, percentage):\n",
    "    a = whole_set[0]\n",
    "    b = whole_set[1]\n",
    "    if len(a) != len(b):\n",
    "        raise ValueError(\"Both arrays should have the same length.\")\n",
    "\n",
    "    if not 0 <= percentage <= 1:\n",
    "        raise ValueError(\"Percentage must be between 0 and 1.\")\n",
    "\n",
    "    unique_classes = np.unique(b)\n",
    "\n",
    "    a_prime = []\n",
    "    b_prime = []\n",
    "\n",
    "    for cls in unique_classes:\n",
    "        indices = np.where(b == cls)[0]\n",
    "        subset_size = int(len(indices) * percentage)\n",
    "\n",
    "        selected_indices = np.random.choice(indices, subset_size, replace=False)\n",
    "\n",
    "        a_prime.extend(a[selected_indices])\n",
    "        b_prime.extend(b[selected_indices])\n",
    "\n",
    "    a_prime, b_prime = np.array(a_prime), np.array(b_prime)\n",
    "\n",
    "    # Shuffle arrays to randomize the order of elements\n",
    "    shuffle_indices = np.random.permutation(len(a_prime))\n",
    "    a_prime, b_prime = a_prime[shuffle_indices], b_prime[shuffle_indices]\n",
    "\n",
    "    return [a_prime, b_prime]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Traning Client Total: 30217 1476 1564 1294 1598 1206 1792 1640 1641 1573 1450 1642 1491 1733 1503 1454 1411 1391 1265 1502 1591\n",
      "Client 0: 151 9 0 1 3 6 0 6 22 7 28 0 10 0 10 11 20 8 4 6 0\n",
      "Client 1: 152 14 8 1 3 1 8 5 16 5 0 0 24 30 26 3 0 0 1 2 5\n",
      "Client 2: 149 1 0 2 1 12 0 4 6 3 34 27 0 15 0 0 15 1 21 4 3\n",
      "Client 3: 152 1 0 0 0 3 10 18 0 9 0 5 2 35 24 25 2 1 11 6 0\n",
      "Client 4: 151 17 0 2 9 45 41 5 0 10 2 0 4 3 3 0 0 5 0 2 3\n",
      "Client 5: 153 0 0 2 21 0 12 0 6 0 22 1 0 9 3 1 9 0 32 33 2\n",
      "Client 6: 152 22 5 1 0 3 3 44 24 0 8 2 1 0 20 2 1 0 10 0 6\n",
      "Client 7: 149 3 9 4 10 3 0 4 0 1 3 10 7 4 57 11 3 0 16 2 2\n",
      "Client 8: 153 0 0 20 0 0 1 26 11 0 0 11 0 0 25 0 4 22 33 0 0\n",
      "Client 9: 152 16 0 3 2 11 0 8 6 0 5 7 12 0 5 11 44 22 0 0 0\n",
      "Client 10: 153 8 11 0 0 25 15 0 7 1 0 2 3 54 4 1 1 0 2 16 3\n",
      "Client 11: 152 0 4 0 9 0 4 20 6 16 1 26 5 5 5 7 0 37 7 0 0\n",
      "Client 12: 152 3 24 15 0 4 1 0 26 0 5 0 9 5 5 0 14 14 14 10 3\n",
      "Client 13: 151 33 30 0 1 1 2 0 2 1 1 4 34 0 5 3 2 0 7 7 18\n",
      "Client 14: 151 4 0 0 1 1 33 5 3 4 8 6 0 2 9 17 7 12 0 33 6\n",
      "Client 15: 149 0 0 9 36 1 13 2 32 21 0 1 5 0 4 0 1 17 7 0 0\n",
      "Client 16: 149 4 32 0 6 0 40 0 2 0 7 0 15 12 0 2 1 22 2 4 0\n",
      "Client 17: 150 0 3 50 0 12 13 0 9 0 5 1 3 12 16 3 0 10 0 1 12\n",
      "Client 18: 151 0 1 22 27 5 0 16 1 10 0 1 17 4 9 5 4 0 17 2 10\n",
      "Client 19: 152 0 39 2 9 6 11 0 12 0 8 5 5 4 6 1 5 0 6 15 18\n",
      "Client 20: 154 0 0 17 28 14 0 0 12 1 14 9 4 11 0 12 0 2 0 12 18\n",
      "Client 21: 154 2 21 1 0 13 5 0 5 1 7 53 31 0 3 4 0 2 4 0 2\n",
      "Client 22: 151 3 20 0 10 16 7 3 0 2 12 0 15 22 11 8 1 1 10 10 0\n",
      "Client 23: 152 8 0 0 0 34 0 41 2 2 6 0 12 9 1 28 0 7 1 0 1\n",
      "Client 24: 151 2 2 16 0 2 48 22 4 0 15 4 3 1 0 4 8 0 1 19 0\n",
      "Client 25: 151 2 1 2 25 8 47 0 20 6 0 0 2 2 6 2 0 1 23 1 3\n",
      "Client 26: 150 51 7 2 10 1 8 14 1 2 0 0 11 0 9 6 0 4 3 3 18\n",
      "Client 27: 152 7 6 12 3 1 0 2 26 0 8 6 10 0 2 0 7 1 0 43 18\n",
      "Client 28: 153 2 17 0 11 17 2 17 4 0 0 0 3 11 4 2 10 37 6 10 0\n",
      "Client 29: 154 0 4 49 26 1 6 2 0 2 0 0 3 0 9 2 3 3 19 25 0\n",
      "Client 30: 149 0 30 4 9 2 0 24 0 27 1 17 8 0 12 5 3 4 0 2 1\n",
      "Client 31: 153 20 2 2 0 16 16 48 6 7 0 0 0 6 20 0 1 0 4 5 0\n",
      "Client 32: 150 1 5 1 16 3 1 17 0 23 4 1 13 10 4 0 10 28 7 4 2\n",
      "Client 33: 151 0 2 13 0 5 4 38 3 9 0 5 3 7 6 13 5 21 0 14 3\n",
      "Client 34: 152 0 12 0 9 7 14 0 6 0 0 5 21 9 22 1 9 5 7 10 15\n",
      "Client 35: 149 5 2 26 4 7 0 1 1 1 0 17 3 13 23 11 1 0 11 18 5\n",
      "Client 36: 152 9 7 11 13 2 2 23 0 0 3 0 38 4 2 5 2 5 8 2 16\n",
      "Client 37: 152 2 11 8 1 4 0 22 0 0 10 0 0 15 14 26 0 0 0 23 16\n",
      "Client 38: 150 23 1 5 7 2 5 13 6 1 8 23 15 4 0 15 0 4 6 3 9\n",
      "Client 39: 150 3 0 2 1 7 9 36 4 0 19 0 2 7 14 9 16 20 0 0 1\n",
      "Client 40: 151 0 0 8 8 24 22 0 0 17 5 0 0 40 0 0 2 0 1 10 14\n",
      "Client 41: 151 4 0 2 9 3 16 2 0 53 0 8 0 2 5 14 7 5 1 3 17\n",
      "Client 42: 150 32 8 0 8 0 1 4 4 15 10 12 0 14 3 4 0 1 20 13 1\n",
      "Client 43: 150 0 2 4 3 2 24 20 15 0 1 9 0 0 0 13 2 5 4 19 27\n",
      "Client 44: 147 0 0 10 0 6 32 9 5 4 2 36 4 0 10 12 0 0 10 4 3\n",
      "Client 45: 148 7 1 3 2 1 13 0 0 0 2 45 1 1 4 0 32 17 2 0 17\n",
      "Client 46: 153 0 48 9 0 1 0 2 8 1 0 31 2 10 16 0 0 20 1 1 3\n",
      "Client 47: 150 2 2 0 0 5 28 6 8 1 26 9 0 1 4 17 0 6 7 26 2\n",
      "Client 48: 151 1 3 17 3 4 40 14 13 2 3 3 10 25 0 3 0 0 2 1 7\n",
      "Client 49: 150 2 14 0 2 16 4 29 8 1 19 4 7 0 1 1 3 27 7 5 0\n",
      "Client 50: 150 18 4 0 0 12 8 0 21 4 1 0 0 0 10 23 32 0 10 7 0\n",
      "Client 51: 153 18 9 1 1 19 0 6 25 0 0 18 1 22 0 0 0 1 24 2 6\n",
      "Client 52: 152 9 33 15 4 2 12 11 15 0 11 2 4 0 9 21 0 2 2 0 0\n",
      "Client 53: 151 0 1 5 14 4 3 0 0 0 19 0 7 0 0 0 2 41 0 14 41\n",
      "Client 54: 150 19 15 0 13 8 17 1 10 0 23 18 1 1 13 4 1 0 0 4 2\n",
      "Client 55: 150 9 0 18 0 0 2 0 33 0 0 1 20 10 0 0 1 0 40 0 16\n",
      "Client 56: 150 0 0 2 3 0 1 1 2 11 0 38 4 15 11 4 0 4 16 10 28\n",
      "Client 57: 149 10 0 23 0 0 0 0 3 3 4 28 0 1 1 14 10 11 24 1 16\n",
      "Client 58: 152 0 0 3 0 5 14 2 9 5 10 33 21 16 0 7 1 4 1 21 0\n",
      "Client 59: 152 0 41 0 0 1 10 9 8 5 0 0 31 5 0 0 18 1 18 0 5\n",
      "Client 60: 150 18 0 1 1 0 1 31 6 0 0 0 6 5 4 21 2 9 18 4 23\n",
      "Client 61: 150 0 1 15 0 0 5 11 13 12 16 38 8 4 2 1 0 0 24 0 0\n",
      "Client 62: 149 25 16 0 9 3 19 9 4 19 4 5 27 4 1 0 0 0 0 0 4\n",
      "Client 63: 153 2 1 1 1 4 0 3 7 0 23 16 28 29 19 2 0 0 11 4 2\n",
      "Client 64: 150 0 7 22 0 1 5 9 1 5 7 15 5 0 14 7 14 1 0 4 33\n",
      "Client 65: 150 4 9 1 1 5 0 55 8 6 10 7 2 6 4 11 4 1 0 1 15\n",
      "Client 66: 151 2 30 13 1 38 0 1 0 3 2 4 0 10 13 11 1 6 0 4 12\n",
      "Client 67: 150 4 7 36 0 0 13 6 8 4 5 4 6 1 2 1 18 2 4 5 24\n",
      "Client 68: 153 1 0 1 20 1 5 4 13 32 0 6 23 9 5 0 2 0 9 16 6\n",
      "Client 69: 153 2 1 7 6 5 15 0 0 0 8 0 2 0 0 34 4 4 26 0 39\n",
      "Client 70: 150 2 0 0 0 31 3 0 6 7 15 20 35 4 0 5 5 2 9 0 6\n",
      "Client 71: 152 7 8 0 0 0 0 1 1 3 19 27 1 0 27 14 41 1 2 0 0\n",
      "Client 72: 154 45 1 7 14 0 5 4 0 7 3 1 0 40 1 2 0 10 9 0 5\n",
      "Client 73: 151 7 0 20 2 11 9 2 8 29 5 0 34 1 0 0 0 19 3 0 1\n",
      "Client 74: 151 13 5 1 24 1 26 0 23 0 17 0 0 16 1 7 2 0 3 8 4\n",
      "Client 75: 150 33 3 39 5 1 16 6 2 5 0 0 0 13 0 0 6 2 1 1 17\n",
      "Client 76: 149 1 0 45 0 7 6 1 1 27 0 1 24 2 7 8 0 0 0 10 9\n",
      "Client 77: 150 35 29 0 5 0 1 4 0 2 16 0 9 9 0 30 0 5 2 3 0\n",
      "Client 78: 149 1 14 0 0 2 2 11 1 1 0 20 0 16 43 1 35 0 0 2 0\n",
      "Client 79: 152 0 8 31 0 7 0 1 8 7 1 10 4 3 5 5 3 51 5 0 3\n",
      "Client 80: 152 0 0 0 0 7 24 20 0 18 12 1 0 7 2 2 1 28 0 17 13\n",
      "Client 81: 151 2 4 1 3 2 2 12 1 24 2 16 13 5 27 7 7 0 1 16 6\n",
      "Client 82: 151 1 0 0 0 0 0 62 0 11 5 3 20 10 1 30 4 2 2 0 0\n",
      "Client 83: 153 4 5 9 0 2 3 1 0 0 6 6 22 3 22 44 1 1 0 0 24\n",
      "Client 84: 152 0 39 1 0 3 0 6 0 2 17 3 11 0 47 0 15 0 7 1 0\n",
      "Client 85: 151 11 0 76 17 5 12 3 0 2 8 0 4 8 0 0 3 0 2 0 0\n",
      "Client 86: 151 11 4 5 0 4 0 0 2 0 23 0 0 0 31 4 0 13 13 0 41\n",
      "Client 87: 151 1 0 0 5 4 2 5 5 17 0 0 5 1 0 10 7 52 2 18 17\n",
      "Client 88: 151 21 0 3 78 3 0 9 4 2 1 12 1 1 0 4 0 0 5 2 5\n",
      "Client 89: 151 0 3 4 9 4 0 1 98 0 6 6 0 14 0 0 0 2 1 1 2\n",
      "Client 90: 148 19 10 3 0 18 19 15 24 2 12 3 2 7 0 4 0 0 1 4 5\n",
      "Client 91: 153 0 3 1 13 1 0 18 1 22 1 0 3 54 3 4 6 0 0 8 15\n",
      "Client 92: 152 35 26 5 16 18 0 2 0 0 0 3 0 8 20 1 4 0 4 0 10\n",
      "Client 93: 150 1 17 7 1 0 0 1 12 6 6 5 26 6 3 10 7 0 39 3 0\n",
      "Client 94: 151 30 0 2 8 2 0 1 7 10 2 0 3 1 4 9 43 7 3 2 17\n",
      "Client 95: 151 28 1 0 0 0 7 2 29 11 9 5 7 0 0 1 8 6 0 5 32\n",
      "Client 96: 151 20 0 3 1 0 0 66 0 1 1 14 0 7 7 0 0 5 2 15 9\n",
      "Client 97: 153 8 0 1 5 7 13 0 3 7 17 0 0 2 5 34 4 2 15 29 1\n",
      "Client 98: 154 0 1 0 0 1 3 15 31 0 0 48 5 0 0 8 0 10 17 0 15\n",
      "Client 99: 150 14 0 1 6 9 0 1 20 27 8 24 0 13 0 6 0 5 10 6 0\n",
      "Client 100: 151 0 1 2 3 2 32 22 0 2 17 0 2 1 1 5 1 16 24 3 17\n",
      "Client 101: 151 0 12 0 2 14 1 0 4 1 0 20 10 2 0 33 1 16 9 16 10\n",
      "Client 102: 152 1 1 2 0 1 0 21 34 23 0 0 4 34 7 3 12 1 6 0 2\n",
      "Client 103: 152 1 0 0 16 0 0 2 1 16 6 5 3 24 11 0 1 9 5 52 0\n",
      "Client 104: 151 0 0 43 0 1 12 6 0 4 1 6 10 28 0 16 14 2 0 8 0\n",
      "Client 105: 153 10 0 4 49 4 4 4 1 0 3 5 2 33 0 7 6 2 2 9 8\n",
      "Client 106: 152 11 23 1 1 1 17 0 41 16 0 0 0 20 6 3 9 0 0 3 0\n",
      "Client 107: 151 2 46 2 15 0 20 4 1 9 1 0 0 6 1 16 10 4 8 0 6\n",
      "Client 108: 149 5 5 15 13 3 0 0 5 0 0 0 3 34 23 12 2 10 0 5 14\n",
      "Client 109: 148 7 4 24 0 2 5 4 11 14 0 7 1 21 0 0 3 18 0 20 7\n",
      "Client 110: 152 8 42 1 0 16 10 8 2 4 4 0 5 28 2 0 0 15 1 4 2\n",
      "Client 111: 150 5 13 1 48 1 6 1 0 0 34 2 8 6 1 0 0 12 4 8 0\n",
      "Client 112: 152 6 6 0 3 7 0 7 0 0 10 19 6 21 0 9 16 0 0 22 20\n",
      "Client 113: 152 0 0 2 34 4 13 1 43 0 1 2 0 12 4 2 23 5 3 0 3\n",
      "Client 114: 150 7 5 2 9 1 4 0 1 1 30 0 6 0 15 3 24 7 22 10 3\n",
      "Client 115: 152 0 3 0 8 4 2 9 10 0 2 71 14 3 0 0 0 0 26 0 0\n",
      "Client 116: 151 39 2 1 2 0 11 1 0 14 2 8 8 6 32 2 2 5 1 0 15\n",
      "Client 117: 150 4 30 0 3 0 20 1 2 59 2 6 1 0 7 12 2 1 0 0 0\n",
      "Client 118: 151 22 8 11 2 24 15 4 0 1 5 1 1 9 3 3 0 0 13 29 0\n",
      "Client 119: 149 2 0 0 3 0 0 2 11 11 6 53 3 0 0 9 1 33 7 6 2\n",
      "Client 120: 152 6 23 0 22 2 11 13 0 0 3 8 0 0 28 0 2 14 1 10 9\n",
      "Client 121: 151 4 0 0 10 33 0 26 0 5 1 0 18 29 6 7 0 0 2 7 3\n",
      "Client 122: 150 0 4 0 0 3 5 0 34 0 38 14 1 8 1 8 11 3 11 4 5\n",
      "Client 123: 151 9 1 1 5 0 14 2 1 38 10 0 0 22 14 0 0 1 12 9 12\n",
      "Client 124: 151 3 0 4 3 25 18 13 0 2 40 0 22 0 1 1 0 0 1 0 18\n",
      "Client 125: 151 2 0 0 2 6 1 23 0 10 0 20 14 13 8 2 18 13 17 0 2\n",
      "Client 126: 151 0 29 0 4 19 5 20 1 0 12 6 10 11 23 0 0 1 3 7 0\n",
      "Client 127: 150 0 5 4 13 1 27 3 9 14 0 0 2 2 4 29 31 1 1 3 1\n",
      "Client 128: 150 4 8 4 4 0 22 16 0 33 0 0 0 18 14 0 6 14 3 2 2\n",
      "Client 129: 151 0 11 4 1 3 2 11 1 0 19 40 3 0 0 14 7 0 2 33 0\n",
      "Client 130: 149 10 13 15 6 0 0 0 25 6 0 13 0 6 20 8 1 0 0 5 21\n",
      "Client 131: 152 3 9 0 31 2 1 27 0 7 3 0 7 6 0 0 22 15 17 1 1\n",
      "Client 132: 153 29 5 40 2 1 2 0 0 15 0 1 4 0 25 7 19 0 2 0 1\n",
      "Client 133: 153 9 5 0 3 10 37 14 2 5 27 0 1 1 4 3 10 0 2 11 9\n",
      "Client 134: 149 8 6 1 3 21 4 8 11 26 14 0 0 1 5 7 9 5 0 16 4\n",
      "Client 135: 152 5 44 0 16 3 41 1 5 0 4 0 5 0 0 7 13 8 0 0 0\n",
      "Client 136: 150 0 6 10 0 7 1 1 14 31 14 0 43 7 1 0 4 1 6 0 4\n",
      "Client 137: 152 2 0 1 36 8 32 0 1 27 1 2 3 0 1 7 2 0 21 4 4\n",
      "Client 138: 151 16 23 1 0 0 0 4 1 59 0 14 0 4 0 0 1 12 0 16 0\n",
      "Client 139: 151 1 17 12 6 3 0 4 0 20 9 1 9 0 11 25 1 24 1 3 4\n",
      "Client 140: 149 0 27 5 0 0 2 3 2 0 0 8 14 3 10 7 6 0 0 35 27\n",
      "Client 141: 152 0 9 12 2 5 0 3 0 24 0 2 20 0 8 20 0 0 41 0 6\n",
      "Client 142: 150 6 9 0 13 1 19 1 0 9 11 19 25 1 31 0 2 0 0 3 0\n",
      "Client 143: 150 13 4 2 4 0 0 1 8 2 12 28 1 2 0 10 46 7 3 6 1\n",
      "Client 144: 152 10 66 2 3 0 7 5 11 3 1 6 0 0 4 4 24 5 0 0 1\n",
      "Client 145: 151 3 11 8 1 9 5 17 28 9 5 0 25 14 0 2 2 8 2 0 2\n",
      "Client 146: 151 16 2 1 5 2 0 9 11 1 35 14 2 4 10 18 13 0 0 0 8\n",
      "Client 147: 151 0 0 2 10 0 6 0 5 10 14 1 13 4 0 13 39 2 1 31 0\n",
      "Client 148: 149 9 0 1 29 1 12 20 5 0 24 0 2 4 8 12 5 7 0 2 8\n",
      "Client 149: 150 3 0 14 1 24 1 10 0 3 4 38 6 5 2 11 7 0 14 3 4\n",
      "Client 150: 149 28 2 2 1 13 35 0 1 0 7 21 9 0 1 0 26 0 1 0 2\n",
      "Client 151: 151 5 4 2 51 0 10 10 19 3 9 0 0 2 24 2 0 0 9 0 1\n",
      "Client 152: 153 1 13 3 5 1 1 0 20 0 0 11 2 0 26 1 61 0 2 0 6\n",
      "Client 153: 152 22 4 10 5 14 5 0 1 3 7 0 0 38 23 1 6 8 0 5 0\n",
      "Client 154: 154 3 1 7 1 0 5 13 0 0 7 5 1 23 0 5 0 1 2 74 6\n",
      "Client 155: 150 2 22 8 9 0 0 0 8 6 1 0 17 0 0 44 2 3 0 24 4\n",
      "Client 156: 149 3 0 0 15 4 4 0 12 5 14 29 9 40 5 7 1 0 1 0 0\n",
      "Client 157: 152 4 5 12 12 4 13 0 44 2 21 5 1 5 1 0 0 0 2 0 21\n",
      "Client 158: 152 13 1 0 20 0 0 0 1 2 20 2 7 2 5 3 41 13 4 2 16\n",
      "Client 159: 151 10 0 4 0 9 19 15 16 0 0 3 10 1 14 0 17 2 0 19 12\n",
      "Client 160: 150 0 0 1 15 0 9 0 31 2 9 6 26 11 1 0 0 28 6 3 2\n",
      "Client 161: 153 29 8 2 5 16 11 0 4 1 1 0 1 14 3 0 27 8 0 1 22\n",
      "Client 162: 149 3 9 34 3 2 35 1 33 0 0 4 0 1 0 10 0 7 1 0 6\n",
      "Client 163: 152 7 3 0 0 1 0 11 8 8 42 3 7 2 2 11 15 27 2 3 0\n",
      "Client 164: 149 0 1 3 22 34 5 8 14 0 5 9 4 3 5 0 3 0 5 1 27\n",
      "Client 165: 151 0 0 8 18 23 1 1 5 1 0 10 23 7 7 7 6 2 2 29 1\n",
      "Client 166: 154 0 4 0 0 0 1 38 20 9 2 0 5 30 5 0 17 0 23 0 0\n",
      "Client 167: 149 0 0 10 45 12 2 2 0 11 4 0 0 12 13 0 0 14 9 1 14\n",
      "Client 168: 152 6 1 22 1 1 9 9 1 40 5 11 18 7 0 0 5 7 0 0 9\n",
      "Client 169: 150 0 2 6 12 5 5 0 9 0 4 43 1 11 1 3 0 14 0 26 8\n",
      "Client 170: 151 7 12 0 0 2 10 0 3 25 1 27 1 7 0 15 0 3 18 11 9\n",
      "Client 171: 154 4 0 9 34 19 0 5 5 18 0 1 4 1 0 0 0 18 0 2 34\n",
      "Client 172: 150 7 10 0 0 0 12 7 12 1 11 2 0 38 9 1 26 0 10 4 0\n",
      "Client 173: 151 3 0 10 2 0 31 2 5 9 6 1 6 13 3 15 2 0 1 14 28\n",
      "Client 174: 153 32 11 0 5 3 8 27 7 11 0 2 1 6 0 3 11 14 6 0 6\n",
      "Client 175: 151 0 0 5 0 0 12 14 0 12 0 22 17 46 2 1 12 0 2 1 5\n",
      "Client 176: 153 1 9 2 2 1 2 3 32 5 0 7 0 0 0 35 33 9 0 7 5\n",
      "Client 177: 152 1 2 8 0 1 27 0 3 11 5 11 6 1 22 25 11 11 0 0 7\n",
      "Client 178: 154 1 0 11 2 4 18 2 0 0 9 4 44 0 2 0 1 43 8 3 2\n",
      "Client 179: 150 3 0 0 16 13 2 8 0 0 4 9 0 2 9 0 0 7 7 25 45\n",
      "Client 180: 152 15 0 1 2 0 30 7 8 7 0 0 0 5 11 1 1 2 7 13 42\n",
      "Client 181: 151 10 12 0 6 19 0 20 1 16 3 15 0 2 17 3 1 1 4 2 19\n",
      "Client 182: 150 2 0 0 5 3 6 1 5 2 12 26 0 0 16 2 1 36 24 4 5\n",
      "Client 183: 150 10 0 0 34 16 23 0 0 4 2 1 5 31 3 0 0 7 0 14 0\n",
      "Client 184: 151 17 2 4 0 16 1 6 0 9 10 1 27 2 5 17 18 2 13 0 1\n",
      "Client 185: 150 0 44 3 0 41 1 6 0 1 0 0 19 2 12 3 0 1 5 10 2\n",
      "Client 186: 153 11 2 2 31 0 2 0 16 19 15 0 0 2 19 4 12 5 0 11 2\n",
      "Client 187: 151 4 10 10 1 0 0 6 0 29 2 10 1 0 22 1 0 15 4 2 34\n",
      "Client 188: 150 4 21 3 9 0 0 0 0 15 24 2 0 9 0 62 1 0 0 0 0\n",
      "Client 189: 152 0 3 3 0 0 80 5 29 6 7 1 7 0 1 0 2 5 2 1 0\n",
      "Client 190: 150 0 2 5 11 0 6 5 38 32 3 1 7 5 2 0 12 6 6 6 3\n",
      "Client 191: 152 7 2 11 0 2 18 0 4 20 4 1 23 3 1 28 10 4 0 13 1\n",
      "Client 192: 152 12 0 0 25 0 0 1 5 28 0 1 22 11 4 0 2 6 31 0 4\n",
      "Client 193: 150 0 5 11 0 0 8 48 1 3 8 0 8 2 5 27 4 14 0 5 1\n",
      "Client 194: 151 12 4 3 30 3 0 0 3 0 0 7 3 4 0 1 9 26 0 27 19\n",
      "Client 195: 154 12 4 0 2 6 7 0 10 11 29 0 0 15 1 0 2 2 0 42 11\n",
      "Client 196: 150 4 18 4 6 8 0 4 5 0 12 14 3 21 4 1 1 3 0 12 30\n",
      "Client 197: 150 23 21 1 14 0 4 2 18 17 18 3 7 4 1 3 0 9 3 1 1\n",
      "Client 198: 152 15 1 12 4 13 1 0 3 9 5 2 0 32 39 5 0 0 10 1 0\n",
      "Client 199: 153 8 1 0 39 2 22 0 14 1 10 2 0 0 0 19 17 4 1 0 13\n",
      "Client 0 Test: 39 2 0 1 0 2 0 2 5 2 7 0 3 0 2 3 5 2 2 1 0\n",
      "Client 1 Test: 40 4 2 0 1 0 2 1 4 1 0 0 6 8 7 1 0 0 1 0 2\n",
      "Client 2 Test: 39 0 0 1 0 3 0 1 2 1 9 7 0 4 0 0 4 0 5 1 1\n",
      "Client 3 Test: 40 1 0 0 0 1 3 5 0 2 0 1 0 9 6 7 1 0 3 1 0\n",
      "Client 4 Test: 41 4 1 1 2 12 11 1 0 3 1 0 1 0 1 0 1 1 0 0 1\n",
      "Client 5 Test: 38 0 0 1 5 0 3 0 2 0 6 0 0 2 0 0 3 0 8 8 0\n",
      "Client 6 Test: 39 5 2 1 0 1 1 11 6 1 2 0 0 0 5 0 0 0 2 0 2\n",
      "Client 7 Test: 41 1 3 1 2 1 1 1 0 1 1 3 2 1 14 3 0 0 4 1 1\n",
      "Client 8 Test: 39 0 0 5 0 0 0 6 3 0 0 3 0 0 6 0 1 6 8 0 1\n",
      "Client 9 Test: 39 4 0 1 1 2 0 2 2 0 2 1 3 0 1 3 11 6 0 0 0\n",
      "Client 10 Test: 41 2 3 0 0 7 4 0 2 0 0 0 1 14 1 0 1 0 0 5 1\n",
      "Client 11 Test: 40 0 1 0 3 0 1 6 1 4 0 7 1 1 1 2 0 9 2 1 0\n",
      "Client 12 Test: 40 0 6 4 0 1 0 0 7 0 2 0 3 1 1 0 3 4 4 3 1\n",
      "Client 13 Test: 38 8 8 0 0 1 0 0 0 0 0 1 9 0 1 1 1 0 2 2 4\n",
      "Client 14 Test: 39 1 1 0 0 1 8 1 0 1 2 2 0 1 2 4 2 3 0 8 2\n",
      "Client 15 Test: 42 0 0 2 10 0 4 1 8 5 0 0 1 1 1 0 1 5 2 0 1\n",
      "Client 16 Test: 40 1 9 0 1 0 10 1 1 0 2 0 4 3 0 1 0 6 0 1 0\n",
      "Client 17 Test: 40 0 1 13 0 3 3 0 3 0 2 0 1 4 4 1 0 2 0 0 3\n",
      "Client 18 Test: 40 0 0 6 7 1 0 4 0 3 0 0 5 2 3 1 1 0 4 0 3\n",
      "Client 19 Test: 39 0 10 0 2 2 3 0 4 0 2 1 1 1 2 0 2 0 1 4 4\n",
      "Client 20 Test: 40 1 0 5 7 3 0 0 3 0 3 2 1 3 0 4 0 0 0 3 5\n",
      "Client 21 Test: 36 0 5 0 0 3 1 0 1 0 2 13 8 0 0 1 0 0 1 0 1\n",
      "Client 22 Test: 40 1 5 0 3 4 2 1 0 1 3 0 4 6 3 3 0 0 2 2 0\n",
      "Client 23 Test: 38 2 0 0 0 8 0 10 1 1 1 0 3 2 0 8 0 2 0 0 0\n",
      "Client 24 Test: 42 1 1 4 0 1 12 6 1 0 4 1 1 1 0 2 2 0 0 5 0\n",
      "Client 25 Test: 39 1 1 1 6 2 12 0 5 1 0 0 1 1 1 1 0 0 6 0 0\n",
      "Client 26 Test: 39 13 2 1 3 0 2 4 1 0 0 0 3 0 2 1 0 1 1 0 5\n",
      "Client 27 Test: 39 2 2 3 1 0 0 0 6 0 3 1 2 0 1 0 2 0 0 11 5\n",
      "Client 28 Test: 38 0 4 0 2 4 0 4 2 0 0 0 1 3 1 1 3 9 2 2 0\n",
      "Client 29 Test: 38 0 2 13 7 0 1 0 0 1 0 0 1 0 2 1 0 0 4 6 0\n",
      "Client 30 Test: 41 0 8 1 2 1 0 6 0 7 0 5 2 0 4 1 1 1 0 1 1\n",
      "Client 31 Test: 39 5 1 0 0 4 4 12 2 2 0 0 0 2 5 0 0 0 1 1 0\n",
      "Client 32 Test: 40 0 1 0 4 1 0 5 1 6 1 1 3 3 1 0 2 7 2 1 1\n",
      "Client 33 Test: 40 0 0 4 0 1 1 10 0 3 0 1 1 2 1 4 2 5 0 4 1\n",
      "Client 34 Test: 38 0 3 0 2 1 4 0 1 0 0 1 5 3 5 1 2 1 2 3 4\n",
      "Client 35 Test: 40 2 0 7 1 2 0 0 0 0 1 4 1 3 6 3 0 0 3 5 2\n",
      "Client 36 Test: 39 2 2 3 3 0 0 6 0 0 1 0 9 1 0 1 1 1 3 1 5\n",
      "Client 37 Test: 41 0 3 2 0 2 1 5 0 0 3 0 0 4 4 6 0 0 0 6 5\n",
      "Client 38 Test: 44 6 1 1 2 1 2 4 2 1 2 6 4 1 0 4 0 1 2 1 3\n",
      "Client 39 Test: 42 1 0 1 1 2 3 9 2 0 5 0 1 2 3 2 5 5 0 0 0\n",
      "Client 40 Test: 41 0 0 3 2 6 6 0 0 4 1 1 1 10 0 0 1 0 1 2 3\n",
      "Client 41 Test: 41 1 0 1 2 1 5 0 0 14 0 2 0 1 1 4 2 1 0 1 5\n",
      "Client 42 Test: 42 8 2 0 2 0 0 2 2 4 3 3 0 4 1 1 0 1 5 3 1\n",
      "Client 43 Test: 43 0 1 1 1 1 6 6 4 0 0 3 1 1 0 3 1 2 1 4 7\n",
      "Client 44 Test: 43 1 0 3 0 2 8 3 2 1 0 10 1 0 3 3 1 0 3 1 1\n",
      "Client 45 Test: 43 2 0 1 1 1 4 0 1 0 1 12 0 0 1 0 8 5 1 1 4\n",
      "Client 46 Test: 37 0 12 2 0 0 0 0 2 0 0 8 0 3 4 0 0 5 0 0 1\n",
      "Client 47 Test: 42 1 0 0 0 1 8 2 3 1 6 2 0 1 1 4 0 2 2 7 1\n",
      "Client 48 Test: 38 0 0 5 1 1 11 4 4 0 0 0 2 7 0 1 0 0 1 0 1\n",
      "Client 49 Test: 40 1 4 0 1 4 1 7 2 1 5 1 2 0 1 0 1 6 2 1 0\n",
      "Client 50 Test: 41 4 1 0 0 4 2 0 6 1 0 0 0 1 3 5 8 0 3 2 1\n",
      "Client 51 Test: 37 4 2 0 0 5 0 1 6 0 0 4 0 6 0 0 0 1 7 0 1\n",
      "Client 52 Test: 40 3 8 4 1 0 3 3 4 0 3 0 2 0 2 5 0 1 1 0 0\n",
      "Client 53 Test: 40 0 0 1 4 1 1 0 0 0 5 0 2 0 0 0 0 11 1 4 10\n",
      "Client 54 Test: 41 5 4 0 4 2 5 1 3 0 6 4 0 1 4 1 0 0 0 1 0\n",
      "Client 55 Test: 41 3 0 5 0 0 0 0 8 1 0 0 6 3 0 0 0 0 11 0 4\n",
      "Client 56 Test: 42 1 0 0 1 1 1 0 1 3 0 10 1 4 2 2 0 1 4 3 7\n",
      "Client 57 Test: 41 3 0 5 0 0 0 0 1 1 1 8 0 1 1 4 3 2 6 0 5\n",
      "Client 58 Test: 38 0 0 1 0 1 4 0 2 1 3 8 5 5 0 1 0 1 0 6 0\n",
      "Client 59 Test: 41 0 10 0 0 0 3 2 2 2 0 0 8 2 1 0 4 1 5 0 1\n",
      "Client 60 Test: 41 4 0 1 1 0 0 8 2 0 0 0 2 1 2 5 1 3 4 1 6\n",
      "Client 61 Test: 42 0 0 4 0 0 1 3 4 4 5 10 2 1 1 0 0 0 7 0 0\n",
      "Client 62 Test: 44 6 5 0 3 1 5 2 2 5 1 2 7 2 0 0 0 1 0 0 2\n",
      "Client 63 Test: 37 1 0 0 0 1 0 1 2 0 6 4 7 7 4 0 0 0 2 1 1\n",
      "Client 64 Test: 41 0 1 6 0 0 2 3 1 2 2 4 2 1 3 2 3 0 0 1 8\n",
      "Client 65 Test: 38 1 2 1 1 1 0 14 2 2 2 2 0 1 1 3 1 0 0 0 4\n",
      "Client 66 Test: 40 0 7 3 1 10 0 0 0 1 1 1 0 3 3 3 0 2 0 2 3\n",
      "Client 67 Test: 41 2 1 9 0 0 4 1 2 1 1 2 2 1 1 0 5 1 1 1 6\n",
      "Client 68 Test: 38 0 0 0 5 0 1 1 3 8 0 2 6 2 1 0 1 0 3 4 1\n",
      "Client 69 Test: 38 0 1 1 2 2 3 0 0 0 3 0 1 0 0 8 1 1 6 0 9\n",
      "Client 70 Test: 42 1 0 1 1 8 0 0 1 2 4 5 8 1 0 2 1 1 3 1 2\n",
      "Client 71 Test: 39 2 2 1 0 0 1 0 0 1 4 7 0 0 6 4 10 0 1 0 0\n",
      "Client 72 Test: 36 12 0 1 3 0 1 1 0 2 0 0 0 10 0 0 0 2 2 0 2\n",
      "Client 73 Test: 41 2 1 5 0 3 3 1 2 8 1 0 9 0 0 0 0 5 0 0 1\n",
      "Client 74 Test: 41 3 2 1 6 1 7 0 6 0 4 0 0 4 0 2 1 0 1 2 1\n",
      "Client 75 Test: 41 9 1 10 1 1 4 2 0 1 0 1 1 4 0 0 1 1 0 0 4\n",
      "Client 76 Test: 42 1 0 12 0 1 2 0 1 7 0 0 6 1 2 2 1 0 1 3 2\n",
      "Client 77 Test: 42 8 7 0 2 0 1 1 0 1 4 1 2 3 0 8 0 2 1 1 0\n",
      "Client 78 Test: 43 0 4 1 0 0 1 3 1 1 1 6 0 4 11 0 9 0 0 0 1\n",
      "Client 79 Test: 38 0 3 8 0 1 0 0 3 1 0 3 1 1 1 1 0 13 1 0 1\n",
      "Client 80 Test: 40 0 0 0 0 2 6 5 0 4 3 0 0 2 1 1 1 7 0 4 4\n",
      "Client 81 Test: 38 1 1 0 1 1 0 3 0 6 0 4 3 1 7 2 2 0 0 4 2\n",
      "Client 82 Test: 39 0 0 0 0 0 0 16 0 3 1 1 5 3 0 7 2 0 1 0 0\n",
      "Client 83 Test: 38 1 1 3 0 0 1 0 0 0 2 2 5 1 5 11 0 0 0 0 6\n",
      "Client 84 Test: 41 0 10 1 0 1 0 2 1 0 4 1 3 0 12 0 4 0 2 0 0\n",
      "Client 85 Test: 40 3 0 19 5 1 3 1 0 1 3 0 1 2 0 0 1 0 0 0 0\n",
      "Client 86 Test: 42 3 2 1 0 2 0 0 1 0 6 1 0 0 7 1 0 4 3 0 11\n",
      "Client 87 Test: 38 1 0 0 2 1 0 1 1 4 1 0 1 0 1 2 2 13 0 4 4\n",
      "Client 88 Test: 37 5 0 1 19 0 0 2 1 0 0 3 0 0 0 2 0 0 2 1 1\n",
      "Client 89 Test: 41 0 1 1 2 1 0 0 25 0 2 2 0 3 1 1 0 1 0 0 1\n",
      "Client 90 Test: 44 5 3 1 0 5 5 4 7 1 3 1 0 2 0 2 0 0 1 2 2\n",
      "Client 91 Test: 39 0 1 0 3 0 0 4 1 5 1 0 1 13 1 1 1 0 0 3 4\n",
      "Client 92 Test: 37 8 7 1 4 5 0 0 0 0 0 0 0 2 5 0 1 0 2 0 2\n",
      "Client 93 Test: 41 1 4 1 0 0 0 1 3 2 2 1 7 2 1 3 2 0 10 1 0\n",
      "Client 94 Test: 38 7 0 0 2 0 1 0 2 3 0 0 0 1 1 2 11 1 1 1 5\n",
      "Client 95 Test: 41 7 1 0 0 0 1 1 8 3 3 1 2 0 0 0 2 2 0 2 8\n",
      "Client 96 Test: 41 5 0 1 0 0 1 17 0 1 0 3 1 2 2 0 0 1 0 4 3\n",
      "Client 97 Test: 37 2 0 1 1 2 4 0 1 1 4 0 0 0 1 8 1 1 3 7 0\n",
      "Client 98 Test: 39 0 0 0 0 1 0 4 8 0 0 12 2 0 0 2 0 2 4 0 4\n",
      "Client 99 Test: 40 3 0 1 1 2 0 0 6 7 2 7 0 3 0 2 1 1 2 2 0\n",
      "Client 100 Test: 39 0 0 1 1 1 8 5 0 0 5 1 0 1 0 1 0 4 6 1 4\n",
      "Client 101 Test: 40 0 3 0 1 4 1 0 1 0 0 6 2 0 0 9 0 4 2 4 3\n",
      "Client 102 Test: 40 0 0 1 0 0 0 6 8 5 0 0 1 9 2 1 3 1 2 1 0\n",
      "Client 103 Test: 38 1 0 0 4 0 0 1 0 4 1 2 0 6 3 0 0 2 1 13 0\n",
      "Client 104 Test: 39 0 0 11 0 1 3 1 0 1 0 1 3 7 0 4 3 1 0 3 0\n",
      "Client 105 Test: 39 3 0 1 12 1 2 1 0 0 1 1 0 8 0 2 1 1 0 2 3\n",
      "Client 106 Test: 40 3 6 1 0 0 4 1 10 4 0 0 0 5 2 1 2 0 0 1 0\n",
      "Client 107 Test: 41 0 12 0 4 0 5 1 1 3 0 0 0 2 1 4 3 1 2 0 2\n",
      "Client 108 Test: 39 2 1 3 4 1 0 0 2 0 0 0 1 8 6 3 1 2 0 1 4\n",
      "Client 109 Test: 41 2 1 6 0 1 1 2 3 3 0 2 1 6 0 0 1 5 0 5 2\n",
      "Client 110 Test: 39 2 10 0 0 4 2 2 1 2 1 0 2 7 0 1 0 3 0 1 1\n",
      "Client 111 Test: 42 1 4 1 12 1 1 1 0 1 9 1 2 1 1 0 0 3 1 2 0\n",
      "Client 112 Test: 40 2 1 0 1 2 0 2 0 0 2 5 1 5 0 2 5 1 0 6 5\n",
      "Client 113 Test: 41 0 0 0 9 1 4 0 11 0 0 1 0 3 2 1 6 1 1 0 1\n",
      "Client 114 Test: 40 2 1 0 3 0 1 1 0 1 7 0 1 0 4 1 6 2 6 3 1\n",
      "Client 115 Test: 39 0 1 0 2 1 1 2 2 0 1 18 4 0 0 0 0 1 6 0 0\n",
      "Client 116 Test: 41 9 1 1 1 0 3 0 0 4 0 2 2 2 8 1 1 1 1 0 4\n",
      "Client 117 Test: 40 1 8 0 1 0 5 0 0 15 1 2 0 0 2 3 1 1 0 0 0\n",
      "Client 118 Test: 41 6 2 3 1 6 4 1 0 1 1 1 0 3 0 1 1 0 3 7 0\n",
      "Client 119 Test: 40 1 1 0 1 0 0 0 3 3 1 14 1 0 0 2 0 9 1 2 1\n",
      "Client 120 Test: 41 2 6 0 6 0 3 4 0 1 1 2 0 0 7 0 0 4 1 2 2\n",
      "Client 121 Test: 41 1 0 0 2 8 0 7 0 2 1 0 4 8 2 2 0 0 1 2 1\n",
      "Client 122 Test: 40 0 2 0 0 1 2 0 8 0 9 4 0 3 0 2 3 0 3 1 2\n",
      "Client 123 Test: 41 3 1 1 1 0 4 0 1 10 2 0 0 5 4 0 0 1 3 2 3\n",
      "Client 124 Test: 40 1 0 1 1 6 4 4 1 1 10 0 5 0 0 0 1 0 0 0 5\n",
      "Client 125 Test: 38 0 0 0 1 1 0 6 0 2 0 5 4 3 3 0 5 3 5 0 0\n",
      "Client 126 Test: 40 0 7 0 1 5 1 5 0 0 3 2 3 3 6 1 0 0 1 2 0\n",
      "Client 127 Test: 39 0 1 1 3 0 7 1 3 4 0 0 1 0 1 7 8 0 0 1 1\n",
      "Client 128 Test: 41 1 3 1 1 1 5 4 0 8 1 0 0 5 4 1 1 3 0 1 1\n",
      "Client 129 Test: 38 0 2 1 0 0 0 3 1 0 5 10 1 0 0 3 2 0 1 9 0\n",
      "Client 130 Test: 42 3 3 4 2 1 0 1 6 2 0 4 0 2 5 2 0 0 0 2 5\n",
      "Client 131 Test: 40 1 3 0 7 0 0 7 0 2 1 0 2 1 1 0 6 4 5 0 0\n",
      "Client 132 Test: 40 7 1 10 1 0 1 0 1 4 0 0 1 0 6 2 5 0 1 0 0\n",
      "Client 133 Test: 41 2 1 0 1 2 9 3 0 1 7 0 1 1 1 1 3 1 1 3 3\n",
      "Client 134 Test: 43 2 1 1 1 6 1 3 3 7 4 0 1 1 2 1 2 1 0 5 1\n",
      "Client 135 Test: 38 1 11 0 4 1 10 0 1 0 2 0 1 0 0 2 3 2 0 0 0\n",
      "Client 136 Test: 40 0 2 3 0 2 0 0 3 8 4 0 11 2 0 0 1 1 2 0 1\n",
      "Client 137 Test: 39 1 0 1 9 2 8 0 0 7 1 0 1 0 0 2 0 0 5 1 1\n",
      "Client 138 Test: 40 4 6 0 0 0 1 2 0 14 1 3 0 1 1 0 0 3 0 4 0\n",
      "Client 139 Test: 40 1 5 3 2 1 0 1 0 5 2 0 3 0 2 6 0 6 0 1 2\n",
      "Client 140 Test: 41 0 6 2 1 0 0 1 1 0 0 3 4 1 3 1 2 0 0 9 7\n",
      "Client 141 Test: 40 0 3 3 1 1 0 1 0 6 0 0 5 0 2 5 0 0 11 0 2\n",
      "Client 142 Test: 38 1 3 0 3 0 5 0 0 2 3 5 7 0 8 0 0 0 0 1 0\n",
      "Client 143 Test: 41 3 2 1 1 0 0 0 2 0 3 7 1 1 1 3 12 1 1 2 0\n",
      "Client 144 Test: 40 3 16 1 1 0 2 1 3 1 0 2 0 0 1 1 6 2 0 0 0\n",
      "Client 145 Test: 41 1 3 2 1 2 2 5 7 2 2 0 6 4 0 1 0 2 1 0 0\n",
      "Client 146 Test: 42 4 1 0 1 1 0 3 3 1 8 4 0 1 3 5 4 0 0 0 3\n",
      "Client 147 Test: 42 0 0 1 3 0 2 0 1 3 4 0 4 1 1 3 10 1 0 8 0\n",
      "Client 148 Test: 41 2 0 0 8 0 3 6 1 0 7 0 1 1 2 3 1 2 0 1 3\n",
      "Client 149 Test: 39 1 0 3 0 6 0 3 0 1 1 10 2 1 1 3 2 0 3 1 1\n",
      "Client 150 Test: 40 7 1 0 1 4 9 0 0 0 2 5 3 0 0 0 7 0 0 0 1\n",
      "Client 151 Test: 40 2 1 1 13 0 2 3 4 0 2 0 0 0 6 1 1 0 2 1 1\n",
      "Client 152 Test: 38 0 3 1 2 0 0 0 5 0 0 3 1 0 7 0 15 0 0 0 1\n",
      "Client 153 Test: 39 5 1 3 2 3 2 0 1 1 2 0 0 9 6 0 1 2 0 1 0\n",
      "Client 154 Test: 38 1 0 1 0 0 2 3 0 0 2 1 0 6 0 1 0 0 0 19 2\n",
      "Client 155 Test: 40 1 6 2 2 0 0 0 2 2 1 1 4 0 0 12 0 0 0 6 1\n",
      "Client 156 Test: 42 1 0 0 4 1 1 1 3 1 4 8 3 10 2 2 1 0 0 0 0\n",
      "Client 157 Test: 39 1 1 3 3 1 4 0 11 0 6 1 0 1 1 0 0 0 1 0 5\n",
      "Client 158 Test: 39 4 0 0 5 0 0 0 0 0 5 1 2 1 1 1 10 3 1 1 4\n",
      "Client 159 Test: 39 2 0 1 0 2 5 4 5 0 0 1 3 0 3 0 5 0 0 5 3\n",
      "Client 160 Test: 41 0 1 0 4 0 2 0 7 0 2 2 7 3 0 1 0 8 2 1 1\n",
      "Client 161 Test: 36 7 2 0 2 4 3 0 1 0 0 0 0 3 1 0 6 2 0 0 5\n",
      "Client 162 Test: 40 1 2 9 1 0 9 1 8 0 0 1 0 1 0 2 0 2 1 0 2\n",
      "Client 163 Test: 39 2 1 0 0 0 0 3 2 2 10 1 1 0 1 3 4 7 1 1 0\n",
      "Client 164 Test: 42 0 0 1 6 8 1 3 4 1 2 3 1 1 2 0 1 0 1 1 6\n",
      "Client 165 Test: 40 0 0 2 4 6 0 0 2 0 1 3 6 2 1 2 1 1 1 8 0\n",
      "Client 166 Test: 39 0 1 0 0 0 0 9 5 2 0 0 2 7 2 0 5 0 6 0 0\n",
      "Client 167 Test: 43 0 1 3 11 3 1 1 0 3 1 0 0 3 3 1 1 4 3 1 3\n",
      "Client 168 Test: 40 2 0 5 0 1 3 3 0 10 1 3 4 1 0 1 1 2 1 0 2\n",
      "Client 169 Test: 43 0 1 1 3 2 2 1 3 0 1 11 1 3 1 0 0 4 0 7 2\n",
      "Client 170 Test: 38 2 3 1 0 1 3 0 1 6 0 6 0 2 0 3 0 1 4 3 2\n",
      "Client 171 Test: 38 1 0 2 9 4 0 2 2 4 0 0 1 0 1 0 0 4 0 0 8\n",
      "Client 172 Test: 42 2 3 0 0 0 4 2 3 0 3 1 0 10 3 1 6 0 2 2 0\n",
      "Client 173 Test: 39 0 0 2 0 0 8 1 2 2 1 0 2 3 0 4 1 0 1 4 8\n",
      "Client 174 Test: 37 8 3 0 1 1 2 6 2 2 0 0 0 1 0 1 2 4 2 0 2\n",
      "Client 175 Test: 41 0 0 1 0 0 4 3 0 3 0 5 5 11 1 0 4 1 1 0 2\n",
      "Client 176 Test: 39 0 2 1 1 1 1 1 8 1 0 2 0 0 0 8 8 2 1 1 1\n",
      "Client 177 Test: 39 0 0 2 0 0 7 0 1 3 2 3 2 0 6 6 3 3 0 0 1\n",
      "Client 178 Test: 38 0 0 3 0 1 5 1 0 0 2 1 11 0 0 0 1 10 2 0 1\n",
      "Client 179 Test: 41 1 0 0 4 4 1 2 0 0 1 3 0 1 2 0 0 2 2 7 11\n",
      "Client 180 Test: 41 4 0 1 1 0 8 2 2 2 0 0 0 1 2 0 1 1 2 3 11\n",
      "Client 181 Test: 39 2 4 0 1 5 0 5 0 4 1 4 1 0 5 0 1 0 1 1 4\n",
      "Client 182 Test: 43 1 0 0 1 1 2 1 2 1 3 7 0 0 4 1 1 9 6 1 2\n",
      "Client 183 Test: 38 2 0 0 8 4 6 0 0 1 0 1 2 8 0 0 0 2 0 4 0\n",
      "Client 184 Test: 40 5 0 2 1 4 0 1 0 2 3 1 7 0 1 5 4 0 3 0 1\n",
      "Client 185 Test: 38 0 11 1 0 10 0 1 0 1 0 0 5 0 3 0 0 1 1 3 1\n",
      "Client 186 Test: 38 2 0 1 8 1 0 0 4 4 3 0 0 0 4 2 3 2 0 3 1\n",
      "Client 187 Test: 40 1 3 2 0 0 0 2 0 7 1 3 0 1 6 0 0 3 1 1 9\n",
      "Client 188 Test: 42 1 5 1 3 0 0 0 1 4 6 1 0 2 1 15 1 0 0 1 0\n",
      "Client 189 Test: 38 1 0 1 0 0 20 1 8 2 1 0 2 0 0 0 0 1 1 0 0\n",
      "Client 190 Test: 41 0 1 1 3 0 1 2 10 8 0 1 2 2 1 0 3 1 2 2 1\n",
      "Client 191 Test: 40 2 1 3 1 0 5 0 1 6 1 0 6 0 0 7 2 1 0 3 1\n",
      "Client 192 Test: 40 3 0 0 7 0 0 0 2 7 0 1 6 3 1 0 0 1 8 0 1\n",
      "Client 193 Test: 40 0 1 2 0 0 2 12 1 1 2 0 2 1 2 7 1 4 0 1 1\n",
      "Client 194 Test: 39 3 1 0 7 1 1 0 1 0 0 2 1 1 0 0 2 7 0 7 5\n",
      "Client 195 Test: 38 3 2 0 0 2 1 0 2 3 7 0 0 4 0 0 1 1 0 10 2\n",
      "Client 196 Test: 40 1 4 2 1 2 1 2 1 0 3 3 1 5 1 1 0 1 0 3 8\n",
      "Client 197 Test: 40 5 5 1 4 0 1 1 5 4 4 1 2 1 1 1 0 2 1 1 0\n",
      "Client 198 Test: 39 4 1 3 1 3 0 0 0 2 1 0 0 8 10 1 0 0 3 1 1\n",
      "Client 199 Test: 38 2 1 0 10 0 6 0 3 1 2 0 0 0 0 5 4 1 0 0 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 准备数据集\n",
    "# 这部分是我加的\n",
    "cifar = CIFAR100()\n",
    "prob = get_prob(non_iid, client_num, class_num=20)\n",
    "client_data, client_test_data = create_data(prob, size_per_client, cifar, N=20)\n",
    "\n",
    "\n",
    "all_images = []\n",
    "all_labels = []\n",
    "for data in client_data:\n",
    "    all_images.extend(data[0])\n",
    "    all_labels.extend(data[1])\n",
    "comb_client_data = [np.array(all_images), np.array(all_labels)]\n",
    "\n",
    "# 输出cpmb_client_data情况\n",
    "imgs, lbls = comb_client_data\n",
    "lbls = np.array(lbls)\n",
    "total_count = len(lbls)\n",
    "unique_classes, counts = np.unique(lbls, return_counts=True)\n",
    "\n",
    "# 创建一个长度为20的数组记录各类别计数，默认0\n",
    "class_counts = [0]*20\n",
    "for cls, cnt in zip(unique_classes, counts):\n",
    "    class_counts[cls] = cnt\n",
    "\n",
    "# 打印格式：Total: 总数 类别0计数 类别1计数 ... 类别19计数\n",
    "print(\"Traning Client Total: {}\".format(\" \".join([str(total_count)] + [str(c) for c in class_counts])))\n",
    "\n",
    "\n",
    "# 打印每个客户端训练数据情况\n",
    "for i, (imgs, lbls) in enumerate(client_data):\n",
    "    lbls = np.array(lbls)\n",
    "    total_count = len(lbls)\n",
    "    unique_classes, counts = np.unique(lbls, return_counts=True)\n",
    "    # 创建一个长度为20的数组记录各类别计数，默认0\n",
    "    class_counts = [0]*20\n",
    "    for cls, cnt in zip(unique_classes, counts):\n",
    "        class_counts[cls] = cnt\n",
    "    # 打印格式：Client i: 总数 类别0计数 类别1计数 ... 类别19计数\n",
    "    print(\"Client {}: {}\".format(i, \" \".join([str(total_count)] + [str(c) for c in class_counts])))\n",
    "    \n",
    "\n",
    "# 打印每个客户端测试数据情况\n",
    "for i, (imgs, lbls) in enumerate(client_test_data):\n",
    "    lbls = np.array(lbls)\n",
    "    total_count = len(lbls)\n",
    "    unique_classes, counts = np.unique(lbls, return_counts=True)\n",
    "    class_counts = [0]*20\n",
    "    for cls, cnt in zip(unique_classes, counts):\n",
    "        class_counts[cls] = cnt\n",
    "    # 打印格式：Client i Test: 总数 类别0计数 类别1计数 ... 类别19计数\n",
    "    print(\"Client {} Test: {}\".format(i, \" \".join([str(total_count)] + [str(c) for c in class_counts])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "XvuicdZfeDvL"
   },
   "outputs": [],
   "source": [
    "# 本地训练并更新权重，返回更新后的模型权重、平均训练损失以及第一个迭代的梯度信息\n",
    "def update_weights(model_weight, dataset, learning_rate, local_epoch):\n",
    "    model = mobilenetv2().to(device)\n",
    "    model.load_state_dict(model_weight)\n",
    "\n",
    "    model.train()\n",
    "    epoch_loss = []\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    Tensor_set = TensorDataset(torch.Tensor(dataset[0]).to(device), torch.Tensor(dataset[1]).to(device))\n",
    "    data_loader = DataLoader(Tensor_set, batch_size=128, shuffle=True)\n",
    "\n",
    "    first_iter_gradient = None  # 初始化变量来保存第一个iter的梯度\n",
    "\n",
    "    for iter in range(local_epoch):\n",
    "        batch_loss = []\n",
    "        for batch_idx, (images, labels) in enumerate(data_loader):\n",
    "            model.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels.long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            batch_loss.append(loss.item()/images.shape[0])\n",
    "\n",
    "            # 保存第一个iter的梯度\n",
    "            if iter == 0 and batch_idx == 0:\n",
    "                first_iter_gradient = {}\n",
    "                for name, param in model.named_parameters():\n",
    "                    first_iter_gradient[name] = param.grad.clone()\n",
    "                # 保存 BatchNorm 层的 running mean 和 running variance\n",
    "                for name, module in model.named_modules():\n",
    "                    if isinstance(module, nn.BatchNorm2d):\n",
    "                        first_iter_gradient[name + '.running_mean'] = module.running_mean.clone()\n",
    "                        first_iter_gradient[name + '.running_var'] = module.running_var.clone()\n",
    "\n",
    "        epoch_loss.append(sum(batch_loss)/len(batch_loss))\n",
    "\n",
    "    return model.state_dict(), sum(epoch_loss) / len(epoch_loss), first_iter_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "qsPZGD4Iem5w"
   },
   "outputs": [],
   "source": [
    "# 计算模型权重的差异，并根据学习率 lr 对权重差异进行缩放\n",
    "def weight_differences(n_w, p_w, lr):\n",
    "    w_diff = copy.deepcopy(n_w)\n",
    "    for key in w_diff.keys():\n",
    "        if 'num_batches_tracked' in key:\n",
    "            continue\n",
    "        w_diff[key] = (p_w[key] - n_w[key]) * lr\n",
    "    return w_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "040d862vbG9M"
   },
   "outputs": [],
   "source": [
    "# 也是本地训练，不过引入了本文的权重修正机制\n",
    "def update_weights_correction(model_weight, dataset, learning_rate, local_epoch, c_i, c_s):\n",
    "    model = mobilenetv2().to(device)\n",
    "    model.load_state_dict(model_weight)\n",
    "\n",
    "    model.train()\n",
    "    epoch_loss = []\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    Tensor_set = TensorDataset(torch.Tensor(dataset[0]).to(device), torch.Tensor(dataset[1]).to(device))\n",
    "    data_loader = DataLoader(Tensor_set, batch_size=200, shuffle=True)\n",
    "\n",
    "    for iter in range(local_epoch):\n",
    "        batch_loss = []\n",
    "        for batch_idx, (images, labels) in enumerate(data_loader):\n",
    "            model.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels.long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            batch_loss.append(loss.sum().item()/images.shape[0])\n",
    "        epoch_loss.append(sum(batch_loss)/len(batch_loss))\n",
    "        corrected_graident = weight_differences(c_i, c_s, learning_rate)\n",
    "        orginal_model_weight = model.state_dict()\n",
    "        corrected_model_weight = weight_differences(corrected_graident, orginal_model_weight, 1)  # 这里缩放权重为1\n",
    "        model.load_state_dict(corrected_model_weight)\n",
    "\n",
    "    return model.state_dict(),  sum(epoch_loss) / len(epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "qeFHXRuEo5Du"
   },
   "outputs": [],
   "source": [
    "def average_weights(w):\n",
    "    \"\"\"\n",
    "    Returns the average of the weights.\n",
    "    \"\"\"\n",
    "    w_avg = copy.deepcopy(w[0])\n",
    "    for key in w_avg.keys():\n",
    "        if 'num_batches_tracked' in key:\n",
    "            continue\n",
    "        for i in range(1, len(w)):\n",
    "            w_avg[key] += w[i][key]\n",
    "        w_avg[key] = torch.div(w_avg[key], len(w))\n",
    "    return w_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "pLG9RrFffbl8"
   },
   "outputs": [],
   "source": [
    "# baseline: server-only\n",
    "def server_only(initial_w, global_round, gamma, E):\n",
    "    test_model = mobilenetv2().to(device)\n",
    "    train_w = copy.deepcopy(initial_w)\n",
    "    test_acc = []\n",
    "    train_loss = []\n",
    "    \n",
    "    # 提前生成固定的服务器数据\n",
    "    # Modify: 这是我后来修改的\n",
    "    server_data = select_subset(comb_client_data, server_percentage)\n",
    "    \n",
    "    for round in tqdm(range(global_round)):\n",
    "        # if gamma > 0.001:\n",
    "        #     gamma = gamma * 0.99\n",
    "        # Server side local training\n",
    "        \n",
    "        \n",
    "        # 从comb中（论文中说明为全部训练数据）选择固定比率的server数据（并且是保证类别均衡的）\n",
    "        # server_data = select_subset(comb_client_data, server_percentage)\n",
    "        \n",
    "        # 第一轮都打印服务器数据情况，简化输出格式\n",
    "        if round == 0:\n",
    "            s_imgs, s_lbls = server_data\n",
    "            s_lbls = np.array(s_lbls)\n",
    "            total_count = len(s_lbls)\n",
    "            unique_classes, counts = np.unique(s_lbls, return_counts=True)\n",
    "            class_counts = [0]*20\n",
    "            for cls, cnt in zip(unique_classes, counts):\n",
    "                class_counts[cls] = cnt\n",
    "\n",
    "            # 输出格式: Server round: 总数 类别0计数 类别1计数 ... 类别19计数\n",
    "            print(\"Server {}: {}\".format(round, \" \".join([str(total_count)] + [str(c) for c in class_counts])))\n",
    "        \n",
    "        update_server_w, round_loss, _ = update_weights(train_w, server_data, gamma, E)\n",
    "        train_w = update_server_w\n",
    "        test_model.load_state_dict(train_w)\n",
    "        train_loss.append(round_loss)\n",
    "        # Test Accuracy\n",
    "        test_a = 0\n",
    "        for i in client_test_data:\n",
    "            ac = test_inference(test_model,i)[0]\n",
    "            test_a = test_a + ac\n",
    "        test_a = test_a/len(client_test_data)\n",
    "        test_acc.append(test_a)\n",
    "        # print(test_a)\n",
    "    return test_acc, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "nGtAn28aok2c"
   },
   "outputs": [],
   "source": [
    "def fedavg(initial_w, global_round, eta, K, M):\n",
    "    test_model = mobilenetv2().to(device)\n",
    "    train_w = copy.deepcopy(initial_w)\n",
    "    test_acc = []\n",
    "    train_loss = []\n",
    "    for round in tqdm(range(global_round)):\n",
    "        local_weights, local_loss = [], []\n",
    "        # Client side local training\n",
    "        # if eta > 0.001:\n",
    "        #     eta = eta * 0.99\n",
    "        sampled_client = random.sample(range(client_num), M)\n",
    "        for i in sampled_client:\n",
    "            update_client_w, client_round_loss, _ = update_weights(train_w, client_data[i], eta, K)\n",
    "            local_weights.append(update_client_w)\n",
    "            local_loss.append(client_round_loss)\n",
    "\n",
    "        train_w = average_weights(local_weights)\n",
    "\n",
    "        # Test Accuracy\n",
    "        test_model.load_state_dict(train_w)\n",
    "        loss_avg = sum(local_loss)/ len(local_loss)\n",
    "        train_loss.append(loss_avg)\n",
    "        test_a = 0\n",
    "        for i in client_test_data:\n",
    "            ac = test_inference(test_model,i)[0]\n",
    "            test_a = test_a + ac\n",
    "        test_a = test_a/len(client_test_data)\n",
    "        test_acc.append(test_a)\n",
    "#         print(test_a)\n",
    "    return test_acc, train_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "uzxW0sUxRGth"
   },
   "outputs": [],
   "source": [
    "def CLG_SGD(initial_w, global_round, eta, gamma, K, E, M):\n",
    "    test_model = mobilenetv2().to(device)\n",
    "    train_w = copy.deepcopy(initial_w)\n",
    "    test_acc = []\n",
    "    train_loss = []\n",
    "    \n",
    "    # 提前生成固定的服务器数据\n",
    "    # Modify: 这是我后来修改的\n",
    "    server_data = select_subset(comb_client_data, server_percentage)\n",
    "    \n",
    "    for round in tqdm(range(global_round)):\n",
    "        # 学习率衰减，这里默认注释掉了\n",
    "        # if eta > 0.001:\n",
    "        #     eta = eta * 0.99\n",
    "        # if gamma > 0.001:\n",
    "        #     gamma = gamma * 0.99\n",
    "        local_weights, local_loss = [], []\n",
    "        # Client side local training\n",
    "        # 从总共client_num客户端中选择M个训练\n",
    "        sampled_client = random.sample(range(client_num), M)\n",
    "        for i in sampled_client:\n",
    "            update_client_w, client_round_loss, _ = update_weights(train_w, client_data[i], eta, K)\n",
    "            local_weights.append(update_client_w)\n",
    "            local_loss.append(client_round_loss)\n",
    "        train_w = average_weights(local_weights)\n",
    "        # Server side local training\n",
    "        \n",
    "        \n",
    "        # 从comb中（论文中说明为全部训练数据）选择固定比率的server数据（并且是保证类别均衡的）\n",
    "        # TODO_241216:这里是每一轮都重新选择数据（但保证类别比例是一样的，都是按照comb中的比例），我的场景中可以这样吗？\n",
    "        # server_data = select_subset(comb_client_data, server_percentage)\n",
    "        \n",
    "        \n",
    "        # 第一轮都打印服务器数据情况，简化输出格式\n",
    "        if round == 0:\n",
    "            s_imgs, s_lbls = server_data\n",
    "            s_lbls = np.array(s_lbls)\n",
    "            total_count = len(s_lbls)\n",
    "            unique_classes, counts = np.unique(s_lbls, return_counts=True)\n",
    "            class_counts = [0]*20\n",
    "            for cls, cnt in zip(unique_classes, counts):\n",
    "                class_counts[cls] = cnt\n",
    "\n",
    "            # 输出格式: Server round: 总数 类别0计数 类别1计数 ... 类别19计数\n",
    "            print(\"Server {}: {}\".format(round, \" \".join([str(total_count)] + [str(c) for c in class_counts])))\n",
    "\n",
    "        update_server_w, round_loss, _ = update_weights(train_w, server_data, gamma, E)\n",
    "        train_w = update_server_w\n",
    "        local_loss.append(round_loss)\n",
    "\n",
    "        # Test Accuracy\n",
    "        test_model.load_state_dict(train_w)\n",
    "        loss_avg = sum(local_loss)/ len(local_loss)\n",
    "        train_loss.append(loss_avg)   # 计算所有客户端和服务器一起的平均损失\n",
    "\n",
    "        test_a = 0\n",
    "        # 遍历客户端测试数据，计算平均准确率\n",
    "        for i in client_test_data:\n",
    "            ac = test_inference(test_model,i)[0]\n",
    "            test_a = test_a + ac\n",
    "        test_a = test_a/len(client_test_data)\n",
    "        test_acc.append(test_a)\n",
    "#         print(test_a)\n",
    "    return test_acc, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "iJTODAzxYJgA"
   },
   "outputs": [],
   "source": [
    "def Fed_C(initial_w, global_round, eta, gamma, K, E, M):\n",
    "    test_model = mobilenetv2().to(device)\n",
    "    train_w = copy.deepcopy(initial_w)\n",
    "    test_acc = []\n",
    "    train_loss = []\n",
    "    \n",
    "    # 提前生成固定的服务器数据\n",
    "    # Modify: 这是我后来修改的\n",
    "    server_data = select_subset(comb_client_data, server_percentage)\n",
    "    \n",
    "    for round in tqdm(range(global_round)):\n",
    "        # if eta > 0.001:\n",
    "        #     eta = eta * 0.99\n",
    "        # if gamma > 0.001:\n",
    "        #     gamma = gamma * 0.99\n",
    "        local_weights, local_loss = [], []\n",
    "        g_i_list = []\n",
    "        # server_data = select_subset(comb_client_data, server_percentage)\n",
    "        \n",
    "        # 第一轮都打印服务器数据情况，简化输出格式\n",
    "        if round == 0:\n",
    "            s_imgs, s_lbls = server_data\n",
    "            s_lbls = np.array(s_lbls)\n",
    "            total_count = len(s_lbls)\n",
    "            unique_classes, counts = np.unique(s_lbls, return_counts=True)\n",
    "            class_counts = [0]*20\n",
    "            for cls, cnt in zip(unique_classes, counts):\n",
    "                class_counts[cls] = cnt\n",
    "\n",
    "            # 输出格式: Server round: 总数 类别0计数 类别1计数 ... 类别19计数\n",
    "            print(\"Server {}: {}\".format(round, \" \".join([str(total_count)] + [str(c) for c in class_counts])))\n",
    "        \n",
    "        \n",
    "        # 计算Server gradient\n",
    "        _, _, g_s = update_weights(train_w, server_data, gamma, 1)\n",
    "\n",
    "        # 计算Client gradient\n",
    "        sampled_client = random.sample(range(client_num), M)\n",
    "        for i in sampled_client:\n",
    "            _, _, g_i = update_weights(train_w, client_data[i], eta, 1)\n",
    "            g_i_list.append(g_i)\n",
    "\n",
    "\n",
    "        # Client side local training\n",
    "        for i in range(len(sampled_client)):\n",
    "            update_client_w, client_round_loss = update_weights_correction(train_w, client_data[sampled_client[i]], eta, K, g_i_list[i], g_s)\n",
    "            local_weights.append(update_client_w)\n",
    "            local_loss.append(client_round_loss)\n",
    "        train_w = average_weights(local_weights)\n",
    "        # Server side local training\n",
    "        update_server_w, round_loss, _ = update_weights(train_w, server_data, gamma, E)\n",
    "        train_w = update_server_w\n",
    "        local_loss.append(round_loss)\n",
    "\n",
    "        # Test Accuracy\n",
    "        test_model.load_state_dict(train_w)\n",
    "        loss_avg = sum(local_loss)/ len(local_loss)\n",
    "        train_loss.append(loss_avg)\n",
    "\n",
    "        test_a = 0\n",
    "        for i in client_test_data:\n",
    "            ac = test_inference(test_model,i)[0]\n",
    "            test_a = test_a + ac\n",
    "        test_a = test_a/len(client_test_data)\n",
    "        test_acc.append(test_a)\n",
    "    return test_acc, train_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "tXqVbWZK7gLn"
   },
   "outputs": [],
   "source": [
    "def Fed_S(initial_w, global_round, eta, gamma, K, E, M):\n",
    "    test_model = mobilenetv2().to(device)\n",
    "    train_w = copy.deepcopy(initial_w)\n",
    "    test_acc = []\n",
    "    train_loss = []\n",
    "    \n",
    "    # 提前生成固定的server数据\n",
    "    # Modify: 这是我后来修改的\n",
    "    server_data = select_subset(comb_client_data, server_percentage)\n",
    "    \n",
    "    for round in tqdm(range(global_round)):\n",
    "        # if eta > 0.001:\n",
    "        #     eta = eta * 0.99\n",
    "        # if gamma > 0.001:\n",
    "        #     gamma = gamma * 0.99\n",
    "        local_weights, local_loss = [], []\n",
    "        g_i_list = []\n",
    "        # Server gradient\n",
    "        # server_data = select_subset(comb_client_data, server_percentage)\n",
    "        _, _, g_s = update_weights(train_w, server_data, gamma, 1)\n",
    "\n",
    "        # Client gradient\n",
    "        sampled_client = random.sample(range(client_num), M)\n",
    "        for i in sampled_client:\n",
    "            _, _, g_i = update_weights(train_w, client_data[i], eta, 1)\n",
    "            g_i_list.append(g_i)\n",
    "\n",
    "\n",
    "        # Client side local training\n",
    "        for i in range(len(sampled_client)):\n",
    "            update_client_w, client_round_loss, _ = update_weights(train_w, client_data[sampled_client[i]], eta, K)\n",
    "            local_weights.append(update_client_w)\n",
    "            local_loss.append(client_round_loss)\n",
    "        train_w = average_weights(local_weights)\n",
    "\n",
    "        # Server aggregation correction\n",
    "        g_i_average = average_weights(g_i_list)\n",
    "        correction_g = weight_differences(g_i_average, g_s, K*eta)\n",
    "        train_w = weight_differences(correction_g, copy.deepcopy(train_w), 1)\n",
    "\n",
    "\n",
    "        # Server side local training\n",
    "        update_server_w, round_loss, _ = update_weights(train_w, server_data, gamma, E)\n",
    "        train_w = update_server_w\n",
    "        local_loss.append(round_loss)\n",
    "\n",
    "        # Test Accuracy\n",
    "        test_model.load_state_dict(train_w)\n",
    "        loss_avg = sum(local_loss)/ len(local_loss)\n",
    "        train_loss.append(loss_avg)\n",
    "\n",
    "        test_a = 0\n",
    "        for i in client_test_data:\n",
    "            ac = test_inference(test_model,i)[0]\n",
    "            test_a = test_a + ac\n",
    "        test_a = test_a/len(client_test_data)\n",
    "        test_acc.append(test_a)\n",
    "    return test_acc, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server 0: 1502 73 78 64 79 60 89 82 82 78 72 82 74 86 75 72 70 69 63 75 79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [03:10<00:00,  1.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server only 训练完成！\n",
      "各轮平均测试精度: [0.13265224464017994, 0.12877315551324778, 0.16186401313318644, 0.14996105819063088, 0.15667813094547572, 0.16812398226347977, 0.16643065126473705, 0.1618994307804275, 0.18138245378515763, 0.18736571458126736, 0.18390136265324702, 0.18862464757591935, 0.19024919609866392, 0.19019814629532278, 0.198979050855133, 0.19767950050785818, 0.19749502367981253, 0.19711869094097348, 0.19285369732745608, 0.1942067198783509, 0.19595521973965568, 0.1961333114088771, 0.19618869899358454, 0.1947097639483561, 0.19442062179049452, 0.1933733377366315, 0.1946381535845219, 0.194656157948046, 0.19554356393959194, 0.19611806154586106, 0.19438931919794009, 0.1968115156764812, 0.19548866528126235, 0.1964613978063279, 0.1952186686360605, 0.19462743974735713, 0.1955719213803818, 0.19560348990021414, 0.19738010852634183, 0.19540921549603293, 0.1948584423198007, 0.19705961301076905, 0.19525082552139456, 0.19496535397118273, 0.19568772928454015, 0.19581980459037354, 0.19448614613987633, 0.19545665839266377, 0.1951639299131798, 0.19474796823656046, 0.19643274857478743, 0.19517237035995805, 0.19528591606544846, 0.1929127898287599, 0.19392288326469737, 0.19529056364583414, 0.19578996750549796, 0.19514532153236375, 0.19431375147772884, 0.19541089972190517, 0.19508956666531227, 0.1961531406844606, 0.19492820786559018, 0.19743520652415472, 0.19690867999742298, 0.19572638087637556, 0.18625754397030186, 0.18958668061853035, 0.19050957068599683, 0.1899909899156286, 0.19040362794755716, 0.19013236240217757, 0.1909911150902209, 0.18877819306503962, 0.190599341271894, 0.19005936837216508, 0.19120982430842642, 0.19124984296211944, 0.19078440127136648, 0.19080723785315992, 0.19193338307533236, 0.19259725846651166, 0.19268847199606295, 0.19475194456631972, 0.1926222301328057, 0.19263704958438072, 0.1916573874645194, 0.19304462065504846, 0.19093750432516587, 0.19222876760118526, 0.19277839489769288, 0.19221599046615837, 0.19310836091340683, 0.19265975562228202, 0.19104092740156037, 0.19314058819588417, 0.1914430480847437, 0.19304894067481754, 0.1932103970962711, 0.19336361672470878]\n",
      "各轮平均训练损失: [0.023959189110455362, 0.018293232017639258, 0.013378881681248126, 0.009015175088883397, 0.00568537173523561, 0.002992334598774447, 0.0015712601412170243, 0.0009899843788257032, 0.0007331922901538366, 0.0005240444200179364, 0.0001264442448110516, 1.3889290952879782e-05, 6.802414131659541e-06, 2.715859025166466e-06, 8.215616017960588e-06, 5.325233039130541e-06, 1.905901198582029e-06, 1.4398973974845399e-06, 2.916367633570641e-06, 2.549468166625714e-06, 1.9142599501648057e-06, 1.2128922288247882e-06, 1.2306948894155674e-06, 1.1836028003422174e-06, 1.6386124151325777e-06, 1.3690923751645714e-06, 9.924943290341823e-07, 1.0154951499510983e-06, 9.204289908694618e-07, 1.0133464689600467e-06, 1.1021846062277317e-06, 1.1522711099930143e-06, 1.2028299701622481e-06, 1.3162747140810189e-06, 1.0465206093221376e-06, 9.74475251760247e-07, 1.0428620959307685e-06, 1.0031598906664787e-06, 8.550012543006033e-07, 8.687713697377923e-07, 8.932790871730703e-07, 8.392784262946247e-07, 8.416904263908885e-07, 1.0073413180567896e-06, 8.754176247262354e-07, 8.163767385263647e-07, 1.0365451273692927e-06, 8.953778143994355e-07, 8.304908331645474e-07, 8.171256231862442e-07, 1.1818980069986872e-06, 9.206603736487496e-07, 9.362021650915253e-07, 1.3837012255474013e-06, 8.815379911318795e-07, 9.625407330555126e-07, 9.774064142603582e-07, 1.01900915497502e-06, 1.0090072351984559e-06, 9.454066161582667e-07, 1.01278903965733e-06, 9.920823533827954e-07, 1.2267787054817699e-06, 1.084472828568078e-06, 1.2690263709757332e-06, 9.96996865845028e-07, 3.6735659209029086e-06, 1.7835197272503224e-06, 1.2778835648709934e-06, 1.0862934890471948e-06, 1.1076107646703936e-06, 1.2105593995771245e-06, 1.1502551752868487e-06, 1.1459566897804617e-06, 1.2595877786213884e-06, 1.0942807569243936e-06, 9.904578503403868e-07, 1.2365856987537672e-06, 1.0315082303509855e-06, 1.290315963813632e-06, 1.2324962657446785e-06, 1.0836680152954724e-06, 1.1129298353830402e-06, 1.2318078747884623e-06, 1.3182764829738232e-06, 1.0830288089338722e-06, 1.2626952042182892e-06, 1.1729525092811747e-06, 1.1391096418652096e-06, 1.2188841475174464e-06, 1.288693059976153e-06, 1.2488752224686025e-06, 1.1009436927955168e-06, 1.2383969928686198e-06, 1.1627610267914087e-06, 1.3336988525616882e-06, 1.2479114911226546e-06, 1.1789442954702106e-06, 1.2651461423285957e-06, 1.250912340550074e-06]\n",
      "最终测试精度: 0.19336361672470878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:33<00:00,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fedavg训练完成！\n",
      "各轮平均测试精度: [0.047130967249313656, 0.04916137708042207, 0.045509596633712214, 0.05333087829875229, 0.05806897548856905, 0.05686584208727233, 0.04765692527891381, 0.07111222570406973, 0.07536779736395742, 0.06818521928029117, 0.09228074700559173, 0.12317444402073613, 0.09660546347916105, 0.11502055877127897, 0.12164176987018205, 0.11473259354548342, 0.09604923782721039, 0.11983143810634697, 0.1054496718443265, 0.12328674025446487, 0.10063816398382171, 0.09877164377380057, 0.12997020597064626, 0.11719105438006379, 0.1264379522598393, 0.15064573143590665, 0.1205013102253265, 0.11348774011256092, 0.13322953871319015, 0.15721927643170205, 0.138298460187745, 0.13997756985514834, 0.18731017633150293, 0.13538849944218326, 0.16483779029061807, 0.14596393179624872, 0.14936200895875631, 0.15104842117834683, 0.14138767862642385, 0.1338038728527913, 0.13589744959731442, 0.14754037595336061, 0.1655289758241887, 0.15577013232853668, 0.15020080146932918, 0.17638020179856378, 0.17148523636227747, 0.1435019845437196, 0.1697936875647229, 0.1718184234880393, 0.18147654846756633, 0.1814323505345201, 0.18502716834137922, 0.17610976446688592, 0.17690212577062514, 0.16671661116538633, 0.18749344755374026, 0.13596272252126496, 0.17811460670402515, 0.20559702241671146, 0.157791427575688, 0.19740005792484377, 0.1738224832187349, 0.189946158044846, 0.1598307713742192, 0.19804724134924967, 0.1904733693395252, 0.20705491760967998, 0.1994594674382342, 0.17911869079390427, 0.19956912364291374, 0.17844414622162627, 0.21117517489886295, 0.19067110279230393, 0.17220715316418636, 0.20933766571846465, 0.22432829335352694, 0.21332642699305013, 0.2093086959959328, 0.19590963507589992, 0.2038953291351527, 0.2154302872874499, 0.21064053458508178, 0.20145859370299976, 0.19065172465700475, 0.21994682037313462, 0.19831189995202825, 0.20292474417552772, 0.22980697200089978, 0.1997557014234291, 0.21021821215880743, 0.22276494537089506, 0.21569596517587375, 0.175900179308839, 0.21396068794239526, 0.24764155123507808, 0.149262293348898, 0.22673123793003178, 0.24298521466562253, 0.2130870545030954]\n",
      "各轮平均训练损失: [0.13883592880090653, 0.09282856710976295, 0.08104951988630252, 0.07165613973182014, 0.06627771953654414, 0.06376274125565123, 0.0639170185929614, 0.06294298539125355, 0.0620260920958692, 0.057477451062940485, 0.060585020467279274, 0.05163002723799355, 0.0576758812686569, 0.053078164693873234, 0.05557995574744529, 0.04935939512838295, 0.052773054717869375, 0.051883864232987166, 0.052670758682225406, 0.050566583821228674, 0.04789528344088341, 0.047644128780316194, 0.04751860404259549, 0.05053965861655796, 0.04813965373208451, 0.04507680613405747, 0.0485074943320846, 0.050084744319630836, 0.0469980835254094, 0.04625012189693199, 0.043882137814445984, 0.04653730753325076, 0.045150855191776515, 0.0407553155271938, 0.04578667210396224, 0.04135156945650389, 0.04313011995107123, 0.0413234736108017, 0.041761887186483035, 0.04090219182754344, 0.04160039900469843, 0.03897818712497225, 0.03898137665804992, 0.039568196742675685, 0.039463622973543964, 0.037013056847865496, 0.043247540393022484, 0.04025577233310381, 0.03726575023887902, 0.03922193448795548, 0.03843082040890767, 0.03929846727492471, 0.03796475126363797, 0.03524739134945787, 0.037705926911803814, 0.03946488556521204, 0.03465236865652463, 0.03418414033268958, 0.03304387600863614, 0.03503466635787726, 0.033523192905266744, 0.03476678601119963, 0.03174602848457819, 0.03503136078511329, 0.03547174765361687, 0.03571958258385611, 0.02750268304174004, 0.03547743823847492, 0.03390866437553688, 0.028175915613696374, 0.031596472132834945, 0.035243972358434204, 0.029964289699179414, 0.036602981430121875, 0.03460835448442567, 0.033056851292036574, 0.029399842099721473, 0.030866298776894625, 0.028373085531482316, 0.027247136583183403, 0.026972149421336633, 0.027634359670083604, 0.02800468722960518, 0.028194585184351906, 0.030410544910170458, 0.027163046550409242, 0.030068843177351683, 0.029923585963230553, 0.025994991996143534, 0.029223477467384705, 0.023873788018956347, 0.026903476213989724, 0.027830631282786095, 0.030706639452526045, 0.026990234384579436, 0.024769979663930915, 0.025893663457308102, 0.029863466125006156, 0.024573425927618242, 0.025601916289153148]\n",
      "最终测试精度: 0.2130870545030954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server 0: 1502 73 78 64 79 60 89 82 82 78 72 82 74 86 75 72 70 69 63 75 79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [06:35<00:00,  3.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLG_SGD 训练完成！\n",
      "各轮平均测试精度: [0.13981846097426223, 0.15754623076811994, 0.1516340236548575, 0.16429285560052492, 0.1628520533928033, 0.17630418198840367, 0.1869413601996034, 0.20262701882499168, 0.2023541021694848, 0.21306829610460887, 0.2039500491565229, 0.21518409745734945, 0.22468907026815932, 0.224741884435525, 0.228044405138783, 0.22214224743147476, 0.2306738323735629, 0.22722414160107074, 0.23702871563581474, 0.2386639582779386, 0.24693078753816264, 0.23582081530811633, 0.2425112985233145, 0.24253309597707612, 0.24420337230588907, 0.24327574719556083, 0.24810123902318357, 0.24673326884696936, 0.2546406313972328, 0.2528723651049422, 0.2524281376667, 0.25523343027343004, 0.2554248426704617, 0.2523562853817018, 0.25456639406936843, 0.2553654332116358, 0.2483259647173579, 0.25264543902330483, 0.2559782201506013, 0.26140885992284246, 0.25659757800421146, 0.25938935626978954, 0.2556238480985846, 0.256491698538434, 0.2630907478672018, 0.26963120790185524, 0.2572252358452577, 0.26141654880005327, 0.26571073028597963, 0.2651706761169175, 0.2614405338541754, 0.26799957679445013, 0.26853648160022603, 0.26892987674146795, 0.272483844291006, 0.2731815879838465, 0.2773013058538143, 0.2730664617211174, 0.2776347155811174, 0.277257081192456, 0.2710634254508444, 0.27797351183786534, 0.27638086557815555, 0.2747171299801013, 0.27485178455932546, 0.27157150154791, 0.2722951009568878, 0.2787394848507449, 0.2674336957451527, 0.2743995642378632, 0.27370800330869893, 0.28257500520698725, 0.27101557164430334, 0.27911765850720854, 0.28802012569021185, 0.28038729381503724, 0.28294515861522224, 0.2780575521848622, 0.2730571066654408, 0.2836367966366586, 0.27706123663000015, 0.27123848177215265, 0.28362900271576047, 0.2870902441492382, 0.27746737210691813, 0.28563728459429566, 0.28683259315749904, 0.2860264576924612, 0.28462232555575245, 0.2856047269470785, 0.2858224391635071, 0.2807310175934268, 0.2848485983826275, 0.28557385092681536, 0.28218735839555614, 0.28280834395726406, 0.28155087369362897, 0.2852484042951398, 0.2897670662671221, 0.2950521518801514]\n",
      "各轮平均训练损失: [0.11353703569908938, 0.05354133125608074, 0.04740163989766109, 0.04705638614362297, 0.03927630816037242, 0.04439071223923779, 0.050013163471484594, 0.06794005462669317, 0.06689638567132337, 0.05626223563950452, 0.05537249070238095, 0.0472665794458702, 0.045225941389003065, 0.04188977080473967, 0.039501380121042935, 0.042375199161448884, 0.04050505574047269, 0.036320751256134216, 0.03602859654505126, 0.03467731703845409, 0.031684086546115625, 0.02956317205806069, 0.02871922486364759, 0.030693798603530418, 0.03220052368647725, 0.032255547142852836, 0.030531699996377278, 0.02957043438828302, 0.030816825954815608, 0.031025954833218346, 0.02963813979349448, 0.027231458886001723, 0.028731224365545125, 0.02768266671190057, 0.02737109816842888, 0.024239421782922002, 0.028911487387325022, 0.027336800616285375, 0.024077069376416085, 0.025690196349107443, 0.01943543740394775, 0.023158931042515762, 0.02346610460313399, 0.02548128512340233, 0.02382458653573426, 0.022474455896470794, 0.02020801615578808, 0.022665683786229823, 0.025684574053901052, 0.02488801297065305, 0.02378487811166408, 0.024279842231701557, 0.023579457148916513, 0.02445535787431512, 0.02286761934279896, 0.0203178933728921, 0.020533203630069767, 0.02246227714504565, 0.021661300760283893, 0.02087674536446653, 0.020228610042337166, 0.022039934717161893, 0.020877989673754718, 0.021482445685740998, 0.020099248200137185, 0.02053178058242551, 0.021955556127229183, 0.021034824607334135, 0.02002811539966332, 0.018996939379796164, 0.01968756949316772, 0.021117380090973078, 0.02075998017714752, 0.01803865730108116, 0.01921204760226949, 0.02101290972704075, 0.022138889065798542, 0.02216520329288176, 0.017639846066590005, 0.02175760915924561, 0.020036818011342408, 0.017094081291993853, 0.022983522134747292, 0.020727627992844607, 0.022413179679802428, 0.016593805662752786, 0.01864905936549194, 0.017819346348777073, 0.019002533966769954, 0.017179439771218, 0.01633986820646464, 0.018822453259732336, 0.019773949504999954, 0.018838347754179974, 0.019361940511594525, 0.016222823779057767, 0.015898314041367816, 0.015666853641333287, 0.019067290561007602, 0.01698772731695322]\n",
      "最终测试精度: 0.2950521518801514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server 0: 1502 73 78 64 79 60 89 82 82 78 72 82 74 86 75 72 70 69 63 75 79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [09:14<00:00,  5.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fed_C 训练完成！\n",
      "各轮平均测试精度: [0.13405586115609766, 0.10101851576954943, 0.12755256904694903, 0.15866613121678858, 0.13678644017460168, 0.15443742569518742, 0.15799133074851782, 0.17714098987351054, 0.19178357401409085, 0.19670741409938203, 0.20084033714551372, 0.20862034300480636, 0.2077575916222286, 0.20596564792559938, 0.21382263177142177, 0.2157057893024545, 0.21974812006065164, 0.21805033136964724, 0.2165090573134278, 0.21976208592962704, 0.2200630578975244, 0.22585673447906984, 0.22460853928009566, 0.2233614409935908, 0.22066678494928776, 0.22225284014844632, 0.22548221332426632, 0.22659773236205458, 0.22791449757351542, 0.22716918504897277, 0.22837006430355833, 0.23297387807299125, 0.2293182452034438, 0.23106647767281183, 0.23441868464300686, 0.23245189738844016, 0.23260540874198063, 0.23186123656112392, 0.23425126920938483, 0.23698230968577186, 0.23891330523901708, 0.23601200781360185, 0.24051762896084386, 0.24109553815063997, 0.24392389197670267, 0.24579622743884838, 0.245565879973174, 0.24125067537106296, 0.24560670571097598, 0.2439451122674507, 0.24199001931052197, 0.2382189843271767, 0.24319276483332572, 0.2385499952697314, 0.24246257326159998, 0.2388422322757972, 0.23849879740237828, 0.24679258805917909, 0.24104569761517408, 0.24783308807996454, 0.2448795590935408, 0.24187102836742352, 0.24714582594989437, 0.2502746736539986, 0.24790092648876277, 0.24815916945425553, 0.2500041566106549, 0.2507793045211583, 0.2510999674999512, 0.24244532803887367, 0.2489889321436623, 0.2471496312005349, 0.25156572283412365, 0.25198964377899796, 0.2482111304829943, 0.24626514387860915, 0.24764991046988694, 0.2534140571668039, 0.2525245608909817, 0.25057830168007567, 0.2524073003749058, 0.2526234244788183, 0.25691924259608684, 0.25098667505848743, 0.24325288113186672, 0.24967713658919957, 0.238267850779404, 0.2323060748122617, 0.24294773046700466, 0.24881948771885182, 0.24089734572903967, 0.24676401735105138, 0.24450736026443934, 0.2532383942854507, 0.25082477338583486, 0.25599699358824063, 0.2611162385858814, 0.25253468906244136, 0.2509350087718151, 0.2540667349533294]\n",
      "各轮平均训练损失: [0.02006710070321793, 0.01492717646473215, 0.012926962620054551, 0.014267045463999655, 0.014671329636502533, 0.014005941148147405, 0.020782828466825404, 0.021325564428372152, 0.021249705713199504, 0.018513051041674916, 0.016311763279404857, 0.015087860680111172, 0.015083011234855814, 0.012211253118605363, 0.012583608338447521, 0.01074849713773008, 0.011027863558408126, 0.01114192755448822, 0.011478326803268319, 0.010836992618024283, 0.010988381919543546, 0.010638735772185118, 0.009362326953487836, 0.009503338700402934, 0.009650320720486131, 0.010383332088604957, 0.008038004331456386, 0.008668577171189547, 0.00837216088484494, 0.009620224951568637, 0.00916187729275008, 0.008241042684358097, 0.00938295982711413, 0.009011377811509742, 0.008384058792414616, 0.008223884808809137, 0.008748353429056215, 0.008711623292227329, 0.007568297564725349, 0.007399268665468079, 0.008540475435466151, 0.007700597382084479, 0.008804097719839291, 0.006618607788674826, 0.007519469656337899, 0.007557898415839001, 0.00626812447044578, 0.007374312752441955, 0.007345442215067757, 0.007155596289111602, 0.006374839295254789, 0.007300000940111271, 0.006995676646320859, 0.007286126877557339, 0.008103988622443384, 0.0060590636003768515, 0.006470899690381712, 0.006877404179579119, 0.006984106673161159, 0.005817540087033879, 0.006490405813348488, 0.006140320961099511, 0.007299652603092364, 0.006601599425851586, 0.006559087199156929, 0.006878541102231503, 0.005712026460042951, 0.006276043822869887, 0.0062661779554244144, 0.007938811225515999, 0.0053756788697675835, 0.007751414195606093, 0.005778000052918618, 0.005946825131799811, 0.006422774006202631, 0.006349391449121392, 0.005746287395060645, 0.005829487602638234, 0.005549589875130466, 0.005304639177835035, 0.005804740135865907, 0.005614202379797851, 0.005972043915376459, 0.005700413000500688, 0.006157363325143003, 0.00620691996547566, 0.006485785646199424, 0.00802615134387871, 0.007967893576388553, 0.006887611401159224, 0.006877968701118549, 0.0056733577426424904, 0.0055889346037881725, 0.005920908403322143, 0.005461135299210334, 0.0058536153143444606, 0.005131552223777463, 0.005350189556701713, 0.0056704016530129886, 0.00500993577547704]\n",
      "最终测试精度: 0.2540667349533294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 83/100 [06:53<01:24,  4.97s/it]"
     ]
    }
   ],
   "source": [
    "# 初始化模型与参数\n",
    "# 这部分是我补充的\n",
    "\n",
    "\n",
    "init_model = mobilenetv2().to(device)\n",
    "initial_w = init_model.state_dict()\n",
    "\n",
    "# Servfer-only训练\n",
    "test_acc, train_loss = server_only(initial_w, global_round, gamma, E)\n",
    "\n",
    "# 打印训练过程中的结果\n",
    "print(\"Server only 训练完成！\")\n",
    "print(\"各轮平均测试精度:\", test_acc)\n",
    "print(\"各轮平均训练损失:\", train_loss)\n",
    "print(\"最终测试精度:\", test_acc[-1] if len(test_acc) > 0 else \"无数据\")\n",
    "\n",
    "\n",
    "init_model = mobilenetv2().to(device)\n",
    "initial_w = init_model.state_dict()\n",
    "\n",
    "# fedavg训练\n",
    "test_acc, train_loss = fedavg(initial_w, global_round, eta, K, M)\n",
    "\n",
    "# 打印训练过程中的结果\n",
    "print(\"fedavg训练完成！\")\n",
    "print(\"各轮平均测试精度:\", test_acc)\n",
    "print(\"各轮平均训练损失:\", train_loss)\n",
    "print(\"最终测试精度:\", test_acc[-1] if len(test_acc) > 0 else \"无数据\")\n",
    "\n",
    "\n",
    "init_model = mobilenetv2().to(device)\n",
    "initial_w = init_model.state_dict()\n",
    "\n",
    "# CLG_SGD训练\n",
    "test_acc, train_loss = CLG_SGD(initial_w, global_round, eta, gamma, K, E, M)\n",
    "\n",
    "# 打印训练过程中的结果\n",
    "print(\"CLG_SGD 训练完成！\")\n",
    "print(\"各轮平均测试精度:\", test_acc)\n",
    "print(\"各轮平均训练损失:\", train_loss)\n",
    "print(\"最终测试精度:\", test_acc[-1] if len(test_acc) > 0 else \"无数据\")\n",
    "\n",
    "\n",
    "init_model = mobilenetv2().to(device)\n",
    "initial_w = init_model.state_dict()\n",
    "\n",
    "# Fed_C训练\n",
    "test_acc, train_loss = Fed_C(initial_w, global_round, eta, gamma, K, E, M)\n",
    "\n",
    "# 打印训练过程中的结果\n",
    "print(\"Fed_C 训练完成！\")\n",
    "print(\"各轮平均测试精度:\", test_acc)\n",
    "print(\"各轮平均训练损失:\", train_loss)\n",
    "print(\"最终测试精度:\", test_acc[-1] if len(test_acc) > 0 else \"无数据\")\n",
    "\n",
    "\n",
    "init_model = mobilenetv2().to(device)\n",
    "initial_w = init_model.state_dict()\n",
    "\n",
    "# Fed_S训练\n",
    "test_acc, train_loss = Fed_S(initial_w, global_round, eta, gamma, K, E, M)\n",
    "\n",
    "# 打印训练过程中的结果\n",
    "print(\"Fed_S 训练完成！\")\n",
    "print(\"各轮平均测试精度:\", test_acc)\n",
    "print(\"各轮平均训练损失:\", train_loss)\n",
    "print(\"最终测试精度:\", test_acc[-1] if len(test_acc) > 0 else \"无数据\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "env8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
