{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "id": "gSK1TSekTVeu"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'data_random_fix' from 'config' (/home/fuyufan/HybridFL-baseline/FedCLG-origin/config.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[164], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Counter\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data_random_fix, seed_num\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'data_random_fix' from 'config' (/home/fuyufan/HybridFL-baseline/FedCLG-origin/config.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.functional as func\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "id": "9-WEXWakTwf8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True' # 解决由于多次加载 OpenMP 相关动态库而引起的冲突"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sns3blEITybc",
    "outputId": "120095fb-5597-4ada-8c12-b4470d8ad28e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec 17 16:57:30 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090        Off | 00000000:21:00.0 Off |                  Off |\n",
      "| 30%   25C    P8              12W / 350W |   3343MiB / 24564MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 4090        Off | 00000000:E1:00.0 Off |                  Off |\n",
      "| 30%   30C    P8              15W / 350W |     14MiB / 24564MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      4557      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "|    0   N/A  N/A    717162      C   /home/anaconda/envs/env8/bin/python        3326MiB |\n",
      "|    1   N/A  N/A      4557      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "id": "96gqMCQneWho"
   },
   "outputs": [],
   "source": [
    "# MobileNetV2（比lenet更复杂的CNN网络）网络中的线性瓶颈结构，原文中用于CIFAR-100任务\n",
    "class LinearBottleNeck(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride, t=6, class_num=100):\n",
    "        super().__init__()\n",
    "\n",
    "        self.residual = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels * t, 1),\n",
    "            nn.BatchNorm2d(in_channels * t),\n",
    "            nn.ReLU6(inplace=True),\n",
    "\n",
    "            nn.Conv2d(in_channels * t, in_channels * t, 3, stride=stride, padding=1, groups=in_channels * t),\n",
    "            nn.BatchNorm2d(in_channels * t),\n",
    "            nn.ReLU6(inplace=True),\n",
    "\n",
    "            nn.Conv2d(in_channels * t, out_channels, 1),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "\n",
    "        self.stride = stride\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        residual = self.residual(x)\n",
    "\n",
    "        if self.stride == 1 and self.in_channels == self.out_channels:\n",
    "            residual += x\n",
    "\n",
    "        return residual\n",
    "\n",
    "class MobileNetV2(nn.Module):\n",
    "\n",
    "    def __init__(self, class_num=20):\n",
    "        super().__init__()\n",
    "\n",
    "        self.pre = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU6(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.stage1 = LinearBottleNeck(32, 16, 1, 1)\n",
    "        self.stage2 = self._make_stage(2, 16, 24, 2, 6)\n",
    "        self.stage3 = self._make_stage(3, 24, 32, 2, 6)\n",
    "        self.stage4 = self._make_stage(4, 32, 64, 2, 6)\n",
    "        self.stage5 = self._make_stage(3, 64, 96, 1, 6)\n",
    "        self.stage6 = self._make_stage(3, 96, 160, 1, 6)\n",
    "        self.stage7 = LinearBottleNeck(160, 320, 1, 6)\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(320, 1280, 1),\n",
    "            nn.BatchNorm2d(1280),\n",
    "            nn.ReLU6(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Conv2d(1280, class_num, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pre(x)\n",
    "        x = self.stage1(x)\n",
    "        x = self.stage2(x)\n",
    "        x = self.stage3(x)\n",
    "        x = self.stage4(x)\n",
    "        x = self.stage5(x)\n",
    "        x = self.stage6(x)\n",
    "        x = self.stage7(x)\n",
    "        x = self.conv1(x)\n",
    "        x = F.adaptive_avg_pool2d(x, 1)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _make_stage(self, repeat, in_channels, out_channels, stride, t):\n",
    "\n",
    "        layers = []\n",
    "        layers.append(LinearBottleNeck(in_channels, out_channels, stride, t))\n",
    "\n",
    "        while repeat - 1:\n",
    "            layers.append(LinearBottleNeck(out_channels, out_channels, 1, t))\n",
    "            repeat -= 1\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "def mobilenetv2():\n",
    "    return MobileNetV2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "id": "QkvtGtMuUDmr"
   },
   "outputs": [],
   "source": [
    "def test_inference(model, test):\n",
    "    \"\"\" Returns the test accuracy and loss.\n",
    "    \"\"\"\n",
    "    tensor_x = torch.Tensor(test[0]).to(device)\n",
    "    tensor_y = torch.Tensor(test[1]).to(device)\n",
    "    test_dataset = TensorDataset(tensor_x, tensor_y)\n",
    "\n",
    "    model.eval()\n",
    "    loss, total, correct = 0.0, 0.0, 0.0\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    testloader = DataLoader(test_dataset, batch_size=128,\n",
    "                            shuffle=True)\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(testloader):\n",
    "        with torch.no_grad():  # 在测试过程中不需要计算梯度，节省内存和加速计算\n",
    "        # Inference\n",
    "            outputs = model(images)\n",
    "            batch_loss = criterion(outputs, labels.long())\n",
    "            loss += batch_loss.item() * labels.size(0) # 计算损失值，更好反映模型输出概率分布与真实标签的差距\n",
    "\n",
    "        # Prediction\n",
    "            _, pred_labels = torch.max(outputs, 1)\n",
    "            pred_labels = pred_labels.view(-1)\n",
    "            correct += torch.sum(torch.eq(pred_labels, labels)).item()\n",
    "            total += len(labels)\n",
    "    #print(correct,\"/\",total)\n",
    "    accuracy = correct/total\n",
    "    return accuracy, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "id": "jURskA9VUJOF"
   },
   "outputs": [],
   "source": [
    "# 将CIFAR-100的100个类别转为20个类别（粒度更粗，降低任务复杂度）\n",
    "def sparse2coarse(targets):\n",
    "    \"\"\"Convert Pytorch CIFAR100 sparse targets to coarse targets.\n",
    "\n",
    "    Usage:\n",
    "        trainset = torchvision.datasets.CIFAR100(path)\n",
    "        trainset.targets = sparse2coarse(trainset.targets)\n",
    "    \"\"\"\n",
    "    coarse_labels = np.array([ 4,  1, 14,  8,  0,  6,  7,  7, 18,  3,\n",
    "                               3, 14,  9, 18,  7, 11,  3,  9,  7, 11,\n",
    "                               6, 11,  5, 10,  7,  6, 13, 15,  3, 15,\n",
    "                               0, 11,  1, 10, 12, 14, 16,  9, 11,  5,\n",
    "                               5, 19,  8,  8, 15, 13, 14, 17, 18, 10,\n",
    "                               16, 4, 17,  4,  2,  0, 17,  4, 18, 17,\n",
    "                               10, 3,  2, 12, 12, 16, 12,  1,  9, 19,\n",
    "                               2, 10,  0,  1, 16, 12,  9, 13, 15, 13,\n",
    "                              16, 19,  2,  4,  6, 19,  5,  5,  8, 19,\n",
    "                              18,  1,  2, 15,  6,  0, 17,  8, 14, 13])\n",
    "    return coarse_labels[targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "id": "jcZ7eQGET_YJ"
   },
   "outputs": [],
   "source": [
    "# 共有6w个图像，其中5w训练，1w测试\n",
    "def CIFAR100():\n",
    "    '''Return Cifar100\n",
    "    '''\n",
    "    train_dataset = torchvision.datasets.CIFAR100(root='../data/CIFAR-100',\n",
    "                                            train=True,\n",
    "                                            transform=transforms.ToTensor(),\n",
    "                                            download=True)\n",
    "    test_dataset = torchvision.datasets.CIFAR100(root='../data/CIFAR-100',\n",
    "                                            train=False,\n",
    "                                            transform=transforms.ToTensor(),\n",
    "                                            download=True)\n",
    "    total_img,total_label = [],[]\n",
    "    for imgs,labels in train_dataset:\n",
    "        total_img.append(imgs.numpy())\n",
    "        total_label.append(labels)\n",
    "    for imgs,labels in test_dataset:\n",
    "        total_img.append(imgs.numpy())\n",
    "        total_label.append(labels) \n",
    "    total_img = np.array(total_img)\n",
    "    total_label = np.array(sparse2coarse(total_label))\n",
    "\n",
    "    cifar = [total_img, total_label]\n",
    "    return cifar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "id": "f1eQhNtPUMOF"
   },
   "outputs": [],
   "source": [
    "# 基于 Dirichlet 分布 来模拟non-IID。返回一个形状为 (client_num, class_num) 的概率矩阵，每一行代表一个客户端对各类别的概率分布。\n",
    "def get_prob(non_iid, client_num, class_num = 20):\n",
    "    # Modify：我之后加上的\n",
    "    if data_random_fix:\n",
    "        np.random.seed(seed_num)  # 固定种子，确保数据抽样一致\n",
    "    \n",
    "    return np.random.dirichlet(np.repeat(non_iid, class_num), client_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "id": "npT3idE-UaGm"
   },
   "outputs": [],
   "source": [
    "def create_data(prob, size_per_client, dataset, N=20):\n",
    "    total_each_class = size_per_client * np.sum(prob, 0)\n",
    "    data, label = dataset\n",
    "\n",
    "    # Modify：我之后加上的\n",
    "    if data_random_fix:\n",
    "        np.random.seed(seed_num)  # 固定种子，确保数据抽样一致\n",
    "        random.seed(seed_num)\n",
    "\n",
    "    # 为每个类别随机采样数据\n",
    "    all_class_set = []\n",
    "    for i in range(N):\n",
    "        size = total_each_class[i]\n",
    "        sub_data = data[label == i]\n",
    "        sub_label = label[label == i]\n",
    "\n",
    "        rand_indx = np.random.choice(len(sub_data), size=int(size), replace=False).astype(int)\n",
    "        sub2_data, sub2_label = sub_data[rand_indx], sub_label[rand_indx]\n",
    "        all_class_set.append((sub2_data, sub2_label))\n",
    "\n",
    "    index = [0] * N\n",
    "    clients, test = [], []\n",
    "\n",
    "    for m in range(prob.shape[0]):  # 遍历客户端\n",
    "        labels, images = [], []  # 训练数据\n",
    "        tlabels, timages = [], [] # 测试数据\n",
    "\n",
    "        # TODO_241216：这里每个client的测试集和它的训练集分布相同，并且最后测试时，也是计算所有client中的准确率的平均值\n",
    "        # TODO_241216：别的FL方法也是这样做的吗？我也要这样做吗？\n",
    "        for n in range(N):\n",
    "            # 80%用于训练，20%用于测试\n",
    "            # 这里的int向下取整，会导致实际的数据量比计算略小\n",
    "            start, end = index[n], index[n] + int(prob[m][n] * size_per_client * 0.8)\n",
    "            test_start, test_end = end, index[n] + int(prob[m][n] * size_per_client)\n",
    "\n",
    "            image, label = all_class_set[n][0][start:end], all_class_set[n][1][start:end]\n",
    "            test_image, test_label = all_class_set[n][0][test_start:test_end], all_class_set[n][1][test_start:test_end]\n",
    "\n",
    "            # 记录当前类别的数据分配进度\n",
    "            index[n] += int(prob[m][n] * size_per_client)\n",
    "\n",
    "            labels.extend(label)\n",
    "            images.extend(image)\n",
    "\n",
    "            tlabels.extend(test_label)\n",
    "            timages.extend(test_image)\n",
    "\n",
    "        clients.append((np.array(images), np.array(labels)))\n",
    "        test.append((np.array(timages), np.array(tlabels)))\n",
    "\n",
    "    return clients, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "id": "DCsR6_QqUzJ8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# 合并所有客户端的测试数据 （上面讲测试数据分成了不同的客户端）\n",
    "# 但并没有使用，用途不明\n",
    "def comb_client_test_func(client_test_data):\n",
    "    comb_client_test_image = []\n",
    "    comb_client_test_label = []\n",
    "    for i in range(client_num):\n",
    "        comb_client_test_image.extend(list(client_test_data[i][0]))\n",
    "        comb_client_test_label.extend(list(client_test_data[i][1]))\n",
    "    \n",
    "    # 将测试图片和标签合并为 numpy 数组\n",
    "    comb_client_test_image = np.array(comb_client_test_image)\n",
    "    comb_client_test_label = np.array(comb_client_test_label)\n",
    "    \n",
    "    label_count = Counter(comb_client_test_label)\n",
    "    print(\"测试集类别分布：\")\n",
    "    for label, count in sorted(label_count.items()):\n",
    "        print(f\"类别 {label}: {count} 个样本\")\n",
    "    \n",
    "    return [comb_client_test_image, comb_client_test_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "id": "JEKzDM0yW3DW"
   },
   "outputs": [],
   "source": [
    "# 从数据集中按类别均匀抽取子集，并按照指定的比例 percentage 进行缩减，同时对数据进行随机打乱\n",
    "def select_subset(whole_set, percentage):\n",
    "    \n",
    "    # Modify：我之后加上的\n",
    "    if data_random_fix:\n",
    "        np.random.seed(seed_num)  # 固定种子，确保数据抽样一致\n",
    "        random.seed(seed_num)\n",
    "    \n",
    "    a = whole_set[0]\n",
    "    b = whole_set[1]\n",
    "    if len(a) != len(b):\n",
    "        raise ValueError(\"Both arrays should have the same length.\")\n",
    "\n",
    "    if not 0 <= percentage <= 1:\n",
    "        raise ValueError(\"Percentage must be between 0 and 1.\")\n",
    "\n",
    "    unique_classes = np.unique(b)\n",
    "\n",
    "    a_prime = []\n",
    "    b_prime = []\n",
    "\n",
    "    for cls in unique_classes:\n",
    "        indices = np.where(b == cls)[0]\n",
    "        subset_size = int(len(indices) * percentage)\n",
    "\n",
    "        selected_indices = np.random.choice(indices, subset_size, replace=False)\n",
    "\n",
    "        a_prime.extend(a[selected_indices])\n",
    "        b_prime.extend(b[selected_indices])\n",
    "\n",
    "    a_prime, b_prime = np.array(a_prime), np.array(b_prime)\n",
    "\n",
    "    # Shuffle arrays to randomize the order of elements\n",
    "    shuffle_indices = np.random.permutation(len(a_prime))\n",
    "    a_prime, b_prime = a_prime[shuffle_indices], b_prime[shuffle_indices]\n",
    "\n",
    "    return [a_prime, b_prime]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'data_random_fix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[163], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 准备数据集\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# 这部分是我加的\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(M)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdata_random_fix\u001b[49m)\n\u001b[1;32m      6\u001b[0m cifar \u001b[38;5;241m=\u001b[39m CIFAR100()\n\u001b[1;32m      7\u001b[0m prob \u001b[38;5;241m=\u001b[39m get_prob(non_iid, client_num, class_num\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_random_fix' is not defined"
     ]
    }
   ],
   "source": [
    "# 准备数据集\n",
    "# 这部分是我加的\n",
    "\n",
    "print(M)\n",
    "print(data_random_fix)\n",
    "cifar = CIFAR100()\n",
    "prob = get_prob(non_iid, client_num, class_num=20)\n",
    "client_data, client_test_data = create_data(prob, size_per_client, cifar, N=20)\n",
    "\n",
    "\n",
    "all_images = []\n",
    "all_labels = []\n",
    "for data in client_data:\n",
    "    all_images.extend(data[0])\n",
    "    all_labels.extend(data[1])\n",
    "comb_client_data = [np.array(all_images), np.array(all_labels)]\n",
    "\n",
    "# 输出cpmb_client_data情况\n",
    "imgs, lbls = comb_client_data\n",
    "lbls = np.array(lbls)\n",
    "total_count = len(lbls)\n",
    "unique_classes, counts = np.unique(lbls, return_counts=True)\n",
    "\n",
    "# 创建一个长度为20的数组记录各类别计数，默认0\n",
    "class_counts = [0]*20\n",
    "for cls, cnt in zip(unique_classes, counts):\n",
    "    class_counts[cls] = cnt\n",
    "\n",
    "# 打印格式：Total: 总数 类别0计数 类别1计数 ... 类别19计数\n",
    "print(\"Traning Client Total: {}\".format(\" \".join([str(total_count)] + [str(c) for c in class_counts])))\n",
    "\n",
    "\n",
    "# 打印每个客户端训练数据情况（只输出前10个）\n",
    "for i, (imgs, lbls) in enumerate(client_data[:10]):\n",
    "    lbls = np.array(lbls)\n",
    "    total_count = len(lbls)\n",
    "    unique_classes, counts = np.unique(lbls, return_counts=True)\n",
    "    # 创建一个长度为20的数组记录各类别计数，默认0\n",
    "    class_counts = [0]*20\n",
    "    for cls, cnt in zip(unique_classes, counts):\n",
    "        class_counts[cls] = cnt\n",
    "    # 打印格式：Client i: 总数 类别0计数 类别1计数 ... 类别19计数\n",
    "    print(\"Client {}: {}\".format(i, \" \".join([str(total_count)] + [str(c) for c in class_counts])))\n",
    "    # 打印前5个数据和标签\n",
    "    print(\"  前5个标签: \", lbls[:5])\n",
    "    print(\"  前5个数据形状: \", [imgs[j].shape for j in range(min(5, len(imgs)))])\n",
    "    print()\n",
    "    \n",
    "\n",
    "# 打印每个客户端测试数据情况（只输出前10个）\n",
    "for i, (imgs, lbls) in enumerate(client_test_data[:10]):\n",
    "    lbls = np.array(lbls)\n",
    "    total_count = len(lbls)\n",
    "    unique_classes, counts = np.unique(lbls, return_counts=True)\n",
    "    class_counts = [0]*20\n",
    "    for cls, cnt in zip(unique_classes, counts):\n",
    "        class_counts[cls] = cnt\n",
    "    # 打印格式：Client i Test: 总数 类别0计数 类别1计数 ... 类别19计数\n",
    "    print(\"Client {} Test: {}\".format(i, \" \".join([str(total_count)] + [str(c) for c in class_counts])))\n",
    "    # 打印前5个数据和标签\n",
    "    print(\"  前5个标签: \", lbls[:5])\n",
    "    print(\"  前5个数据形状: \", [imgs[j].shape for j in range(min(5, len(imgs)))])\n",
    "    print()\n",
    "\n",
    "# 提前生成固定的服务器数据\n",
    "# Modify: 这是我后来修改的\n",
    "server_data = select_subset(comb_client_data, server_percentage)\n",
    "\n",
    "s_imgs, s_lbls = server_data\n",
    "s_lbls = np.array(s_lbls)\n",
    "total_count = len(s_lbls)\n",
    "unique_classes, counts = np.unique(s_lbls, return_counts=True)\n",
    "class_counts = [0]*20\n",
    "for cls, cnt in zip(unique_classes, counts):\n",
    "    class_counts[cls] = cnt\n",
    "\n",
    "# 输出格式: Server round: 总数 类别0计数 类别1计数 ... 类别19计数\n",
    "print(\"Server {}: {}\".format(round, \" \".join([str(total_count)] + [str(c) for c in class_counts])))\n",
    "print(\"  前5个标签: \", lbls[:5])\n",
    "print(\"  前5个数据形状: \", [server_data[0][j].shape for j in range(min(5, len(server_data[0])))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "XvuicdZfeDvL"
   },
   "outputs": [],
   "source": [
    "# 本地训练并更新权重，返回更新后的模型权重、平均训练损失以及第一个迭代的梯度信息\n",
    "def update_weights(model_weight, dataset, learning_rate, local_epoch):\n",
    "    model = mobilenetv2().to(device)\n",
    "    model.load_state_dict(model_weight)\n",
    "\n",
    "    model.train()\n",
    "    epoch_loss = []\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    Tensor_set = TensorDataset(torch.Tensor(dataset[0]).to(device), torch.Tensor(dataset[1]).to(device))\n",
    "    data_loader = DataLoader(Tensor_set, batch_size=128, shuffle=True)\n",
    "\n",
    "    first_iter_gradient = None  # 初始化变量来保存第一个iter的梯度\n",
    "\n",
    "    for iter in range(local_epoch):\n",
    "        batch_loss = []\n",
    "        for batch_idx, (images, labels) in enumerate(data_loader):\n",
    "            model.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels.long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            batch_loss.append(loss.item()/images.shape[0])\n",
    "\n",
    "            # 保存第一个iter的梯度\n",
    "            if iter == 0 and batch_idx == 0:\n",
    "                first_iter_gradient = {}\n",
    "                for name, param in model.named_parameters():\n",
    "                    first_iter_gradient[name] = param.grad.clone()\n",
    "                # 保存 BatchNorm 层的 running mean 和 running variance\n",
    "                for name, module in model.named_modules():\n",
    "                    if isinstance(module, nn.BatchNorm2d):\n",
    "                        first_iter_gradient[name + '.running_mean'] = module.running_mean.clone()\n",
    "                        first_iter_gradient[name + '.running_var'] = module.running_var.clone()\n",
    "\n",
    "        epoch_loss.append(sum(batch_loss)/len(batch_loss))\n",
    "\n",
    "    return model.state_dict(), sum(epoch_loss) / len(epoch_loss), first_iter_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "qsPZGD4Iem5w"
   },
   "outputs": [],
   "source": [
    "# 计算模型权重的差异，并根据学习率 lr 对权重差异进行缩放\n",
    "def weight_differences(n_w, p_w, lr):\n",
    "    w_diff = copy.deepcopy(n_w)\n",
    "    for key in w_diff.keys():\n",
    "        if 'num_batches_tracked' in key:\n",
    "            continue\n",
    "        w_diff[key] = (p_w[key] - n_w[key]) * lr\n",
    "    return w_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "040d862vbG9M"
   },
   "outputs": [],
   "source": [
    "# 也是本地训练，不过引入了本文的权重修正机制\n",
    "def update_weights_correction(model_weight, dataset, learning_rate, local_epoch, c_i, c_s):\n",
    "    model = mobilenetv2().to(device)\n",
    "    model.load_state_dict(model_weight)\n",
    "\n",
    "    model.train()\n",
    "    epoch_loss = []\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    Tensor_set = TensorDataset(torch.Tensor(dataset[0]).to(device), torch.Tensor(dataset[1]).to(device))\n",
    "    data_loader = DataLoader(Tensor_set, batch_size=200, shuffle=True)\n",
    "\n",
    "    for iter in range(local_epoch):\n",
    "        batch_loss = []\n",
    "        for batch_idx, (images, labels) in enumerate(data_loader):\n",
    "            model.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels.long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            batch_loss.append(loss.sum().item()/images.shape[0])\n",
    "        epoch_loss.append(sum(batch_loss)/len(batch_loss))\n",
    "        corrected_graident = weight_differences(c_i, c_s, learning_rate)\n",
    "        orginal_model_weight = model.state_dict()\n",
    "        corrected_model_weight = weight_differences(corrected_graident, orginal_model_weight, 1)  # 这里缩放权重为1\n",
    "        model.load_state_dict(corrected_model_weight)\n",
    "\n",
    "    return model.state_dict(),  sum(epoch_loss) / len(epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "qeFHXRuEo5Du"
   },
   "outputs": [],
   "source": [
    "def average_weights(w):\n",
    "    \"\"\"\n",
    "    Returns the average of the weights.\n",
    "    \"\"\"\n",
    "    w_avg = copy.deepcopy(w[0])\n",
    "    for key in w_avg.keys():\n",
    "        if 'num_batches_tracked' in key:\n",
    "            continue\n",
    "        for i in range(1, len(w)):\n",
    "            w_avg[key] += w[i][key]\n",
    "        w_avg[key] = torch.div(w_avg[key], len(w))\n",
    "    return w_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "pLG9RrFffbl8"
   },
   "outputs": [],
   "source": [
    "# baseline: server-only\n",
    "def server_only(initial_w, global_round, gamma, E):\n",
    "    test_model = mobilenetv2().to(device)\n",
    "    train_w = copy.deepcopy(initial_w)\n",
    "    test_acc = []\n",
    "    train_loss = []\n",
    "    \n",
    "    \n",
    "    for round in tqdm(range(global_round)):\n",
    "        # if gamma > 0.001:\n",
    "        #     gamma = gamma * 0.99\n",
    "        # Server side local training\n",
    "        \n",
    "        \n",
    "        # 从comb中（论文中说明为全部训练数据）选择固定比率的server数据（并且是保证类别均衡的）\n",
    "        # server_data = select_subset(comb_client_data, server_percentage)\n",
    "                \n",
    "        update_server_w, round_loss, _ = update_weights(train_w, server_data, gamma, E)\n",
    "        train_w = update_server_w\n",
    "        test_model.load_state_dict(train_w)\n",
    "        train_loss.append(round_loss)\n",
    "        # Test Accuracy\n",
    "        test_a = 0\n",
    "        for i in client_test_data:\n",
    "            ac = test_inference(test_model,i)[0]\n",
    "            test_a = test_a + ac\n",
    "        test_a = test_a/len(client_test_data)\n",
    "        test_acc.append(test_a)\n",
    "        # print(test_a)\n",
    "    return test_acc, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "nGtAn28aok2c"
   },
   "outputs": [],
   "source": [
    "def fedavg(initial_w, global_round, eta, K, M):\n",
    "    test_model = mobilenetv2().to(device)\n",
    "    train_w = copy.deepcopy(initial_w)\n",
    "    test_acc = []\n",
    "    train_loss = []\n",
    "    for round in tqdm(range(global_round)):\n",
    "        local_weights, local_loss = [], []\n",
    "        # Client side local training\n",
    "        # if eta > 0.001:\n",
    "        #     eta = eta * 0.99\n",
    "        sampled_client = random.sample(range(client_num), M)\n",
    "        for i in sampled_client:\n",
    "            update_client_w, client_round_loss, _ = update_weights(train_w, client_data[i], eta, K)\n",
    "            local_weights.append(update_client_w)\n",
    "            local_loss.append(client_round_loss)\n",
    "\n",
    "        train_w = average_weights(local_weights)\n",
    "\n",
    "        # Test Accuracy\n",
    "        test_model.load_state_dict(train_w)\n",
    "        loss_avg = sum(local_loss)/ len(local_loss)\n",
    "        train_loss.append(loss_avg)\n",
    "        test_a = 0\n",
    "        for i in client_test_data:\n",
    "            ac = test_inference(test_model,i)[0]\n",
    "            test_a = test_a + ac\n",
    "        test_a = test_a/len(client_test_data)\n",
    "        test_acc.append(test_a)\n",
    "#         print(test_a)\n",
    "    return test_acc, train_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybridFL(initial_w, global_round, eta, K, M):\n",
    "    \"\"\"\n",
    "    HybridFL算法：FedAvg改进，服务器也作为一个普通客户端参与训练。\n",
    "    \n",
    "    参数:\n",
    "    - initial_w: 初始模型权重\n",
    "    - global_round: 全局训练轮数\n",
    "    - eta: 学习率\n",
    "    - K: 本地训练轮数\n",
    "    - M: 每轮采样的客户端数量\n",
    "    \"\"\"\n",
    "    test_model = mobilenetv2().to(device)  # 初始化测试模型\n",
    "    train_w = copy.deepcopy(initial_w)     # 当前全局权重\n",
    "    test_acc = []                          # 保存每轮测试精度\n",
    "    train_loss = []                        # 保存每轮训练损失\n",
    "    \n",
    "    for round in tqdm(range(global_round)):\n",
    "        local_weights, local_loss = [], []  # 存储每个客户端/服务器的权重和损失\n",
    "\n",
    "        # 随机采样 M 个客户端\n",
    "        sampled_client = random.sample(range(client_num), M)\n",
    "\n",
    "        # 客户端本地训练\n",
    "        for i in sampled_client:\n",
    "            update_client_w, client_round_loss, _ = update_weights(train_w, client_data[i], eta, K)\n",
    "            local_weights.append(update_client_w)\n",
    "            local_loss.append(client_round_loss)\n",
    "\n",
    "        # 服务器参与训练\n",
    "        update_server_w, server_round_loss, _ = update_weights(train_w, server_data, eta, K)\n",
    "        local_weights.append(update_server_w)   # 将服务器权重加入列表\n",
    "        local_loss.append(server_round_loss)    # 将服务器损失加入列表\n",
    "\n",
    "        # 权重聚合\n",
    "        train_w = average_weights(local_weights)\n",
    "\n",
    "        # 评估模型性能\n",
    "        test_model.load_state_dict(train_w)\n",
    "        loss_avg = sum(local_loss) / len(local_loss)\n",
    "        train_loss.append(loss_avg)\n",
    "        \n",
    "        test_a = 0\n",
    "        for i in client_test_data:  # 遍历所有客户端测试数据\n",
    "            ac = test_inference(test_model, i)[0]\n",
    "            test_a += ac\n",
    "        test_a = test_a / len(client_test_data)\n",
    "        test_acc.append(test_a)\n",
    "        \n",
    "        # # 打印每轮的结果\n",
    "        # print(f\"Round {round + 1}: Test Accuracy = {test_a:.4f}, Train Loss = {loss_avg:.4f}\")\n",
    "    \n",
    "    return test_acc, train_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "uzxW0sUxRGth"
   },
   "outputs": [],
   "source": [
    "def CLG_SGD(initial_w, global_round, eta, gamma, K, E, M):\n",
    "    test_model = mobilenetv2().to(device)\n",
    "    train_w = copy.deepcopy(initial_w)\n",
    "    test_acc = []\n",
    "    train_loss = []\n",
    "    \n",
    "    for round in tqdm(range(global_round)):\n",
    "        # 学习率衰减，这里默认注释掉了\n",
    "        # if eta > 0.001:\n",
    "        #     eta = eta * 0.99\n",
    "        # if gamma > 0.001:\n",
    "        #     gamma = gamma * 0.99\n",
    "        local_weights, local_loss = [], []\n",
    "        # Client side local training\n",
    "        # 从总共client_num客户端中选择M个训练\n",
    "        sampled_client = random.sample(range(client_num), M)\n",
    "        for i in sampled_client:\n",
    "            update_client_w, client_round_loss, _ = update_weights(train_w, client_data[i], eta, K)\n",
    "            local_weights.append(update_client_w)\n",
    "            local_loss.append(client_round_loss)\n",
    "        train_w = average_weights(local_weights)\n",
    "        # Server side local training\n",
    "        \n",
    "        \n",
    "        # 从comb中（论文中说明为全部训练数据）选择固定比率的server数据（并且是保证类别均衡的）\n",
    "        # TODO_241216:这里是每一轮都重新选择数据（但保证类别比例是一样的，都是按照comb中的比例），我的场景中可以这样吗？\n",
    "        # server_data = select_subset(comb_client_data, server_percentage)\n",
    "        \n",
    "        update_server_w, round_loss, _ = update_weights(train_w, server_data, gamma, E)\n",
    "        train_w = update_server_w\n",
    "        local_loss.append(round_loss)\n",
    "\n",
    "        # Test Accuracy\n",
    "        test_model.load_state_dict(train_w)\n",
    "        loss_avg = sum(local_loss)/ len(local_loss)\n",
    "        train_loss.append(loss_avg)   # 计算所有客户端和服务器一起的平均损失\n",
    "\n",
    "        test_a = 0\n",
    "        # 遍历客户端测试数据，计算平均准确率\n",
    "        for i in client_test_data:\n",
    "            ac = test_inference(test_model,i)[0]\n",
    "            test_a = test_a + ac\n",
    "        test_a = test_a/len(client_test_data)\n",
    "        test_acc.append(test_a)\n",
    "#         print(test_a)\n",
    "    return test_acc, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "iJTODAzxYJgA"
   },
   "outputs": [],
   "source": [
    "def Fed_C(initial_w, global_round, eta, gamma, K, E, M):\n",
    "    test_model = mobilenetv2().to(device)\n",
    "    train_w = copy.deepcopy(initial_w)\n",
    "    test_acc = []\n",
    "    train_loss = []\n",
    "    \n",
    "    \n",
    "    for round in tqdm(range(global_round)):\n",
    "        # if eta > 0.001:\n",
    "        #     eta = eta * 0.99\n",
    "        # if gamma > 0.001:\n",
    "        #     gamma = gamma * 0.99\n",
    "        local_weights, local_loss = [], []\n",
    "        g_i_list = []\n",
    "        # server_data = select_subset(comb_client_data, server_percentage)\n",
    "        \n",
    "        \n",
    "        # 计算Server gradient\n",
    "        _, _, g_s = update_weights(train_w, server_data, gamma, 1)\n",
    "\n",
    "        # 计算Client gradient\n",
    "        sampled_client = random.sample(range(client_num), M)\n",
    "        for i in sampled_client:\n",
    "            _, _, g_i = update_weights(train_w, client_data[i], eta, 1)\n",
    "            g_i_list.append(g_i)\n",
    "\n",
    "\n",
    "        # Client side local training\n",
    "        for i in range(len(sampled_client)):\n",
    "            update_client_w, client_round_loss = update_weights_correction(train_w, client_data[sampled_client[i]], eta, K, g_i_list[i], g_s)\n",
    "            local_weights.append(update_client_w)\n",
    "            local_loss.append(client_round_loss)\n",
    "        train_w = average_weights(local_weights)\n",
    "        # Server side local training\n",
    "        update_server_w, round_loss, _ = update_weights(train_w, server_data, gamma, E)\n",
    "        train_w = update_server_w\n",
    "        local_loss.append(round_loss)\n",
    "\n",
    "        # Test Accuracy\n",
    "        test_model.load_state_dict(train_w)\n",
    "        loss_avg = sum(local_loss)/ len(local_loss)\n",
    "        train_loss.append(loss_avg)\n",
    "\n",
    "        test_a = 0\n",
    "        for i in client_test_data:\n",
    "            ac = test_inference(test_model,i)[0]\n",
    "            test_a = test_a + ac\n",
    "        test_a = test_a/len(client_test_data)\n",
    "        test_acc.append(test_a)\n",
    "    return test_acc, train_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "tXqVbWZK7gLn"
   },
   "outputs": [],
   "source": [
    "def Fed_S(initial_w, global_round, eta, gamma, K, E, M):\n",
    "    test_model = mobilenetv2().to(device)\n",
    "    train_w = copy.deepcopy(initial_w)\n",
    "    test_acc = []\n",
    "    train_loss = []\n",
    "    \n",
    "    \n",
    "    for round in tqdm(range(global_round)):\n",
    "        # if eta > 0.001:\n",
    "        #     eta = eta * 0.99\n",
    "        # if gamma > 0.001:\n",
    "        #     gamma = gamma * 0.99\n",
    "        local_weights, local_loss = [], []\n",
    "        g_i_list = []\n",
    "        # Server gradient\n",
    "        # server_data = select_subset(comb_client_data, server_percentage)\n",
    "        _, _, g_s = update_weights(train_w, server_data, gamma, 1)\n",
    "\n",
    "        # Client gradient\n",
    "        sampled_client = random.sample(range(client_num), M)\n",
    "        for i in sampled_client:\n",
    "            _, _, g_i = update_weights(train_w, client_data[i], eta, 1)\n",
    "            g_i_list.append(g_i)\n",
    "\n",
    "\n",
    "        # Client side local training\n",
    "        for i in range(len(sampled_client)):\n",
    "            update_client_w, client_round_loss, _ = update_weights(train_w, client_data[sampled_client[i]], eta, K)\n",
    "            local_weights.append(update_client_w)\n",
    "            local_loss.append(client_round_loss)\n",
    "        train_w = average_weights(local_weights)\n",
    "\n",
    "        # Server aggregation correction\n",
    "        g_i_average = average_weights(g_i_list)\n",
    "        correction_g = weight_differences(g_i_average, g_s, K*eta)\n",
    "        train_w = weight_differences(correction_g, copy.deepcopy(train_w), 1)\n",
    "\n",
    "\n",
    "        # Server side local training\n",
    "        update_server_w, round_loss, _ = update_weights(train_w, server_data, gamma, E)\n",
    "        train_w = update_server_w\n",
    "        local_loss.append(round_loss)\n",
    "\n",
    "        # Test Accuracy\n",
    "        test_model.load_state_dict(train_w)\n",
    "        loss_avg = sum(local_loss)/ len(local_loss)\n",
    "        train_loss.append(loss_avg)\n",
    "\n",
    "        test_a = 0\n",
    "        for i in client_test_data:\n",
    "            ac = test_inference(test_model,i)[0]\n",
    "            test_a = test_a + ac\n",
    "        test_a = test_a/len(client_test_data)\n",
    "        test_acc.append(test_a)\n",
    "    return test_acc, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [03:16<00:00,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server only 训练完成！\n",
      "各轮平均测试精度: [0.10287596441104581, 0.14398139309991856, 0.18785217434418858, 0.15332232592133085, 0.18244263935723987, 0.1758266011586979, 0.18132141144894515, 0.19606317445627663, 0.18624657813666906, 0.19404969934120306, 0.20645191418580824, 0.20822378262696045, 0.21310308546850618, 0.21384980198832929, 0.21281931882743513, 0.21749593855331667, 0.21687878338543315, 0.21281561314871392, 0.22119947122900005, 0.21719179773927563, 0.2184955529584898, 0.22000441994541833, 0.22120145343921352, 0.2218838383774683, 0.2220098439812817, 0.22330934645071362, 0.22244248830570737, 0.22266935400075302, 0.22307121334723048, 0.2240268590851516, 0.2228268642004425, 0.2231056267508674, 0.22245187424746796, 0.2228217072357219, 0.2203045619932656, 0.2200781050569018, 0.2215119964262164, 0.22105446769436837, 0.22176671851942406, 0.2221537017430568, 0.2221933714186379, 0.22351907557640532, 0.22328075253345805, 0.2219697519089592, 0.22186528445081083, 0.2199071593625958, 0.22313815307124038, 0.2234762215068698, 0.2225750717159351, 0.2228792206571188, 0.22340421851764283, 0.22223863572868718, 0.22255339628457743, 0.22251558766664978, 0.22278461827666238, 0.22257056506444525, 0.22358128542696573, 0.22336985105951737, 0.22315499849435355, 0.22537174782635958, 0.2232710985305883, 0.21582240870052838, 0.21915551469748862, 0.21948421269840726, 0.21237765036811967, 0.2133544045633075, 0.21291426781070621, 0.21322561493399556, 0.21374409925776466, 0.21393970047005395, 0.21645409715371575, 0.21462306139046217, 0.2145724196381195, 0.21617019578061988, 0.21457780152308767, 0.21393128237835599, 0.21677071723257565, 0.21652933373507233, 0.21619874732187022, 0.21656348399581749, 0.2165416701777905, 0.21540006350186736, 0.21626562642673408, 0.2172365849194221, 0.21750995769054848, 0.21732885840755567, 0.2181613758907248, 0.21753783231465554, 0.21810531577004327, 0.21904598980756923, 0.21890138689597968, 0.21873110424751988, 0.21814398026740178, 0.21877176879329682, 0.219042097253131, 0.2192509008836515, 0.2178691971727952, 0.21790959751174843, 0.2197358749637349, 0.2146850501769413]\n",
      "各轮平均训练损失: [0.023416101795330803, 0.018740201113732223, 0.014045505073442256, 0.010092580247767217, 0.0068113591961769596, 0.0035901797043475054, 0.002530206358600591, 0.001570852960455298, 0.0009752950862765237, 0.0007548387495699251, 0.0003094280554664872, 8.80768304476756e-05, 2.5122134944731737e-05, 5.029859712285673e-06, 3.405390746140474e-06, 7.220692736728212e-06, 2.031128349106139e-05, 1.3547978103670632e-05, 4.62827043782529e-06, 5.613326382721617e-06, 3.2952337195072807e-06, 2.1682130293083738e-06, 1.5598575000438124e-06, 1.5245244888692014e-06, 1.3817112288597773e-06, 1.338821971300056e-06, 1.493383246231327e-06, 1.2322335232216236e-06, 1.447492335571097e-06, 1.1152836958203594e-06, 9.332912703563551e-07, 1.0795395983326898e-06, 1.5637572170471345e-06, 1.1762653239479423e-06, 9.339801365928896e-07, 9.478615864360943e-07, 9.555076924767232e-07, 1.1580965435396187e-06, 1.22808655357923e-06, 8.334070268984503e-07, 1.0374595565173216e-06, 9.206258790157915e-07, 8.387639313467938e-07, 1.5704748455109813e-06, 9.492405464366813e-07, 9.000152431173764e-07, 1.6664109708640389e-06, 9.679692557912245e-07, 9.41572932832819e-07, 9.004234087890878e-07, 8.842546761602486e-07, 1.5634756601586175e-06, 9.50060313888372e-07, 1.328175580404459e-06, 1.4680912651989913e-06, 1.0736803084988034e-06, 1.0648869627241385e-06, 1.0617371973621859e-06, 1.093720449848604e-06, 1.0928858774367879e-06, 9.241736505617083e-07, 5.6599356009591845e-06, 2.6351491866849645e-06, 1.7038448175088721e-06, 1.133686943346487e-05, 2.6294486067326353e-06, 2.195504316690496e-06, 7.619369014099492e-06, 4.912358741200631e-06, 2.2602606811692094e-06, 1.8613114123722083e-06, 1.843813762676816e-06, 1.4170162671180118e-06, 1.2971574603979106e-06, 1.459308128558382e-06, 1.4061419891174497e-06, 1.189843355896594e-06, 1.2936548513812258e-06, 1.1802550571553923e-06, 1.2850135207442746e-06, 1.1860025442867781e-06, 1.1806132903913787e-06, 1.2210187579197848e-06, 1.2179190965985415e-06, 1.3218014359749775e-06, 1.152130315806655e-06, 1.4252640014640787e-06, 1.1201560052739062e-06, 1.2335767548974118e-06, 1.1497429294581465e-06, 1.0941735267517197e-06, 1.0882389583836507e-06, 1.1922291043702414e-06, 1.2414559338742208e-06, 1.1918483423250108e-06, 1.1756905653534207e-06, 1.8011923342995826e-06, 1.6228187229502163e-06, 1.2108724619306534e-06, 1.4262470050767975e-06]\n",
      "最终测试精度: 0.2146850501769413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:32<00:00,  2.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fedavg训练完成！\n",
      "各轮平均测试精度: [0.04909025234902549, 0.04056460147812731, 0.043613334077364424, 0.05211640637356741, 0.050342874210119744, 0.06446414010343238, 0.10243203302001098, 0.09908160080422884, 0.11629886879982776, 0.0862639521604092, 0.10791582903555977, 0.10070050606671044, 0.12557201517442726, 0.14429485832808506, 0.10927617180579746, 0.1416412639197253, 0.0910099150824588, 0.1473405917603344, 0.1614552283172195, 0.17422235679553486, 0.11458040346819925, 0.12349595601979015, 0.10593530344096798, 0.14233352339481228, 0.11999208294907153, 0.11194232680607576, 0.16152634145237565, 0.14427451565313143, 0.15231357130838036, 0.1667952550986105, 0.14761827962895954, 0.1498900449501697, 0.18335759596093715, 0.14973906480802981, 0.16316053386612303, 0.15528568421199837, 0.15429198570812358, 0.13830550802731134, 0.1637545000082278, 0.18456487916641437, 0.16394078133692488, 0.15428780770213948, 0.18352982600159212, 0.17320022653322273, 0.1900488867649733, 0.19417672279388987, 0.1697734325374337, 0.18493117578679713, 0.19552856490977813, 0.18604549328378694, 0.15914002244347483, 0.2030831480194482, 0.19086071497474008, 0.18029472238322267, 0.17645239550366487, 0.2155909388449727, 0.17735842152441386, 0.16889376954749594, 0.20709042370114625, 0.1675801334980888, 0.20171377514225733, 0.19165758841284258, 0.20731247455191393, 0.21389860845316933, 0.21444943980253103, 0.19508817381727264, 0.20624185589250743, 0.18270216223845273, 0.1963310723772929, 0.20366576679912188, 0.19532017520826958, 0.19957608793736273, 0.21297790936057406, 0.20456784033886824, 0.22260023821068078, 0.20292258358576223, 0.19764239976274645, 0.2031793517405177, 0.21072413841754747, 0.21598843246727756, 0.19783981113037072, 0.21216576768156006, 0.20947032277752553, 0.2111380729262591, 0.2131805753727641, 0.1978666541681997, 0.22685032028865407, 0.21025241359686603, 0.2408290689160431, 0.22783229156602508, 0.22676848695118978, 0.23604121621795568, 0.23542905136642622, 0.21957994469530198, 0.23260770025310118, 0.23212105306485392, 0.23460743683185614, 0.19881356136665562, 0.23785613061619112, 0.2380983829412904]\n",
      "各轮平均训练损失: [0.1194063848781172, 0.0863479965937065, 0.08287341058340604, 0.06371296940172218, 0.06148028849830802, 0.06118923528173379, 0.060541356715515304, 0.0555923189480302, 0.057969740089590084, 0.05486983071892508, 0.05261966084644189, 0.0558759777305702, 0.052195725500187064, 0.05197233530786503, 0.0528913437351287, 0.05008449017792791, 0.05284028704905027, 0.05316310624805356, 0.050491664667284955, 0.05098451635050483, 0.04794332225304872, 0.04573394765254067, 0.050755768729561654, 0.04772959471986002, 0.04659545887703873, 0.05075328775960928, 0.04673349142925554, 0.04395636964786648, 0.044074611638193935, 0.045464827855032794, 0.04384936362233121, 0.0454973635645117, 0.04288024690305994, 0.0433357284100025, 0.043110381183204004, 0.04152929653226321, 0.04268536573494723, 0.04148354638411381, 0.042831297096759334, 0.04013538808327096, 0.03920292440307448, 0.042821875082150504, 0.03910126060673047, 0.03976258897808535, 0.038122746394129846, 0.03976768819576665, 0.03899169499598375, 0.04015358159315408, 0.04002786810016735, 0.03466140684580926, 0.03926837130001844, 0.036242299820618724, 0.034896103588904416, 0.038414585350936045, 0.032625582693850595, 0.035911171954709234, 0.03888257126665008, 0.036494451687792376, 0.03359370558338328, 0.03806067747731036, 0.032508136743557646, 0.035386587836501164, 0.03108188954094345, 0.03412262553280417, 0.033304681230104875, 0.03491128448825475, 0.02905148321365697, 0.032209513414529184, 0.03204706033836567, 0.034234863076221804, 0.03178407106707756, 0.034761182095325395, 0.02889584119513199, 0.03225402060282771, 0.028814987232684674, 0.030884976451184938, 0.03147289970966684, 0.02795329474331677, 0.029088459438477716, 0.02965381834740425, 0.030695742265771837, 0.0327375945924939, 0.026591344860812566, 0.029826529730259017, 0.03105306805388791, 0.02616328941316458, 0.02713373886253827, 0.027718767112750738, 0.02937728449698686, 0.026774043112261586, 0.025945069300403318, 0.02857007325159016, 0.024684764130496514, 0.025751727068212465, 0.02671600942334134, 0.02556506183355368, 0.02621736438558999, 0.03234585724708783, 0.02581357909967777, 0.026364766175247488]\n",
      "最终测试精度: 0.2380983829412904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [06:35<00:00,  3.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hrbridFL训练完成！\n",
      "各轮平均测试精度: [0.053957122894053786, 0.05686840258073125, 0.04714090100213855, 0.04749484461912065, 0.0799466074424876, 0.09326020003920625, 0.091831390987528, 0.09958089509730689, 0.12482589655556252, 0.12671191527281242, 0.13257300379781112, 0.151239897438333, 0.15123664145273527, 0.13572183703622703, 0.15143711387931386, 0.12205902712804814, 0.133213256151411, 0.13312059317541888, 0.13944014202394417, 0.15855623224121884, 0.14551716305128543, 0.15061827077015358, 0.15044808906114374, 0.13681884259166913, 0.15095850188933516, 0.14232047531966918, 0.16109265975948797, 0.15992253674309148, 0.15264397599831736, 0.14374546114863146, 0.16408503161096658, 0.1511708738292685, 0.1447741664925964, 0.13645078822865997, 0.13033396302378214, 0.15706642877117086, 0.1655200463154943, 0.17298106915167386, 0.18974912977742317, 0.16639097209315057, 0.16478634751158025, 0.1564910258706492, 0.19451249521154285, 0.1960555040787524, 0.2342281804225485, 0.2237302188668877, 0.2190291416786026, 0.1912686652663591, 0.2158188042436407, 0.21973011705937417, 0.20286155658201277, 0.23714763972153066, 0.20306668600053818, 0.2185233871887638, 0.2188330083681981, 0.2042843414548155, 0.2465049656478403, 0.21308071686424235, 0.2330212850978478, 0.22877484191793296, 0.24358001610951485, 0.2058887362779763, 0.21765305973912327, 0.23381312828685352, 0.2492013864046918, 0.23622859390437456, 0.23965365168409467, 0.2540556573333241, 0.2474594220663568, 0.2550238138507385, 0.21529989569565117, 0.24067302953896882, 0.23893057139813187, 0.2610292744110811, 0.22067401628122724, 0.25350143255596347, 0.2212983414433283, 0.22757499470655118, 0.23274040103862528, 0.24620194298522569, 0.24670434137633446, 0.23287425112348978, 0.22712746581496007, 0.21303616476017356, 0.2230517173651783, 0.2631859158491916, 0.2604247601841041, 0.2463239633572276, 0.23899089295616213, 0.22984069264663048, 0.240832468433328, 0.2593017620164304, 0.24285422550180966, 0.2730662337659158, 0.21968131693372758, 0.2726824327122078, 0.23727570644130336, 0.2714770478197874, 0.27456707182281476, 0.26771668389164727]\n",
      "各轮平均训练损失: [0.1153350862598287, 0.08452446171160392, 0.0732633485381391, 0.0563864753177989, 0.05249263348406203, 0.048381905466483584, 0.052593188547153114, 0.05132161827336618, 0.04826406546067885, 0.046058244460479174, 0.04758216348113511, 0.04359713141807258, 0.04610927111433678, 0.04390621110256612, 0.0453085577497245, 0.04150994329503777, 0.04165732786115742, 0.035739914766884345, 0.04189889839749774, 0.03448637814950989, 0.0380540986603414, 0.04051637746971154, 0.03096819846062392, 0.03424191154292319, 0.03384048357065025, 0.03657158004202621, 0.03419513497089188, 0.03317678446922753, 0.03336314527655449, 0.03387738884329155, 0.031162584966819305, 0.03056581611269389, 0.034724459713546096, 0.03108970078623999, 0.029002187979606953, 0.029504655992419925, 0.02846010242683593, 0.030018488696118638, 0.025032042903871555, 0.027718148522791586, 0.02924991750889301, 0.02670839093549593, 0.02776163715902719, 0.024276122519712232, 0.027459875822142196, 0.023531296803843513, 0.023052733273902448, 0.02575179833729618, 0.023669554599973407, 0.020806826679763104, 0.025853511225798587, 0.02606989435685574, 0.025768005401539753, 0.023404944265799997, 0.02475946835325209, 0.025278815812948777, 0.02041660625625164, 0.023066897375637874, 0.02157127482896703, 0.022033167325917955, 0.02173362750447708, 0.01869243986518264, 0.022534947139564124, 0.021960248512275158, 0.019376029391714466, 0.02265778437078542, 0.019887657680765867, 0.019778569130894496, 0.02221585347121481, 0.02056744729445942, 0.02221510847484358, 0.018331259570315363, 0.022801942508683483, 0.021103720807071107, 0.022091634908264293, 0.018449638666031002, 0.017659236024471083, 0.021623809822338826, 0.01921894585181684, 0.019461976574721027, 0.018992173936851257, 0.020899358080621613, 0.019864561614536938, 0.020316205233369595, 0.01970589186613135, 0.020710566955311784, 0.017675998664848678, 0.01961201192876224, 0.019416969267212945, 0.018357926115701546, 0.018058292271080693, 0.020089076174141463, 0.021939919643938755, 0.018209826013746693, 0.01696183058794188, 0.017118280179068437, 0.018678332648233882, 0.01513076238572691, 0.019402928905653052, 0.018532409318567214]\n",
      "最终测试精度: 0.26771668389164727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [06:34<00:00,  3.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLG_SGD 训练完成！\n",
      "各轮平均测试精度: [0.12523758996172574, 0.14221342167199988, 0.16057737424548615, 0.14502243708854362, 0.1709575013170446, 0.16487871185916894, 0.19832643131498615, 0.2121569714196328, 0.23073052752357603, 0.22322664553088903, 0.22891850808094802, 0.23669282943712372, 0.238441387177106, 0.24475360900603838, 0.24523140820344286, 0.24473755932969066, 0.2519537682055295, 0.25033475364465063, 0.2513735290642475, 0.25899560887193346, 0.25829460671035653, 0.2648159503099647, 0.2651651346668997, 0.2684001796878584, 0.271747443065591, 0.2707218395661167, 0.26940713490582513, 0.27026183845500484, 0.28148396888711696, 0.2786054416261112, 0.28040295082269, 0.2707211707939496, 0.2783889987401085, 0.27968071061335753, 0.2838844119483169, 0.2850213755366382, 0.2807335032956208, 0.28154487974279296, 0.27898301813255755, 0.2800505387682746, 0.27960427726195936, 0.2837573864766375, 0.28801778316993853, 0.28406216490758757, 0.28262771438623746, 0.28255458911193737, 0.2888241831493614, 0.2808239454355972, 0.286384902621435, 0.2834979444893876, 0.2916740876115669, 0.29082014719165433, 0.29152149774114056, 0.29470232550471814, 0.2989497070389127, 0.29879641618392483, 0.2956037861237655, 0.2932258978119689, 0.29500779569637603, 0.3003237279114222, 0.29529544729599183, 0.2959919410007103, 0.30074066542559985, 0.2989686690534563, 0.2930003394430022, 0.29685267562806944, 0.2896791413972019, 0.3001146440575306, 0.29497702691431976, 0.3042914167855133, 0.2972854185812098, 0.29605801054862535, 0.2985616276945013, 0.2986995941853726, 0.3028726030812413, 0.30193309746492863, 0.3043816798621108, 0.30264904613360794, 0.3049028476593891, 0.30492362030298614, 0.30919133394134873, 0.3027820898441625, 0.298950673861539, 0.29987010908264655, 0.3072657857971132, 0.303905081701694, 0.30921433982506996, 0.3061977127197596, 0.3054639340372951, 0.30741882508376517, 0.29776033437491545, 0.3009882128111858, 0.30059639959751167, 0.3086123318811659, 0.30661099304278544, 0.3041384227112425, 0.3040628077706173, 0.3041104623397513, 0.30919598847825625, 0.3083446313412503]\n",
      "各轮平均训练损失: [0.10640081697304127, 0.05488228308239639, 0.049158143498306384, 0.052205799575113156, 0.0436049171934474, 0.045660281072351386, 0.05485680869783665, 0.07286210860973884, 0.065558019250048, 0.06762657075850835, 0.05793642116510529, 0.0532783841347449, 0.04371294772568942, 0.04354310083399294, 0.04692925150410685, 0.04225800218097761, 0.04056716601586012, 0.04331730687195115, 0.037363334737350644, 0.03764963857249516, 0.03405111551639086, 0.039093748940348776, 0.03191866768047988, 0.030451215472753316, 0.034005345222308636, 0.030597653380587585, 0.0292416176923217, 0.030594831345093654, 0.03127486248715756, 0.03289631001849237, 0.026070696516992398, 0.031890880133697126, 0.028334271336615733, 0.02988719959639565, 0.02604388377983945, 0.028617878221282735, 0.02406702013368255, 0.030291258202943042, 0.027700857860774, 0.0265838250838928, 0.02360904619046129, 0.02318909024951182, 0.02758070388677455, 0.025738879352382945, 0.02501872379739887, 0.025982345115207764, 0.021412651164675115, 0.02618526185233688, 0.02672672442373344, 0.02569896438129043, 0.02523527640983806, 0.02111000683782382, 0.02480418601345695, 0.022694839221627364, 0.023072060484531667, 0.02069755715803021, 0.02272090169624223, 0.02649555717966223, 0.020366149644237726, 0.025161111130595725, 0.019860728135405296, 0.02041419553781902, 0.019050214230313837, 0.020351064625307735, 0.02361623716828921, 0.026936610874557596, 0.02176209109401425, 0.02315116511202507, 0.022878732466176013, 0.020239013207103664, 0.021451236061835563, 0.022876825347590488, 0.02134912083664947, 0.021169876826952004, 0.018248280420760817, 0.023477861398575, 0.02506576363307321, 0.019067907239466882, 0.019149850423146517, 0.024553070540421943, 0.020015044178061357, 0.019705831774037733, 0.018828443139145612, 0.02290685879520289, 0.020128842073794364, 0.020413359911006602, 0.015512342692350427, 0.020590092578609484, 0.019713029527802708, 0.021897702423555376, 0.020720020175430127, 0.020089762601890968, 0.017140013368028437, 0.017894437184740746, 0.01792778561966204, 0.021823338613617967, 0.018454343851094526, 0.018323616939107862, 0.016334337738203107, 0.02043433043857471]\n",
      "最终测试精度: 0.3083446313412503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [09:12<00:00,  5.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fed_C 训练完成！\n",
      "各轮平均测试精度: [0.12615467048895782, 0.1627785754685289, 0.16198091806571666, 0.13723818688190864, 0.1676069967032403, 0.1734848166852264, 0.211449693573436, 0.22312925372548606, 0.22592935062972294, 0.23483138094432007, 0.23951563075659635, 0.24111323880691646, 0.24258253600746207, 0.2454702916865273, 0.24233952398446593, 0.25018736042030276, 0.24930095248243134, 0.2508391692226251, 0.2537979626967334, 0.257471475894107, 0.25176487975438244, 0.2540558915269858, 0.25450033333225486, 0.2554862318613886, 0.25722358977610194, 0.2567135643176557, 0.26245620920625035, 0.26304287665093473, 0.25708633931960256, 0.2642265398168763, 0.2642673753904201, 0.2673103999871807, 0.26687450791894834, 0.2587185153440638, 0.26389970177304867, 0.2702570323461522, 0.2680517203951278, 0.2681644456325995, 0.2742668900774888, 0.2704863444703391, 0.27491716882370515, 0.27544270869847776, 0.2731270232005744, 0.2730589226506732, 0.2729093399045595, 0.2755409400216993, 0.27802053607795174, 0.27522047882421935, 0.27544142938590194, 0.2767773601701191, 0.2732192828548697, 0.2787915957871177, 0.28168427769064386, 0.2801372879687506, 0.28228657915980304, 0.28395242127672654, 0.284092275315814, 0.286468936152128, 0.2853466775300074, 0.28074156243362824, 0.2816142035551907, 0.27725751987513114, 0.28158358066634925, 0.2791273467458089, 0.2782272073223799, 0.28286665467656674, 0.2853255361684363, 0.2856076736158721, 0.2888458169674881, 0.287995380721692, 0.2908432077112069, 0.29184377632396113, 0.2903678345249867, 0.2842212452585097, 0.28837289767944, 0.28648552601623023, 0.29638248692534147, 0.29032507418541614, 0.2918349278353307, 0.28917783366468697, 0.2943633541255605, 0.2901951669256278, 0.29781494161082256, 0.2958002186569857, 0.2980824004771075, 0.29659450191507153, 0.293166284851085, 0.2940342531583761, 0.2883648566531995, 0.2945479719359581, 0.2936057150071389, 0.2888804004157878, 0.293308244208474, 0.28622458474188117, 0.2909196781699654, 0.2888159850793855, 0.2850667416145256, 0.28562767264710714, 0.2936956981992171, 0.29252007446284545]\n",
      "各轮平均训练损失: [0.019953988224831236, 0.014494224721085901, 0.014084112532213184, 0.014614004546024724, 0.013657057062472437, 0.014779974822120167, 0.019624224172372126, 0.019546623069393684, 0.017737390518345404, 0.016324597525576, 0.013852498280044763, 0.013995334850619195, 0.01156849216836253, 0.011414955412901169, 0.011468809630769372, 0.011280398141618143, 0.010430968217784315, 0.010311649278132204, 0.010891988117534095, 0.00997375489394157, 0.008907898685444645, 0.008870179526762147, 0.009447890740722041, 0.009892757211928511, 0.008666043667595102, 0.00814675114030687, 0.008179923258023573, 0.009878805215452747, 0.00914812213985326, 0.008210209687857234, 0.009098039657556484, 0.007899453537359172, 0.00825057613367041, 0.007683353088262288, 0.008325270062658844, 0.007921711025743763, 0.006784912808907925, 0.008193226762726378, 0.006944470990549051, 0.008008653014815797, 0.007610242086996537, 0.008406842025817395, 0.007337350996681303, 0.007426970990196468, 0.007752248566714504, 0.0071058450356163904, 0.005891976213277553, 0.007266469679957254, 0.008267922486967613, 0.006512723469571177, 0.006928241294039153, 0.006087280535936754, 0.0064923632524122666, 0.00717624522686984, 0.0059913868044667645, 0.006340588870298969, 0.005819523750453629, 0.006453327860004244, 0.007085784493746902, 0.006597935642866196, 0.006997172852936829, 0.006444890671353901, 0.006312280348710026, 0.006663604328766573, 0.006183889151155897, 0.006028406449540172, 0.006198910997722768, 0.005770177360083111, 0.006200291535028293, 0.00594919353344572, 0.005266668011590709, 0.006031607747729263, 0.005436123374693618, 0.005498762565964746, 0.004833729464545225, 0.005888551995262046, 0.005784695994432671, 0.006355552571057175, 0.0064614078523960086, 0.005616014266934601, 0.0062221868680300465, 0.004743117892955737, 0.005558749008928342, 0.006226729915703394, 0.0055420064306730375, 0.005308632498348234, 0.006025543917058851, 0.006101598728914464, 0.005255004372425275, 0.006299237408028077, 0.004920953834602813, 0.00630030688075896, 0.005135734230876186, 0.005361836399311288, 0.004882691535301359, 0.005469640271371273, 0.005620950765645684, 0.004898619184429085, 0.004445875254610087, 0.005366809034188456]\n",
      "最终测试精度: 0.29252007446284545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [08:08<00:00,  4.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fed_S 训练完成！\n",
      "各轮平均测试精度: [0.11243657614243403, 0.129382204409315, 0.14752653122295167, 0.12774640828803135, 0.18267021329237715, 0.172139218579519, 0.16099717762975282, 0.1972278806934371, 0.20987041731843498, 0.21282430825065968, 0.21966256256785235, 0.21748071277156705, 0.21161362432234815, 0.2248415028408013, 0.22337587671846695, 0.22628296787587523, 0.23046994128935405, 0.2375578584822843, 0.23042851693815203, 0.24161662425966676, 0.24276353569616788, 0.2370614957009856, 0.239097244114029, 0.2393319197259997, 0.24273599046415253, 0.24341480392404713, 0.24641676027966578, 0.24523474822480323, 0.2443403705685513, 0.2456229285541387, 0.2458172976616717, 0.25121979344643314, 0.2513282905696218, 0.25052011436061483, 0.25063539973717736, 0.25711064287923013, 0.25836051704458934, 0.2544204471904563, 0.25364239362850055, 0.2592582955004066, 0.26190619843744, 0.2655894696277714, 0.2638273908926281, 0.26613416441215565, 0.2644123818392558, 0.267456079117112, 0.26274778543983607, 0.2662344375102308, 0.269518436676768, 0.27035808600295697, 0.2567430134869606, 0.25933331316808184, 0.26554913660050683, 0.26649301581824986, 0.2635663360547603, 0.26070104643167136, 0.26719457654092077, 0.261420391653793, 0.27285226754534436, 0.2637069255166136, 0.2661161819771248, 0.26489346850867646, 0.26763891786597166, 0.26870722930043534, 0.2720484675257714, 0.26612936148936756, 0.2699742234303688, 0.27714968812148777, 0.26960665424109154, 0.27656718979913975, 0.2700553562145496, 0.2773295742029136, 0.2762591387945708, 0.27788485845593563, 0.2731933026711514, 0.2705401318817071, 0.2702058780978124, 0.2698643403714863, 0.27026187516869127, 0.26763899839584976, 0.2751084506807405, 0.2761729248120345, 0.27608857083242094, 0.2802648109992163, 0.2787532008194456, 0.27930045672642767, 0.2777368945845375, 0.2839397057839604, 0.2737593454157698, 0.27887922151377476, 0.28893436945414364, 0.2850835472214925, 0.29099036215383933, 0.29024624883380135, 0.2823322266549794, 0.28999212029224425, 0.2956871256758784, 0.29029825475490023, 0.28319555662797224, 0.28660578013885024]\n",
      "各轮平均训练损失: [0.11710766916686623, 0.05674292802731317, 0.04894104826688767, 0.044546172022514825, 0.04731175596249947, 0.037759380526399516, 0.048572813167380574, 0.06345605229539336, 0.06746701226752816, 0.0628297051846079, 0.06657186228407183, 0.06049211718190968, 0.04854845381187734, 0.05101742413869115, 0.049006226622550185, 0.046232960871247356, 0.03896341002404139, 0.04066975718701716, 0.041086975027137276, 0.040597539735058766, 0.03730334853966175, 0.03632787861854963, 0.03584712738070714, 0.03929863758958289, 0.03650141865680257, 0.034901073168833494, 0.040610244360495366, 0.03609784182829344, 0.03316005302341279, 0.03427299230708488, 0.03354860708266515, 0.03768292307462575, 0.03163076065016952, 0.033517041399896426, 0.03756860850874294, 0.029737483777905103, 0.03326113124130234, 0.03220141888087531, 0.030368736955570897, 0.03413261005225853, 0.03326566389214204, 0.027240729529703796, 0.031785052247306045, 0.02773958907751538, 0.029102428300350366, 0.025776524563546146, 0.026115795330029164, 0.025318612708229663, 0.02541274711795806, 0.027710476122126782, 0.024660478232454364, 0.028397137477382928, 0.02708832243233825, 0.02957166235681886, 0.03036922415208515, 0.02671684123642957, 0.03063151457722616, 0.026028652105798026, 0.024134578727542964, 0.030151264487311234, 0.02710455015543001, 0.0242774864621957, 0.02366304215860218, 0.02844844470108794, 0.02576730697704335, 0.025391336133744648, 0.02385085525784325, 0.025316301423067244, 0.027554752113083746, 0.025619896202643492, 0.027511090055811052, 0.02213012326435365, 0.02589991443020168, 0.022758785886590936, 0.027489081214650445, 0.02686762445447869, 0.025325563551183452, 0.02265075124720483, 0.023175474732953973, 0.02273377930947469, 0.025557848596465663, 0.025739531396763625, 0.022733005395155492, 0.022932263293040024, 0.02162764314419177, 0.025575271624838528, 0.020959542158727355, 0.022974349549860995, 0.02084264317268136, 0.02435477532066929, 0.024118395284052983, 0.023371342254522545, 0.02381704021812586, 0.021308686117042973, 0.019245915133595252, 0.023451153773353318, 0.024181663000365835, 0.01943485281703823, 0.0201210191375782, 0.019660533158325975]\n",
      "最终测试精度: 0.28660578013885024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 初始化模型与参数\n",
    "# 这部分是我补充的\n",
    "\n",
    "\n",
    "init_model = mobilenetv2().to(device)\n",
    "initial_w = init_model.state_dict()\n",
    "\n",
    "# Servfer-only训练\n",
    "test_acc, train_loss = server_only(initial_w, global_round, gamma, E)\n",
    "\n",
    "# 打印训练过程中的结果\n",
    "print(\"Server only 训练完成！\")\n",
    "print(\"各轮平均测试精度:\", test_acc)\n",
    "print(\"各轮平均训练损失:\", train_loss)\n",
    "print(\"最终测试精度:\", test_acc[-1] if len(test_acc) > 0 else \"无数据\")\n",
    "\n",
    "\n",
    "init_model = mobilenetv2().to(device)\n",
    "initial_w = init_model.state_dict()\n",
    "\n",
    "# fedavg训练\n",
    "test_acc, train_loss = fedavg(initial_w, global_round, eta, K, M)\n",
    "\n",
    "# 打印训练过程中的结果\n",
    "print(\"fedavg训练完成！\")\n",
    "print(\"各轮平均测试精度:\", test_acc)\n",
    "print(\"各轮平均训练损失:\", train_loss)\n",
    "print(\"最终测试精度:\", test_acc[-1] if len(test_acc) > 0 else \"无数据\")\n",
    "\n",
    "\n",
    "\n",
    "init_model = mobilenetv2().to(device)\n",
    "initial_w = init_model.state_dict()\n",
    "\n",
    "# hybridfl训练\n",
    "test_acc, train_loss = hybridFL(initial_w, global_round, eta, K, M)\n",
    "\n",
    "# 打印训练过程中的结果\n",
    "print(\"hrbridFL训练完成！\")\n",
    "print(\"各轮平均测试精度:\", test_acc)\n",
    "print(\"各轮平均训练损失:\", train_loss)\n",
    "print(\"最终测试精度:\", test_acc[-1] if len(test_acc) > 0 else \"无数据\")\n",
    "\n",
    "\n",
    "init_model = mobilenetv2().to(device)\n",
    "initial_w = init_model.state_dict()\n",
    "\n",
    "# CLG_SGD训练\n",
    "test_acc, train_loss = CLG_SGD(initial_w, global_round, eta, gamma, K, E, M)\n",
    "\n",
    "# 打印训练过程中的结果\n",
    "print(\"CLG_SGD 训练完成！\")\n",
    "print(\"各轮平均测试精度:\", test_acc)\n",
    "print(\"各轮平均训练损失:\", train_loss)\n",
    "print(\"最终测试精度:\", test_acc[-1] if len(test_acc) > 0 else \"无数据\")\n",
    "\n",
    "\n",
    "init_model = mobilenetv2().to(device)\n",
    "initial_w = init_model.state_dict()\n",
    "\n",
    "# Fed_C训练\n",
    "test_acc, train_loss = Fed_C(initial_w, global_round, eta, gamma, K, E, M)\n",
    "\n",
    "# 打印训练过程中的结果\n",
    "print(\"Fed_C 训练完成！\")\n",
    "print(\"各轮平均测试精度:\", test_acc)\n",
    "print(\"各轮平均训练损失:\", train_loss)\n",
    "print(\"最终测试精度:\", test_acc[-1] if len(test_acc) > 0 else \"无数据\")\n",
    "\n",
    "\n",
    "init_model = mobilenetv2().to(device)\n",
    "initial_w = init_model.state_dict()\n",
    "\n",
    "# Fed_S训练\n",
    "test_acc, train_loss = Fed_S(initial_w, global_round, eta, gamma, K, E, M)\n",
    "\n",
    "# 打印训练过程中的结果\n",
    "print(\"Fed_S 训练完成！\")\n",
    "print(\"各轮平均测试精度:\", test_acc)\n",
    "print(\"各轮平均训练损失:\", train_loss)\n",
    "print(\"最终测试精度:\", test_acc[-1] if len(test_acc) > 0 else \"无数据\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "env8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
